# Intro

**개발 과정 기록**

참고) 인증체크 테스트할때 서버메모리에 쿠키를 저장하기 때문에 "로그아웃" 해줘야 함

참고) [h2 tutorialspoint](https://www.tutorialspoint.com/h2_database/h2_database_explain.htm), [h2 doc](https://www.h2database.com/html/features.html)

<br><br>

## 23-11-23 (Pool 활용 부하테스트 개선) -> 개선은 이거까지만!

**+다중요청) DB Connection Pool, Thread Connection Pool**

* Git merge 먼저
* Thread는 일단 패스하겠고, DB Connection Pool은 당장 적용해보겠음
* **[시리즈3 db 커넥션풀](https://hyuntaeknote.tistory.com/m/12)**
* **[Thread Pool 간단 적용법](https://velog.io/@rara_kim/Spring-Thread-Pool-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0feat.-Scheduler)**

<br><br>

## 23-11-22 (본격 부하테스트 -> 성능개선) + Pool

**부하테스트로 성능비교 + 적절한 캐시 크기 함께 찾기**

* **nGrinder 테스트**
  
  * java11 버전 + cmd 사용
  * nGrinder 실행 : `java -jar ngrinder-controller-{version}.war --port=8300`
  * agent 실행시 `run_agent.bat`
  * 데이터 세팅 : 멤버1의 lists 데이터는 약 2만개, member 관련 데이터 약 4만개
  * db, 스프링, agent, ngrinder 재부팅 하면서 테스트 고고(혹시모르니)
* **참고) "조회 순서 때문에 Index 사용 안함 주의"**
  * 100% fetch join 부분들 때문이라 보면 됨
  * 예로 member desc 먼저 조회하고 character 외래키 하고 exp 외래키 순으로 index적용되어야 하는데,   
    캐릭터 풀스캔, exp 풀스캔, member 풀스캔.... 엉망이다.
    * 따라서 member -> character -> exp 순으로 조회되게끔 최대한 sql 수정해보자.
    * 생각한 아이디어는 서브쿼리를 활용하는것!
    * **참고 : [페이지네이션 최적화](https://taegyunwoo.github.io/tech/Tech_DBPagination#limit-offset-%EB%B0%A9%EC%8B%9D%EC%9D%98-%EB%AC%B8%EC%A0%9C%EC%A0%90)**
    * **JPQL로 서브쿼리는 from절에 사용불가하므로 이땐 "네이티브 쿼리활용!!"**

* **수정전 부하테스트 진행 -> 결과 꼭 기록(+사진)**

  * **시나리오1 -> 나중에 예외처리할 때 수정할 예정**
  * **시나리오3-2**
    * full scan 시? 약 2만개 : 5천개 17일자, 1만5천개 20일자
    * 스크립트 - scenario3-2.groovy 사용 / 에이전트1 / vuser500 / 2분 / Ramp-up (쓰레드, 단위10, 주기1000)
    * 컬렉션 페치조인이다 보니 h2 db에서 쿼리를 어떻게 작성해야할지 모르겠음.
    * 페치조인 제외하고 테스트를 해보면 "외래키Index" 사용중이라 그렇게 느리진 않음
  * **시나리오4**
    * full scan 시? 약 4만개
    * 스크립트 - scenario4.groovy 사용 / 에이전트1 / vuser500 / 2분 / Ramp-up (쓰레드, 단위10, 주기1000)
    * 캐시를 제거하고 테스트해서 성능개선 하겠음 (물론, 마지막에 캐시도 추가할거임)
    * **order by 때문에 매번 full scan을 하므로 TPS : 25, MTT : 12초 라는 최악의 성능을 보여준다.**

* **수정후 부하테스트 진행 -> 결과 꼭 기록(+사진)**

  * **시나리오3-2**

    * **`create index idx_member_id_lists_date on LISTS(MEMBER_ID, LISTS_DATE);` 인덱스 생성**

    * 아무리 서브쿼리를 사용하려고 한다고 해도 "컬렉션 페치조인" 이다보니 적용을 못하겠음

    * ```
      // h2 db
      set cache_size 0;
      explain analyze select * from (select l.* from lists l where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-16' and MEMBER_ID = 1) l;
      select * from (select l.* from lists l where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-16' and MEMBER_ID = 1) l;
      ```

  * **시나리오4**

    * **`create index idx_member_id on member(member_id desc);` 로 인덱스 생성할 것!**

      * 해당 Index를 사용하기 위해서는 JPQL을 수정해야 한다!! - 서브쿼리 사용

      * JPQL로 서브쿼리는 from절에 사용불가하므로 이땐 네이티브쿼리 쓸수밖에

      * **핵심은 Index 사용하는 부분을 "서브쿼리"로 가져와 나머지 JOIN**

      * **이때, JOIN들도 외래키로 등록된 Index 를 통해 빠르게 조회**

      * ```java
        return em.createNativeQuery("select m.member_id, m.nickname, e.level " +
                                    "from (select * from member order by member_id desc limit "+offset+","+limit+") m " +
                                    "inner join character c on m.character_id=c.character_id " +
                                    "inner join exp e on c.exp_id=e.exp_id;")
            .getResultList();
        ```

        ```
        // h2 db
        select m.member_id, m.nickname, e.level from (select * from member order by member_id desc limit 0,10) m inner join character c on m.character_id=c.character_id inner join exp e on c.exp_id=e.exp_id;
        ```

    * **일정 주기마다 데이터 캐싱초기화 - 스케줄링 사용(30분 주기로 설정) + "회원가입 로직 수정"**

      * 회원가입 로직에서 캐싱 초기화 함수 제거
      * 30분마다 실행하는 스케줄링 추가

* **적절한 캐시 크기 결과 - 시나리오4**

  * 캐시 100 ? 캐시 1000 ? 막 극적으로 변하진 않고,
  * 또한 테스트하면서 느꼈는데 중복사용해야 캐시가 효과적이다.
  * 그렇다면,, 제일 많이사용하는곳은?? 당연히 앞쪽 페이지이다!
  * **결론 : 캐시 10~50정도로 적게 사용하자.**

* **성능비교 결과**

  * **h2 db**
    * 시나리오3 : 10ms -> 6ms
    * 시나리오4 : 80ms -> 3ms
  * **부하테스트 API**
    * 시나리오3 : XXXX 여긴 안하겠다. -> 손을못대겠음 ㅜ
    * 시나리오4 : 100배정도 개선

<br><br>

## 23-11-21 (sql 쿼리튜닝)

**시나리오3, 4 관련 성능개선을 먼저 해보겠다.**

* 시나리오3, 4 : 쿼리튜닝
* 이후 부하테스트를 통해 **성능개선 확인 및 시나리오4 의 적절한 캐시크기 찾기**

<br>

**시나리오3 : 쿼리튜닝**

* **적용해볼 쿼리튜닝은?? (앞서 정리한 내용들만 체크해보겠다.)**
  
  * 페이징 - 사용하지 않는다. 전체 데이터가 필요하기 때문
  * N+1문제 - join fetch로 해결된 상태
  * **Index 사용 - 적용해보겠다.**
    * 가급적 where 조건에는 Index 컬럼 모두 사용 -> 가급적 "=" 연산 사용(LIKE 같은것은 효율X)
  * UPDATE 대신 CASE 문 사용, 배치 모드로 Delete, Update 작업 - 조회라서 PASS
  * OR 보다는 AND 사용 - AND 사용중
  * 전체범위 처리, 부분범위 처리 - Index로 열심히 처리해보겠음
  * **distinct 는 가급적 사용X (내부적으로 정렬연산 발생하기 때문) - 가능한지 적용해보겠다.**
  
* **(1) index를 적용할만 한가?**

  * lists 테이블 특성상 lists_date 컬럼은 수정, 삭제가 거의 없다. 
  * 또한, lists_date를 where 절에서 항상 사용중이다.
  * 따라서 충분히 적용할만 하다.

* **테스트할 내용**

  * where문에 lists_date 와 memberId 를 index로 사용중이고,  
    memberId의 경우 외래키이기 때문에 외래키index가 존재해서 자동으로 사용중이다.  
    다만, lists_date + memberId 인 복합 index를 사용중인건 아니기 때문에 속도비교를 해보자
  * **3가지 테스트 : 외래키index / {lists_date, memberId} index / {lists_date, memberId} index**
  * **테스트 쿼리 : `select * from LISTS where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-18' and MEMBER_ID = 1;`**
    * 참고로 **6000개의 데이터** 존재
      * **11-17일자 1000개, 11-20일자 1000개, 11-21일자 1000개, 11-22일자 1000개, 11-23일자 1000개, 11-24일자 1000개 -> memberId = 1** 해당
      * 또한 총 member는 5만, lists도 5만6천개 정도 데이터가 존재중

* **(1-1) 외래키index**

  * 6ms / scanCount: 6002

  * scanCount가 6000개인건 memberId=1의 lists데이터가 6000개이기 때문

  * 따라서 member외래키 index로 바로 찾아가서 lists데이터 6000개를 전체 스캔

    ```
    explain analyze select * from "PUBLIC"."LISTS" use index (FKMRA2MVJOG7I44UKBKTJY3JIDL_INDEX_4) where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-18' and MEMBER_ID = 1;
    SET CACHE_SIZE 0;
    select * from "PUBLIC"."LISTS" use index (FKMRA2MVJOG7I44UKBKTJY3JIDL_INDEX_4) where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-18' and MEMBER_ID = 1;
    explain analyze select * from lists where member_id = 2;
    explain analyze select * from lists where member_id = 1;
    ```

    * 아래 explain 2줄은 확인용일 뿐

* **(1-2) {lists_date, memberId} index**

  * 17ms / scanCount: 50074 / reads: 2176

  * scanCount가 약 50000개인건 lists_date의 17일자 까지 데이터수는 약 50000개 이기 때문

  * member보다 lists가 보통 충분히 많으며, 여기서는 lists를 먼저 scan했기 때문에 이렇게 성능이 안좋게 나오는 것이다.

    ```
    explain analyze select * from "PUBLIC"."LISTS" use index (idx_lists_date_member_id) where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-18' and MEMBER_ID = 1;
    SET CACHE_SIZE 0;
    select * from "PUBLIC"."LISTS" use index (idx_lists_date_member_id) where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-18' and MEMBER_ID = 1;
    ```

* **(1-3) {memberId, lists_date} index**

  * 3ms / scanCount: 1002/ reads: 46

  * scanCount가 약 1000개 인건 index 덕분에 11-18일자 1000개 데이터를 바로 가져왔기 때문

    ```
    explain analyze select * from "PUBLIC"."LISTS" use index (idx_member_id_lists_date) where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-18' and MEMBER_ID = 1;
    SET CACHE_SIZE 0;
    select * from "PUBLIC"."LISTS" use index (idx_idx_member_id_lists_date) where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-18' and MEMBER_ID = 1;
    ```

* **(2) distinct 제거가능한가?**

  * lists와 tasks 는 1:N의 관계를 가지므로 fetch join시 "중복"존재
    * 데이터 뻥튀기 때문에 페이징도 불가 -> batch size로 해결해야함.
  * **1:1, N:1의** 관계의 경우 fetch join해도 데이터 뻥튀기 안되므로 "중복"없다고 볼 수 있음
    * 데이터 뻥튀기 없으니 페이징도 가능
    * **이 경우엔 전부 distinct 제거해도 될 듯?!**
  * 다만, 현재 시나리오3의 쿼리는 **1:N인** 컬렉션을 fetch join한 상태므로 "중복"존재
    * 일반 sql에 distinct는 db단에서 완전 동일한 중복을 제거하지만, jpql의 distinct는 일반 sql처럼 동작 + 앱에서도 중복 제거를 시도
    * **jpql의 특징때문에 오히려 쓰는게 좋다고 생각한다.**

* **정리**

  * **복합 index의 경우 컬럼의 순서가 매우 중요**함을 알 수 있다.
    * 실제로, lists_date컬럼이 먼저온 index의 경우 자동 생성되는 외래키 index가 훨씬 성능이 좋았다.
  * **제일 좋은것은 (3) {memberId, lists_date} index** 였으며 기존보다 **2배 성능**이 좋아졌다.
    * 외래키의 Index를 사용하고 있었기에 드라마틱하게 변할 쿼리문은 아니였다.
    * 다만, Index가 필요한데 사용안하고 있는 쿼리문이 있다면 성능을 6~10배는 올릴수 있겠다고 예상된다.
  * **1:N인 컬렉션 join fetch 이므로 distinct는 그대로 사용하겠다.**
    * 물론, distinct 자체를 사용하게 db설계를 했다는것은 db설계를 효율적이지 않게 설계했다고도 하는데 그렇게 딥하게 생각하지는 않겠다.

* **결론**

  * **`create index idx_member_id_lists_date on LISTS(MEMBER_ID, LISTS_DATE);` 로 인덱스 생성할것!**

<br>

**시나리오4 : 쿼리튜닝 + 캐시에 스케줄링!**

* **적용해볼 쿼리튜닝은?? (앞서 정리한 내용들만 체크해보겠다.)**

  * 페이징 - 사용중이다!! 여기선 필수로 사용할 것이다.
  * N+1문제 - join fetch로 해결된 상태
  * **Index 사용 - 외래키만 쓰면될듯해서 딱히.. 사용안할듯 하다.?**
    * 가급적 where 조건에는 Index 컬럼 모두 사용 -> 가급적 "=" 연산 사용(LIKE 같은것은 효율X)
  * UPDATE 대신 CASE 문 사용, 배치 모드로 Delete, Update 작업 - 조회라서 PASS
  * OR 보다는 AND 사용 - 아예 사용X
  * 전체범위 처리, 부분범위 처리 - 딱히 할게 없을듯?
  * distinct 는 가급적 사용X (내부적으로 정렬연산 발생하기 때문) - 사용안함

* **(1) Index..? 사용할만한가?? 페이징?? 고민**

  * 처음에는 OFFSET을 아예안쓰는 NO OFFSET 방식을 진행하려 했으나,
  * id를 기준 "최신순"으로 보여주고 있어서 해당방식은 id하나 삭제시 "순번이 망가진다."
  * 따라서 "커버링 인덱스" 라고 하여 Index 사용한 채 OFFSET 을 진행하려 했는데,
  * 레벨은 자주 변하는 컬럼이다보니 별루인듯 하다고 생각한다.
  * **제일 좋은건 멤버id기준 desc 정렬인 index를 사용하는게 좋아보인다.**
    * 실제로, 기존 쿼리의 문제는 매순간 order by 정렬의 문제... 즉, full scan의 문제..라 생각

* **테스트할 내용**

  * 새로 생성한 index 와 현재 상태 비교
  * **테스트 쿼리 : `select * from member m inner join character c on m.character_id=c.character_id order by m.member_id desc limit 10000,5;`**
  * 멤버 데이터 참고로 **5만개**정도 있음

* **(1-1) 기존 실행?**

  * 50ms / scanCount: 98146

  * scanCount가 약 10만개인건 join 때문인지 member 5만개, character 5만개 데이터 읽은거라 예상

  * order by 때문에 "전체범위 처리"이므로 기존 offset 1만을 읽는것도 문제지만 전체 5만을 다 읽는 더 큰 문제가 발생..

    ```
    explain analyze select * from member m inner join character c on m.character_id=c.character_id order by m.member_id desc limit 10000,5;
    SET CACHE_SIZE 0;
    select * from member m inner join character c on m.character_id=c.character_id order by m.member_id desc limit 10000,5;
    ```

* **(1-2) 새로운 Index?**

  * 12ms / scanCount: 20009 / index sorted

    * 신기하게 index sorted 라고 정렬된 index 사용한것을 알려준다.

  * scanCount가 약 2만개 인건 order by가 이미 적용된 index를 사용하게 되기 때문!

  * 따라서 기존 OFFSET의 문제인 해당 자리까지 데이터 읽는것 때문에 2만개일 뿐!

    * sql문에 offset 1만개로 설정되어 있기에 member 1만개, character 1만개 읽은 걸로 예상

  * `create index idx_member_id on member(member_id desc);`

  * `drop index idx_member_id on member;` 는 삭제

    ```
    explain analyze select * from member m inner join character c on m.character_id=c.character_id order by m.member_id desc limit 10000,5;
    SET CACHE_SIZE 0;
    select * from member m inner join character c on m.character_id=c.character_id order by m.member_id desc limit 10000,5;
    ```

    * **`order by member_id desc` 가 있으니 자동으로 index 사용**

* **(2) 캐시에 스케줄링은??**

  * **[랭킹시스템 DB](https://www.inven.co.kr/webzine/news/?news=265156)**
    * 시나리오4 가 사용자들을 조회하다보니 캐싱방식이 궁금했는데 해당사이트가 잘 정리되어있다.
    * **일정 주기마다 데이터 캐싱초기화! - 스케줄링 사용하자**
      * 대충 30분 주기로 설정하면 충분할듯
    * **따라서 현재 "회원가입" 때 캐시 제거를 했기때문에 이거 주석처리 해야한다.**

* **정리**

  * order by 한 index를 사용한 경우 거의 5배 가까이 성능이 개선되었다.
    * 물론 OFFSET의 문제는 가져가긴 하지만,
    * 제일 큰 문제인 매번 조회마다 "order by desc" 실행을 해결한것이 큰 이득이다.
  * 실제로 캐시를 사용하기에 좋은 API이기 때문에 반드시 적용할 생각이고, 데이터의 변경을 위한 캐시 갱신을 "스케줄링" 을 통해서 하자.

* **결론**

  * **`create index idx_member_id on member(member_id desc);` 로 인덱스 생성할 것!**
  * **일정 주기마다 데이터 캐싱초기화 - 스케줄링 사용(30분 주기로 설정) + "회원가입 로직 수정"** 

<br>

```
// h2에 사용.. 명령어들..

explain analyze select * from member m inner join character c on m.character_id=c.character_id limit 10000,5;
SET CACHE_SIZE 0;
select * from member m inner join character c on m.character_id=c.character_id limit 10000,5;

explain analyze select * from member limit 1000,5;
SET CACHE_SIZE 0;
select * from member limit 1000,5;


explain analyze select * from "PUBLIC"."LISTS" use index (FKMRA2MVJOG7I44UKBKTJY3JIDL_INDEX_4) where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-18' and MEMBER_ID = 1;
SET CACHE_SIZE 0;
select * from "PUBLIC"."LISTS" use index (FKMRA2MVJOG7I44UKBKTJY3JIDL_INDEX_4) where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-18' and MEMBER_ID = 1;
explain analyze select * from lists where member_id = 2;
explain analyze select * from lists where member_id = 1;

explain analyze select * from "PUBLIC"."LISTS" use index (lists_date_member_id) where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-18' and MEMBER_ID = 1;
SET CACHE_SIZE 0;
select * from "PUBLIC"."LISTS" use index (lists_date_member_id) where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-18' and MEMBER_ID = 1;

explain analyze select * from "PUBLIC"."LISTS" use index (idx_idx_member_id_lists_date) where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-18' and MEMBER_ID = 1;
SET CACHE_SIZE 0;
select * from "PUBLIC"."LISTS" use index (idx_member_id_lists_date) where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-18' and MEMBER_ID = 1;
```

<br><br>

## 23-11-20 (부하테스트, 쿼리튜닝 정리) + 할일

**어떻게 프로젝트에 적용할지 개념과 방법을 정리해보겠다.**

**1. 부하테스트??**

* `성능 테스트, 스트레스 테스트, 부하 테스트` 를 먼저 알아야 한다.
  * 성능 테스트가 제일 큰 개념 - 하위에 스트레스, 부하 테스트가 존재
    * 성능 테스트는 "임계치 이전, 초과" 모두 테스트
      * 앱 성능의 벤치마크(=성능 측정과 비교)와 표준을 설정하는 목적
    * **부하 테스트는 "임계치 이전" 까지 테스트**  
      * **과부하 데이터를 처리하는 방법을 확인 목적**
    * 스트레스 테스트는 "임계치 초과" 하며 테스트   
      * 임계치 초과니까 시스템 과부하에서의 작동방식, 장애복구 방식 등을 알아내는 목적
  * **[주요 차이점 - 성능, 스트레스, 부하 테스트](https://seongwon.dev/ETC/20220919-%EC%84%B1%EB%8A%A5%ED%85%8C%EC%8A%A4%ED%8A%B8-%EB%B6%80%ED%95%98%ED%85%8C%EC%8A%A4%ED%8A%B8-%EC%8A%A4%ED%8A%B8%EB%A0%88%EC%8A%A4%ED%85%8C%EC%8A%A4%ED%8A%B8%EB%9E%80/)**
* **"부하테스트 목적" : 시스템의 상한선을 식별하려면 앱의 SLA를 설정하고 시스템이 과부하 볼륨을 처리하는 방법을 확인한다.**
  * 즉, `volume test` 라고도 하며, `volume` 은 대량의 데이터를 의미
  * `SLA` 란 Service Level Agreement(서비스 수준 협약)
    * 자세히 알아보면 훨씬 방대한 내용을 가진다.
    * 지금 알아둘 수준은 **"제공할 서비스 수준"**이라고 볼 수 있다.
* **"부하테스트 도구" -> nGrinder 사용**
* 자세한 테스트 과정들은 `23-11-13 ~` 에 내용 참고

<br>

**1. 쿼리튜닝??**

* 쿼리튜닝은 서버 최적화처럼 **DB 성능개선을 위해 SQL 최적화**를 하는것이라 볼 수 있다.

* **`페이징, N+1 해결(=쿼리수 줄이기=적절한 JOIN사용=ORM의 문제 해결), Index 사용(단일 or 복합), db캐시(물론 db캐시는 안쓰고 서버,웹 캐시만 사용할 예정)` 전부 해당**한다고 생각한다.
  
  * 특히, 방법들이 다양하게 많다. - 자료첨부
    * **[더 빠른 SQL 쿼리를 위한 21가지 데이터베이스 튜닝 규칙](https://www.itworld.co.kr/tags/2665/SQL/105792?page=0,0)**
    * **[추가적인 튜닝 규칙](https://velog.io/@gillog/SQL-%ED%8A%9C%EB%8B%9D#%EC%B6%94%EA%B0%80%EC%A0%81%EC%9D%B8-%ED%8A%9C%EB%8B%9D-%EA%B7%9C%EC%B9%99)**
    * **[DB전문가의 TIP - Youtube](https://youtu.be/qY-nOOX_Smc?si=28sjP31btwGLlcDM)**
  
* **그렇다면, 적용해볼 쿼리튜닝 방식들은??**
  
  * **"전체범위 처리", "부분범위 처리"**
  
    * **좀 포괄적인 개념이다. Index도 포함 할 수 있고,, 기본적으로 인지해야할 부분이다.**
  
    * 전체범위 처리 예시 : `select * from 테이블 order by asc`
  
      * order by, count함수 등
  
      - Full Range Scan과 다를바 없다.
  
    * 부분범위 처리 예시 : `select * from 테이블`
  
      - Index를 타서 그부분만 읽던지, order by가 없던지 등
      - `select * from 테이블`은 데이터 처리하는 입장에서보면 테이블을 한바퀴 스캔할 필요없이 그냥 바로 테이블에 있는 데이터를 보여주면 되기 때문에 "부분범위 처리"
  
    * 참고 : **[전체vs부분범위 처리](https://kjw1313.tistory.com/m/96)**
  
  * Not 조건의 중요성 - “아니다”란 조건이 있으면 맞다는 조건을 찾을것
  
  * 페이징, N+1 해결(ORM의 문제로 발생)
  
  * UPDATE 대신 CASE 문 사용, 배치 모드로 Delete, Update 작업
  
  * OR 보다는 AND 사용, distinct 는 가급적 사용X (내부적으로 정렬연산 발생하기 때문)
  
  * 가급적 where 조건에는 Index 컬럼 모두 사용 -> 가급적 "=" 연산 사용(LIKE 같은것은 효율X)
    * `CHECKPOINT;` : db 버퍼 캐시 비우기 -> 테스트시 반드시 필수로 사용
    * `SET CACHE_SIZE 0;` : checkpoint 보다 이게 확실한 방법 (캐시 지우기)
      * 공식문서 한참 뒤지니까 나옴
    * `explain` : 반드시 사용해서 index 적용여부 확인
    * `use index` : index가 원하는대로 적용되지 않으면 직접 설정하라(방법은 다양함)
    * 참고로 예상이 안가면 할 수 있는 Index 를 다 적용해서 성능비교를 해보자
      * **필수 세팅 : "데이터 세팅(실제처럼)" + "SET CACHE_SIZE 0;(캐시비우기)"**
      * **예시로 `단일index, 복합index(컬럼순서중요), index사용X` 를 성능비교 해볼 수 있겠다.**
  
  * 다양한 예시들
    * [**DB의 페이지네이션을 어떻게 최적화-이해하기 좋음**](https://taegyunwoo.github.io/tech/Tech_DBPagination#limit-offset-%EB%B0%A9%EC%8B%9D%EC%9D%98-%EB%AC%B8%EC%A0%9C%EC%A0%90) : Index의 개념도 포함되어 있다.
    * **[SQL 튜닝 여러가지 방식](https://chung-develop.tistory.com/145)**
  
* **추가정보1) 발견한 특징??**

  * h2는 `explain analyze` 를 사용해야 rows 까지 확인 가능
  * Index에 사용한 컬럼 정보는 h2웹에서 직접 확인 가능
  * mysql의 `show index` 대신할 명령어 -> index 정보확인
    * `SELECT * FROM INFORMATION_SCHEMA.INDEXES WHERE TABLE_NAME = 'LISTS';`
  * 그냥 컬럼 정보는?
    * `SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = 'LISTS';`
  * 특히 "외래키 매핑" 하면 "**자동**으로 해당 외래키와 현재키 매핑한 Index 생성"
  * h2 db테스트 할때 처음 db connection 에 제일 많은 시간이 소요
    * 이는 db connection pool 기법을 활용해서 개선가능 (나중에 다룰 문제)
  * db connection 이후엔 캐시를 고려해야 함
    * 캐시를 제거안해주면, 정확한 속도 측정이 어려우므로 꼭 캐시 제거하면서 테스트하자
  * h2에 "최대 행 수" 부분을 전체로 해줘야 limit 설정을 적용하기 쉬우니 이부분도 체크

* **추가정보2) Index 사용 주의점**
  1. 인덱스는 **열 단위에 생성**
  2. 인덱스는 **WHERE 절에서 사용되는 열에 생성**
  3. WHERE 절에 사용되는 열이라도 자주 사용해야 가치가 있음
  4. 데이터 중복도가 높은 열에는 인덱스를 만들어도 효과가 없음 (선택도가 높은 경우는 효과 없음)
  5. **외래키를 설정한 열**에는 **자동으로 외래키 인덱스가 생성**됨
  6. **조인에 자주 사용되는 열**에는 인덱스를 생성하는 것이 좋음
  7. **데이터 변경(삽입, 수정, 삭제) 작업이 얼마나 자주 일어나는지 고려**해야 함
  8. 단일 테이블에 인덱스가 많으면 속도가 느려질 수있다. (**테이블당 4~5개 권장**)
  9. **클러스터형 인덱스는 테이블당 하나만** 생성할 수 있음
  10. 테이블에 클러스터형 인덱스가 아예 없는 것이 좋은 경우도 있음
  11. 사용하지 않는 인덱스는 제거
  12. 복합 인덱스는 **WHERE절에서 OR조건이 아니라 AND 조건일 때** 사용하는 것이 좋음
  13. [복합 인덱스의 컬럼 순서 결정법](https://khdscor.tistory.com/51)

* 자세한 테스트 과정들은 `23-11-17 or 23-11-21` 에 내용 참고

<br>

**그래서 뭐를 진행할까?**

* 앞서 진행한 부하테스트 **시나리오1,3,4**의 **부족한 부분 개선** -> 시나리오5는 나중에 생각
  * 시나리오1 : 예외처리 -> 마지막에 리팩토링할때 ㄱㄱ(검증, API예외처리 할 생각)
  * 시나리오3 : 쿼리튜닝
  * 시나리오4 : 적절한 캐시크기 찾기 & 쿼리튜닝
  * 여기서 언급한 **쿼리튜닝** 은?
    * 페이징, N+1 해결(=쿼리수 줄이기=적절한 JOIN사용=ORM의 문제 해결), Index 사용(단일 or 복합), db캐시(물론 db캐시는 안쓰고 서버,웹 캐시만 사용할 예정) 등등 전부 해당
* 모니터링
  * 모니터링 : 프로메테우스, 그라파나, 액츄에이터 사용
  * 인프런 강의에서 본 내용 그대로 따라할 예정 -> 그래서 금방 할 수 있을듯
* 배포자동화 - CI/CD (지속적 통합과 배포) -> 필수는 아닌데 하고싶음
  * 깃헙액션 쉬움, 젠킨스 복잡 -> 따라서 깃헙 액션으로 구성
* 마지막 refactor -> 검증 + 예외처리는 꼭 경험해야한다고 생각
  * valid, exception : 검증 과 API예외처리
* 솔직히 시간만 있으면 "도커"로 서버 구성하여 "배포"까지 할 생각

<br><br>

## 23-11-17 (쿼리튜닝 맛보기)

**시나리오 1~4 의 결론 -> 처리할차례(튜닝먼저도전!!)**

* 시나리오 1에서는 **예외처리**! -> 나중에 리팩토링할떄 ㄱ

* 시나리오 2에서는 **페이징** & 캐시(X 이건 프론트에서!) -> 일단 pass

  * 금일, 이번달, 이번년도, 전체년도... 생각해보면 그냥 시나리오3 밖에 안쓸듯?
  * 시나리오2는 일단 놔두자.

* 시나리오 3에서는 **(1)쿼리튜닝 & 페이징** & 캐시(X 이건 프론트에서!) -> 쿼리튜닝만 ㄱㄱ
  * 인덱스 쿼리튜닝 https://jie0025.tistory.com/509, https://leezzangmin.tistory.com/42, https://taegyunwoo.github.io/tech/Tech_DBPagination#limit-offset-%EB%B0%A9%EC%8B%9D%EC%9D%98-%EB%AC%B8%EC%A0%9C%EC%A0%90
  
  * 날짜를 매번 전체 비교하기 때문에 쿼리수정이 필요함을 느낌 -> "전체범위처리"
  
  * 솔직히 날짜로 분류했다 생각해서 일정 다가져와야하니 페이징은 필요없을듯?
  
  * =>> 인덱스 그래도 적용해보자.
  
  * **기존 속도 확인! -> offset 문제는 없다는점 참고**
    
    * **h2db :** `select * from LISTS where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-14' limit 10;`  
      => 테스트하기 쉽게 limit 10으로 (데이터10개) 비교하겠음  
      => 또한, 다른날짜 데이터가 많아야 속도 비교가 됨
      * 76ms -> explain 찍어보면 전체 테이블 스캔도 하고있음
      * id컬럼은 index존재한다지만 lists_date를 확인해보면 없음
    
  * **인덱스 테이블 추가 꼬꼬**
    
    * NO OFFSET으로 계속하고 인덱스를 추가하면 좋을듯! -> 쿼리튜닝!
    
    * `create index lists_date_index on LISTS(LISTS_DATE);`
      
      * `explain select lists_date from lists;` 입력시 index 사용을 확인가능
      
    * `select * from LISTS where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-14' limit 10;`
      
      * 4ms -> explain 찍어보면 index 사용중!
      
    * memberId 조건문 추가해보자 (이게 원래 사용중인 조건)
      * `select * from LISTS where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-14' and MEMBER_ID = 1 limit 10;`
      
      * 이 또한 4ms로 인덱스 바로 적용됨을 확인(아마 member외래키때매 자동으로 인덱스 추가되는게 있는듯?)
      
      * 단, 이렇게되면 lists_date 인덱스가 필요하긴 한건지 모르겠음..
      
      * memberId =1 로하고 lists가 진짜 수천개 가진 데이터에 테스트해봐야할듯  
        -> 1000개 데이터 생성해봤음
        
        * `select * from LISTS where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-16' and MEMBER_ID = 1 limit 100;`
          
          * 13ms index추가전후 그냥 비슷..
          
          * 이미 외래키등록하면서 자동으로 뭔가 인덱스가 다 되어있나보다
          
            * 진짜 그런것같음 -> gpt는 맞다고 함 ㅇㅇ. 자동으로 인덱스 생성한다함.
          
            * h2 디비에선 show index... 명령어 못쓰니까 아래명령어 사용
          
            * ```
              1. explain 함수 사용 -> 외래키 index 사용 뜸
              explain select * from lists where lists_date = '2021-02-01' and member_id = 1;
              
              2. show index 대신할 명령어임 - index 정보 볼 수 있다.
              => 단, h2의 경우 무슨열의 index 인지 자세한건 직접 웹으로 확인!!
              SELECT * FROM INFORMATION_SCHEMA.INDEXES WHERE TABLE_NAME = 'LISTS';
              SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = 'LISTS';
              
              3. 무슨 index 사용할지 hint를 주는방법으로 사용하게 가능!!! 찾았네
              explain SELECT * FROM "PUBLIC"."LISTS" USE INDEX (idx_lists_date_member_id) WHERE "LISTS_DATE" = TIMESTAMP '2021-02-01 00:00:00' AND "MEMBER_ID" = CAST(1 AS BIGINT);
              ```
          
          * 흠.. 근데 아무리생각해도 여긴 패스하긴 해야할듯 -> 일단 다시 도전
          
            * 추측이지만 memberId 관련 외래키 index쪽에서 한번에 해당 member주소 찾아서! lists와 memberId 로 뭔가 있을듯?? 그래서 바로 lists 정보 들어가서
            * lists_date index가 있는거마냥 빠르게 동작될듯한데? ㄹㅇ
            * 다만 lists가 굉장히많다면?? memberId와 연관된 lists는 바로 찾았다고 해도
            * 해당 lists의 lists_date를 찾는과정에선 여전히 index 없는거나 마찬가지라 생각
            * 따라서 굳이 수정하고 싶다면 외래키 등록때 자동으로 index 만들어지는 부분에 lists_date를 추가로 넣어야 할듯?
          
          * **그래서 lists_date, member_id 두개 열로 구성한 복합 index를 만들어 사용해서**
          
          * **기존과 속도비교 해보겠다!**
          
            * 23ms vs 2ms => 충분히 더 빠른듯! => 근데 캐시되어서 이럴수도 있으니 다시확인해보자.
            
            * ```
              SELECT * FROM "PUBLIC"."LISTS" USE INDEX (idx_lists_date_member_id) WHERE "LISTS_DATE" = TIMESTAMP '2021-02-01 00:00:00' AND "MEMBER_ID" = CAST(1 AS BIGINT);
              SELECT * FROM "PUBLIC"."LISTS" USE INDEX (idx_lists_date_member_id2) WHERE "LISTS_DATE" = TIMESTAMP '2021-02-01 00:00:00' AND "MEMBER_ID" = CAST(1 AS BIGINT);
              select * from lists where lists_date = '2021-02-01' and member_id = 1;
              ```
            
            * 음? 캐시때문이었던거같음.. 속도 차이없는디
            
            * 아니 대체 왜없음? 속도차이 나야 정상아닌가? 
            
            * **현재 3개 index 비교중인데 데이터 좀 많이 넣고 테스트해보겠음..**
  
* 시나리오 4에서는 **수정... (1)캐시크기제한? & (2)쿼리튜닝**

  * 쿼리튜닝으로써 페이징으로 인한 limit offset의 의미없는 I/O는 없는지?? -> 존재

  * 잠시 캐시 제거후 **데이터... 3만개로... 확인.**..  
    **참고) 조회하면 버퍼캐시에 기록하므로 h2 db도 재접속하면서 테스트 할것**

    * **h2db : `select * from MEMBER limit 1, 10;` -> 4ms**
      * `select * from MEMBER limit 30000, 10;` -> 54ms
      * 속도차이는 limit offset 의 특징 때문! -> 30000까지 **데이터 스캔**

    * **스프링(처음 "db커넥트시간 제외") : pageId가 1일때 -> 21, 6ms**  
      (참고) 스프링과 db사이의 db커넥트시간도 따로 존재함을 인지! -> 그래서 db커넥션풀 존재
      * pageId가 3000일때 -> 129, 119ms
      * "실행계획"을 보면 스캔볼 수 있음 -> EXPLAIN 을 sql문 앞에 작성하면 볼 수 있음

  * **참고 : "실행계획" 예시들 -> 데이터 스캔과 인덱스 유무 체크 간단!**

    * `explain select uid from MEMBER;`

      ```sql
      PLAN  
      SELECT
          "UID"
      FROM "PUBLIC"."MEMBER"
          /* PUBLIC.MEMBER.tableScan */
      ```

    * `explain select member_id from MEMBER;`

      ```sql
      PLAN  
      SELECT
          "MEMBER_ID"
      FROM "PUBLIC"."MEMBER"
          /* PUBLIC.CONSTRAINT_INDEX_8 */
      ```

  * 생각해볼만한건 **NO OFFSET(인덱스사용) or 커버링 인덱스**

    * 물론, 잘 생각해보면 NO OFFSET 방식이든뭐든... 값 삭제되면.... 풀스캔 필요할듯

    * **잦은 인덱스 수정은 오히려 성능 다운 -> 이부분 조심!**
    * **이 또한 전부 인덱스 쿼리튜닝의 일종이라 생각**

  * **NO OFFSET(=커서 기반 페이징 방식)** 

    * 페이징 대신 where , id 조합 ㄲ -> id는 기본적으로 인덱스 컬럼 있을 
    * **`select * from MEMBER where member_id > 30000 limit 10;` -> 4ms !!**
      * **성능개선 : 기존 54ms에서 4ms로 성공**

  * **커버링 인덱스 : 쿼리에 사용되는 모든 칼럼을 가지고 있는 인덱스를 의미**  
    => 이는 인덱스에서 조회가 끝나는것이 가능하기에 성능개선이 가능하다는 것  
    => OFFSET을 계속 사용해야할 경우? n번째의 데이터를 얻고싶을때라 볼 수 있음

    * [**제일 이해하기 좋은듯 - DB의 페이지네이션을 어떻게 최적화**](https://taegyunwoo.github.io/tech/Tech_DBPagination#limit-offset-%EB%B0%A9%EC%8B%9D%EC%9D%98-%EB%AC%B8%EC%A0%9C%EC%A0%90)
    * 성능은 NO OFFSET이 훨씬 좋고, 커버링 인덱스는 굳이 `OFFSET` 을 사용할거라면! 사용!

  * **쿼리튜닝 결론 : NO OFFSET 이 유력**

    * Member 의 id 인덱스만 있으면 충분! id 컬럼은 특히 수정 안함!
    * 단, id 삭제의 경우는 ????? 문제인데????????
      * id가 중간에빠지면 기존엔 전부 스캔하기에 offset, limit가 정상인데
      * NO OFFSET은 where id > 30000 limit 10 이런식인데.. 30000이 문제.....
      * 1 2 3 4 5 6 7 8 10 11 12 13 14 15 16 17 18 19 20
      * 1 2 3 4 5 6 7 8 10 11 : pageId=0*10
      * 11 12 13 14 15 16 17 18 19 20 : pageId=1*10
      * 11이 또 나온 문제..

    * id 삭제의 경우가 해결이 안된다면 포기하고 캐시만 해야할듯 -> 포기
    * 커버링 인덱스를 적용해봤자 level같은 정보들이 자주 변경되므로 좋지가 않다고 생각

  * **찐 결론 : 커버링 인덱스나 NO OFFSET 사용하지말자, 캐시만 사용!**

    * **아니다 "커버링 인덱스"는 그래도 한번 해보자. 좋을수도??**

  * **캐시 사이즈 설정**
  
    * 캐시매니저 생성 후 "cacheNames = ..." 로 추가하겠음 (그래야 연동되는듯)
    * 캐시매니저에서 캐시크기 설정 : 100으로 일단 설정하고 몇개 페이지기록이 나을지는 부하테스트를 진행한 후 결정하겠음
    * `implementation 'com.github.ben-manes.caffeine:caffeine:3.1.1'`


<br>

**할일**

* 캐시매니저에서 캐시크기 설정 : 100으로 일단 설정하고 몇개 페이지기록이 나을지는 부하테스트를 진행한 후 결정하겠음
* 쿼리튜닝 할게없는것같음. 공부한것에 만족하겠음. -> 다시 찾아보겠음.
* mysql 쓸지도 고민. -> explain 에 rows 가져온 숫자까지 보여줫. h2는 안보여주는듯. 안보임
  * 방법을 찾았따. 역시 공식문서를 직접 찾아봐야겠네

* 이후에 모니터링 추가 및 시나리오5 도 해결

<br><br>

## 23-11-13 ~ 23-11-16 (부하테스트 첫시도)

* 테스트를 위한 코드는 구현 코드에서 분리되어야 한다.   
  =>"테스트를 위해 접근 제어자를 바꾸는 경우, 테스트 코드에서만 사용되는 메서드"
* **테스트 툴(부하테스트공부) -> 할차례**
  * **nGrinder(네이버 오픈소스) - 부하테스트**
    * 작성한 API 에 **병목 현상**과 얼마 만큼의 **트래픽을 수용**할 수 있는지에 대한 여부를 확인하고자 스트레스 테스트를 작성한다.
    * 아마 이 부하테스트를 통해서 api 장애 개선을 진행할 것이고,
    * 쿼리튜닝도 여기서 시도해보지 않을까 예상됨
  * **nGrinder 설치**
    * download nGrinder + agent 
    * nGrinder 실행 : `java -jar ngrinder-controller-{version}.war --port=8300`
    * agent 실행시 `run_agent.bat` 으로 실행성공..
    * Groovy(언어)는 JUnit 기반 동작. 자바처럼 JVM에서 동작
    * **Java 1.8과 11버전을 지원하므로 nGrinder+agent 실행할 때 꼭 유의!**
      * 이거때문에 **cmd**로 실행했음 (예전에 자바버전 쉽게변경하게 세팅해뒀어서)
      * **반드시 nGrinder와 agent 둘다 Java 1.8 or 11 로 해야함**
      * 포트 확인법(예:16001) : `telnet 127.0.0.1 16001`
    * **스크립트 생성 후 검증 테스트! -> 정상 동작**
    * **특히, 스크립트 오류찾을때 ngrinder 에서 제공하는 로그파일 확인**
    * **실제 시나리오(스크립트) 작성하여 "성능 테스트" 시작**
      * **실제 예상 시나리오 작성**해보겠음
  * **nGrinder 예상 시나리오 작성 -> 하는중!! (시나리오1 하는중)**
    * 예 : [회원가입]로그인 -> 장바구니에 상품 담기 -> 주문 순 등등
      * [참고](https://kirinman.tistory.com/m/102)
      * **한글!! 주의!! 인코딩 에러!! -> 그냥 영어로!! 하자!**
    * 보통 시나리오 단위테스트(+성능개선) -> 통합테스트(+성능개선) 순서대로 진행한다고함.
    * **시나리오1 : [회원가입] -> [로그인]**
      * @Test 로 전부 진행 -> **임의로 실행횟수 지정**해서 1000명 정도 테스트
      * 회원가입, 로그인을 각각 @Test 로 나눠서 스크립트 작성
    * **시나리오2-1 : [로그인] -> [일정 추가] -> [본인의 일정 전체조회]**
      * 임의로 실행횟수가 아닌 **"시간"** 을 설정
      * 이곳에 페이징이나 캐시 없어서 **일정 추가될수록** 아마 성능 안좋게 나올거로 예상
      * [로그인] : @BeforeProcess (uid:123 으로 로그인하겠음)
      * [일정 추가] -> [본인의 일정 전체조회] : @Test (나눠서 스크립트 작성)
    * **시나리오2-2 : [로그인] -> [본인의 일정 전체조회]**
      * 임의로 실행횟수가 아닌 **"시간"** 을 설정
      * 시나리오2-1 방식에서 "일정추가" 만 제외하고 vuser 대폭 키워서 테스트할 목적
      * 데이터 5천개 이상을 조회 가정 (시나리오2-1 실행시 이정도 추가됨!)
    * **시나리오3-1 : [로그인] -> [일정 추가] -> [본인의 해당 날짜 일정조회]**
      * 임의로 실행횟수가 아닌 **"시간"** 을 설정
      * [로그인] : @BeforeProcess (uid:1234 으로 로그인하겠음)
      * [일정 추가] -> [본인의 해당 날짜 일정조회] : @Test (나눠서 스크립트 작성)
    * **시나리오3-2 : [로그인] -> [본인의 해당 날짜 일정조회]**
      * 임의로 실행횟수가 아닌 **"시간"** 을 설정
      * 시나리오3-1 방식에서 "일정추가" 만 제외하고 vuser 대폭 키워서 테스트할 목적
      * 데이터 5천개 이상을 조회 가정 (시나리오3-1 실행시 이정도 추가됨!)
    * **시나리오4 : [전체 멤버 조회(팔로우에 보여줄)]**
      * 임의로 실행횟수가 아닌 **"시간"** 을 설정
      * 로그인 인증 필요없음 + 페이징 + 캐시 적용상태 -> 캐시때매 성능 좋게나올듯
      * pageId 25 제한으로 Member 250개 데이터 확인하게끔
      * [전체 멤버 조회] : @Test
    * **시나리오5~** : **캐릭터부분**... -> 모니터링 추가하고 이부분 추가 테스트 하겠음ㅇㅇ
  * **nGrinder 동작순서**
    * [참고](https://jerry92k.tistory.com/48)
    * @BeforeProcess -> @BeforeThread -> HTTP 요청 순서
    * @Before 의 경우 각각 @Test 실행전에 반복 실행
    * **개인적인 생각**
      * **(1)여러 사용자의 로그인이 필요없다면 로그인 로직을 @BeforeProcess**
        * EX) [회원가입] -> [로그인] -> [로그인필요한 페이지] 테스트의 경우?
        * **로그인필요한 페이지만을 테스트하려는 목적만 강하다면,**
        * [회원가입] -> [로그인] : @BeforeProcess
        * [로그인 필요한 페이지] : @Test
      * **(2)여러 사용자의 로그인이 필요하다면 @BeforeThread**
        * EX) [회원가입] -> [로그인] -> [로그인필요한 페이지] 테스트의 경우?
        * **여러 사용자의 회원가입이 중요하다면,**
        * [회원가입] -> [로그인] : @BeforeThread
          * 설정한 스레드수 만큼 회원가임+로그인 동작
        * [로그인 필요한 페이지] : @Test
          * 설정한 실행횟수 만큼 @Test 동작
      * **(3)로그인+로그인필요 사이트 테스트는 @Before**
        * EX) [회원가입] -> [로그인] -> [로그인필요한 페이지] 테스트의 경우?
        * **회원가입 + 로그인필요 사이트 둘다 중요하다면,**
        * [회원가입] -> [로그인] : @Before
          * "쿠키"를 static 으로 관리하다보니 @BeforeThread 에선 
          * Thread 시작전에 @BeforeThread 있는거 전부 실행해버려서 쿠키가 겹침
          * 단, @Test 쪽이기 때문에 "시간"으로 설정시 굉장히 많은 회원가입 발생
        * [로그인 필요한 페이지] : @Test
      * **(4)else의 경우 ? -> 로그인 인증 필요없는걸 의미**
        * 그냥 @Test 에 다 하면 될듯
  * **nGrinder 부하테스트 결과 분석**
    * 결과 분석할줄도 알아야함 -> 공부필요..
      * 테스트 용어 참고 https://gogoonbuntu.tistory.com/m/83#77
      * 시리즈1 Throughput, Latency : https://hyuntaeknote.tistory.com/m/10
      * 시리즈2 Throughput, Latency 테스트적용 분석 + 동시사용자 일반사용자 https://hyuntaeknote.tistory.com/m/11
      * 시리즈3 db 커넥션풀 https://hyuntaeknote.tistory.com/m/12
      * 프로세스 스레드 차이 http://ngrinder.373.s1.nabble.com/process-thread-td2636.html
      * 페이징 유무에따른 차이 테스트 https://kth990303.tistory.com/446
      * 쿼리튜닝 여러방법 https://kth990303.tistory.com/446
      * 인덱스 쿼리튜닝 https://jie0025.tistory.com/509
    * 시나리오1의 경우?
      * 첫번째 시나리오1 테스트는?
        * 프로세스2, 쓰레드500, 실행횟수1, Ramp-Up 주기 500에 증가단위1 -> vuser:1000
        * 테스트 횟수는 1000이 될때까지 돌아감
        * 실행횟수와 Ramp-up 으로 인해 TPS는 적당히 잘 나오는듯 하다?
        * 에러의 원인은 대부분 중복uid 로써 서버에서 **500 이미등록회원 에러**가 터진다.
          * 나중에 예외처리할때 이부분 꼭 예외처리!
      * 두번째 시나리오1 테스트는?
        * 프로세스1, 쓰레드500, 실행횟수1, Ramp-Up 주기 1000에 증가단위1 -> vuser:500
        * 테스트 횟수는 500이 될때까지 돌아감
          * 참고로 회원가입, 로그인을 각각 @Test 로 나눠서 스크립트 작성해서
          * 총 테스트 횟수가 500인데 실제 db에 250개가 등록되는 것 (실제로 에러0에 db250개)  
            -> 매우 안전하게 돌렸기에 에러도 거의 없는것
          * 즉, @Test 2개라서 통틀어서 1회로 보는게 아니라 각각을 1회, 2회로 보는듯 함
    * 시나리오2-1의 경우? 
      * vuser:100 에 시간 1분설정 및 Ramp-Up 주기 1000에 증가단위 10  
        -> **10초뒤면 vuser 100**(=스레드100) 이 됩니다
      * TPS 그래프를 보면, 10초까지는 "일정추가+스레드증가" 때문에 **제일 가파르게** TPS가 낮아짐 
        * 10초 이후는 "일정추가" 만 있으니 초반 보다는 **가파르진 않음**
      * 다행이 **에러는 전혀 없는**걸 보니 사용자 100명은 충분히 감당 되는듯 하다.
      * **TPS도 200**대는 넘어서 괸찮은듯 하다. (단, 데이터가 커질수록 100아래로도 줄어듬 ㅜ)
      * **단, vuser를 대폭 키워서 "일정조회" 만 한번 테스트 해보겠음 -> 시나리오2-2**
    * 시나리오2-2 의 경우? -> 에이전트 CPU100%, MEM85%(근데 로컬이라... 서버쪽이랑 비교를 못할듯. 서버도 로컬에서 구동중이라..)
      * vuser:500 에 시간 2분설정 및 Ramp-Up 주기 1000에 증가단위 10  
        -> **50초뒤면 vuser 500**
      * 결과보면 **에러**가 많진않지만 생겼음
      * 평균 테스트시간(MTT)이 굉장이 높아짐 **약5초..**
      * **TPS가 73** -> 사용자가 500명 잡았는데 73이면 매우 성능이 안좋은것
    * 시나리오3-1 의 경우?
      * vuser:100 에 시간 1분설정 및 Ramp-Up 주기 1000에 증가단위 10  
        -> **10초뒤면 vuser 100**(=스레드100) 이 됩니다
      * TPS 그래프를 보면, 10초까지는 "일정추가+스레드증가" 때문에 **제일 가파르게** TPS가 낮아짐 
        * 10초 이후는 "일정추가" 만 있으니 초반 보다는 **가파르진 않음**
      * 다행이 **에러는 전혀 없는**걸 보니 사용자 100명은 충분히 감당 되는듯 하다.
      * **TPS도 200**대는 넘어서 괸찮은듯 하다. (단, 데이터가 커질수록 100아래로도 줄어듬 ㅜ)
      * **단, vuser를 대폭 키워서 "일정조회" 만 한번 테스트 해보겠음 -> 시나리오3-2**
    * 시나리오3-2 의 경우?
      * vuser:500 에 시간 2분설정 및 Ramp-Up 주기 1000에 증가단위 10  
        -> **50초뒤면 vuser 500**
      * 결과보면 **에러**가 많진않지만 생겼음
      * 평균 테스트시간(MTT)이 굉장이 높아짐 **약5초..**
      * **TPS가 79** -> 사용자가 500명 잡았는데 79이면 매우 성능이 안좋은것
    * 시나리오4 의 경우? CPU-99% MEM-85% RX-66.0B TX-0.0B
      * vuser:500 으로 2분간.. 테스트했는데 너무 TPS가 좋게나옴
      * 캐시와 페이징 덕분일거임.
    * **시나리오 1~4 의 결론**
      * 시나리오 1에서는 **예외처리**!
      * 시나리오 2에서는 **페이징** & 캐시(X 이건 프론트에서!)
      * 시나리오 3에서는 **쿼리튜닝 & 페이징** & 캐시(X 이건 프론트에서!)
        * 인덱스 쿼리튜닝 https://jie0025.tistory.com/509, https://leezzangmin.tistory.com/42
        * 날짜를 매번 전체 비교하기 때문에 쿼리수정이 필요함을 느낌
      * 시나리오 4에서는 **수정할게 없을듯. 굳이할거면.. 캐시?크기?제한?**
  * **용어**
    * TPS(=Test Per Seconds) : 초당 테스트 개수
    * MTT: 평균 테스트 타임(vuser와 비례관계)
    * MTFB: 평균 첫 번째 바이트 도달 시간(=Response Time으로 볼 수도 있다.)
    * 테스트 기간 : 요청후 응답받으면 바로 다시 요청보내고, 설정한 시간만큼 진행한다.
      * @Test(+@Before) 이부분을 의미!
      * 따라서 설정한 시간만큼 엄청많이 테스트 함
    * 실행 횟수 : 스레드당 몇번 테스트할지 직접 설정할 수 있다.
      * @Test(+@Before) 이부분을 의미!
      * 따라서 설정한 횟수 만큼 테스트 함
    * GTest 객체 : 각각 테스트 시나리오 (@Test에 작성하는것)
* 모니터링
  * 모니터링 : 프로메테우스, 그라파나, 액츄에이터 사용

<br><br>

## 23-11-09 (리팩토링... + DevOps 계획)

* **임시 refactor:** 
  * **전체적으로... 특히 Setter는 다 지우자.(양방향 매핑빼고 별루라는듯?)**
    * 이를 정적 팩토리 메서드로 많이 하는듯.
    * 생각해보니 private 필드는 외부에서 객체.필드 로 접근 안됨
    * Setter 지우면될듯
  * +**@NoArgsConstructor(access = AccessLevel.PROTECTED)** 
* **모니터링 + 테스트 툴(부하테스트공부) -> 할차례**
  * 모니터링 : 프로메테우스, 그라파나, 액츄에이터 사용
  * 테스트툴 ?? : ...앵그라인더(부하테스트)
    * https://leezzangmin.tistory.com/42
    * 아마 이 부하테스트를 통해서 api 장애 개선을 진행할 것이고,
    * 쿼리튜닝도 여기서 시도해보지 않을까 예상됨
* 배포자동화 - CI/CD (지속적 통합과 배포) -> 필수는 아닌데 하고싶음
  * 깃헙액션 쉬움, 젠킨스 복잡 -> 따라서 깃헙 액션으로 구성

* 쿼리튜닝이 정확히 뭐지?? -> 쿼리튜닝 공부해서 적용해야겠음.
  * **fetch join은 1+N 문제 해결방안** 인듯 하다. 쿼리튜닝이라고 칭하긴 좀 그런거같다.
  * 그럼 쿼리튜닝은?? 뭐지? 대표적인게 인덱스 조회?? 가 있는듯 하다.
* ++++refactor -> 필수는 아니고,, 하거나 말거나
  * 스프링데이터JPA혹시 사용할수 있게끔 레포지토리를 인터페이스....추가..
  * valid, exception...??

<br><br>

## 23-10-31 ~ 11-08 (리팩토링:MockMvc 첫시도)

**할일**

* 기능추가 - 상점,아이템 ( +캐시 ) -> DB설계까지.. 완.

  * 캐릭터에 화폐필드 추가

  * 캐릭터아이템에 아이템ID를 외래키로

  * 아이템 테이블 추가!
  * **나머지 API 구현은 유진님이 하고 계시는듯!**
* 경험치 리팩토링 -> **굿(유진님 개발!)**
* ++++test: 테스트코드 컨트롤러(MOCK)

  * 기존 테스트코드부터!! 새로!! 다시! 최대한 Assert로!
    * DOMAIN 먼저
      * character 완료(아이템구현후 캐릭터는 추가로!).
      * member 완료
      * task 완료
    * REPOSITORY
      * character 완료
      * member 완료
      * task 완료
    * SERVICE
    
      * character 완료
      * member 완료
      * task 완료
    * CONTROLLER -> **MockMvc 먼저 공부**
    
      * member 완료
      * character 완료
      * task 완료


<br><br>

## 23-10-17~24

**최적화**

* 브라우저 캐시 : 3d에셋 서버에 저장 후 스프링에 캐시 사용 -> 이 url을 threejs에 넘겨줘서 사용
  * 정적파일 캐싱 한줄로 끝내기.
* 서버 캐시(ex:@Cacheable, @Cacheput)
  * 팔로우(공통), 일정(앱단에서 기록), 캐릭터(상점,??)
* 쿼리튜닝(+코드 리팩토링)
  * **읽기전용쿼리힌트(레퍼지토리), 읽기전용트랜잭션사용(서비스)**
* 상점 테이블이나 아이템 테이블...!! 추가
  * !!@!@!@!@!@!@!@!@!@!@!@!!!
  * **테스트코드 컨트롤러도 나중에 작성 ㄱㄱ**
* 모니터링(인프런), 로드밸런싱([참고1](https://velog.io/@korea3611/Spring-Boot-Spring-Cloud-Gateway-Load-Balancer-MSA5), [참고2](https://kimyhcj.tistory.com/entry/Spring-Cloud-%EC%8B%9C%EB%A6%AC%EC%A6%88-5-Loadbalancer-feat-Ribbon)) 등등
  * 로드밸런싱은 방법이 다양함. 그냥 쿠버네티스로 배포 다 관리하고 싶긴함. 아니면 nginx 설치해서 로드밸런싱 한다던지.
    * 쿠버네티스?? 클라우드환경이라 비용생각해야함.
    * nginx?? 로컬에 설치해야하는데 그렇게 하기는 싫음.

  * 다만, 그건 최종 배포할때 결정하면 되는 문제라고 생각해서 그냥 본인 로컬에서 테스트 해볼수 있는 방안으로 생각을 돌림.
    * Eureka 란것을 사용하면 되는듯 하다. 위에 로드밸런싱 참고1,2 사이트함께 참고할것
    * https://cjw-awdsd.tistory.com/52

<br>

**할일**

0. AOP로 시간측정 코드 추가(최종 때 모니터링으로!!)  
   +쿼리 join조차 안쓴 코드로 바꾸기(Lists레포만 해당->findAllWithMemberTask,findByDateWithMemberTask !!)  
   +꼭 따로 복제하든 커밋으로 남겨두든하자  
   +추후에 모니터링때 비교위해서!
   * **OK**
1. 각 기능별 쿼리수, 시간 정리(적당히 캡쳐도)
   * 일정 조회(all, date) 부분
     * all(해당멤버의 모든 일정)
       * 일정 3개 조회 시간(all) : 46ms
       * 일정 3개 조회 쿼리(all) : 5개
     * date(해당멤버의 지정한 날짜범위 일정)
       * 하루 일정 2개 조회 시간(date) : 27ms
       * 하루 일정 2개 조회 쿼리(date) : 4개
   * 경험치 부분(리팩토링 필수)
     * expTask(일정 완료시 경험치)
       * Task(여러개가능) 1개 완료 시간 : 45ms
       * Task(여러개가능) 1개 완료 쿼리 : 14개..
     * expTimer(타이머 완료시 경험치)
       * Timer(1개만) 1개 완료 시간 : 48ms
       * Timer(1개만) 1개 완료 쿼리 : 8개..
   * 팔로우 부분(조회)
     * 시간 - 14ms
     * 쿼리 - 2개
   * 멤버 조회
     * pass
   * **OK(쿼리많은이유는 LAZY라서 어쩔수없음)**
2. 쿼리튜닝,코드리팩토링작성 한후의 쿼리수 정리    
   +인터셉터 추가수정 - 로그인때 멤버 조회하는겸 캐릭터ID도 같이 조회해두는게 좋을듯  
   +서버캐시도 바로 진행후 테스트 -> "팔로우"만
   * 캐릭터ID, 팔로우 서버캐시
     * 캐릭터 조회를 서버캐시로 기록해두는걸로 하겠음 - resolveArgument에서 따로 DB조회 하는건 굉장히 쿼리 낭비인것 같고, 캐릭터는 회원ID 만큼이나 많이 쓰이게 되기 때문
       * 참고로 멤버ID 는 이미 세션 메모리 사용중
       * **알림, 팔로우 부분에 findCharacterWithMember(캐시) 로 적용!**
     * 팔로우 캐시?
       * 팔로우 추가에 회원가입처럼 **"중복검증 로직 추가"**
       * **전체 멤버 조회 로직 작성후(페이징필수) 캐시 적용**
         * 팔로워순, 랜덤순 이런건 일단 프론트에서 할수도있으니 디테일한건 패스
   * 일정 조회(all, date) 부분
     * all(해당멤버의 모든 일정)
       * 일정 3개 조회 시간(all) : 30ms
       * 일정 3개 조회 쿼리(all) : 1개
     * date(해당멤버의 지정한 날짜범위 일정)
       * 하루 일정 2개 조회 시간(date) : 9ms
       * 하루 일정 2개 조회 쿼리(date) : 1개
   * 경험치 부분(리팩토링 필수) -> 나중에.... 수정..
     * expTask(일정 완료시 경험치)
       * Task(여러개가능) 1개 완료 시간 : 
       * Task(여러개가능) 1개 완료 쿼리 : 
     * expTimer(타이머 완료시 경험치)
       * Timer(1개만) 1개 완료 시간 : 
       * Timer(1개만) 1개 완료 쿼리 : 
   * 팔로우 부분(조회)
     * 시간 - 3ms
     * 쿼리 - 1개(캐시 캐릭)
   * 멤버 조회
     * 시간 - 44ms => 캐시? => 1ms (쿼리0개)
     * 쿼리 - 1개(join fetch)
3. 브라우저 캐시 - 일단 img!!  
   => 이건 three js 돌려서 브라우저에 저장잘되는지 테스트필수  
   => 꼭 캐시전 img로딩 시간과 캐시후 img로딩 시간기록  
   => 이때 3d에셋 예전꺼 받아서 그 이미지와 새로 경랑화된거 구매한 이미지 둘다 테스트 기록!!  
   * 웹 브라우저에서 같은 탭에서 새로고침이나 url요청시 캐시 무시되기도 한다고해서
   * **새로운 탭으로 계속 테스트**하자
   * 되는것같으면 **반드시 three js 로 확인!!**
     * **CORS 해결**
     * **OK**
4. 서버 캐시 - 팔로우(공통), 상점(이건 말만하자. 최종때개밝.)  
   => 이것도 꼭 적용전과 후 속도차이 !!!!! 기록!!  
   => 쿼리가 안날라가서 굉장히 빠를거임.
   * 위에서 이미 적용했음!. **OK**

<br>

**경험치부분 꼭 리팩토링 해야함.**

<br><br>

## 23-10-13

**타이머 구현완료**

* 클라한테는 밀리세컨 단위로 "사용시간" 보내달라 하기
* 서버 DB는 Long 타입으로 "현재시간, 타이머총사용시간, 잔여시간" 구성
  * 단, 일정조회 관련 컨트롤러로 클라한테 반환할때는 "시:분:초" 형태로 바꿔서 반환
  * 구현쉽게 String으로 반환

<br>

**최적화 적용연습**

<br><br>

## 23-10-12

**경험치 체계 확립**

* `=INT((A2-1)^1.2)+10` 이걸로 일단 진행 및 상한선 레벨 100 지정
  * 1년간 시즌제를 통해서 만렙이 100정도까지 경험치 얻을수 있음.
* 물론 추후 테스트를 진행하면서 바뀔가능성도 높음

**타이머 구조 정리 -> "사용시간" 밀리세컨 단위로 달라할것**

* 타이머 테이블 삭제해야 할 듯
  * 여기있던 "집중,허용"상태는 따로 앱사용시 타이머 일시정지로 만들어버리는걸로 **질문방지**
* 클라이언트에서 "사용시간"을 전송
  * 일정추가{시작, 끝, 내용}
    * 일반 일정 -> 체크표시로 완료 전송(클라에서)
      * expUpdate 사용!
    * 타이머 일정 -> 체크표시 사용X. 무조건 종료때!
      * if 타이머상태OFF : 일정상태{타이머상태ON}, 일정{잔여시간}, 리스트{총사용시간}, 리스트{현재시간} 기록
      * else : 일정{잔여시간}, 리스트{총사용시간}, 리스트{현재시간} -> **시간계산**
        * if,else 타이밍은 타이머 종료때로 볼 수 있다.
        * 단, if면 초기 타이머 생성단계. 즉 초기화 단계
    * 시간계산과정
      * if -> 초기화 과정으로 보면 됨
        * 타이머상태 = ON
        * (TASK)잔여시간 = (끝시간 - 시작시간) - "사용시간"
        * (LISTS)타이머총사용시간 += "사용시간"
        * (LISTS)현재시간 += "사용시간"
          * **시간계산**
      * else
        * 잔여시간 -= "사용시간"
        * 타이머총사용시간 += "사용시간"
        * 현재시간 += "사용시간"
          * **시간계산**
      * **시간계산 -> 시간만 경험치 업데이트에 사용**
        * if 현재시간/시간 == 0 : pass
        * else
          * 경험치시간=현재시간/시간
          * 현재시간=현재시간%시간
          * **expUpdate(경험치시간)**
* **일정완료 컨트롤러에서** 타이머상태 조건문에 따라
  * 일반일정완료, 타이머일정완료 구현
  * **사용시간(클라) : 밀리세컨단위로 클라에게서 받기!**
  * **현재시간(계산용), 잔여시간, 타이머총사용시간 : 밀리세컨단위로 기록하기! -> 즉.. 전부다 밀리세컨!**
    * 왜냐하면 날짜로는 기록할수가 없음. 시간타입으로도 24시간을 넘어가서 기록이안됨
    * **애초에 Long으로 DB에 기록하고, 클라에 줄때 String으로 {시:분:초}로 보내**줘야할듯 ㅇㅇ

<br><br>

## 23-09-27 ~

**경험치 수식 재정립**

* 기존공식에 레벨당 필요경험치를 더욱 낮추자.
  * 초반, 중반, 후반에 레벨난이도는 갈수록 어려워지는게 맞을까?
    * **장점 : 레벨이 높을수록 확실히 강해지는 효과**
    * 단점 : 경험치 보상은 일정해서 레벨업이 힘듦. 뽑기도 자주 못하게됨.
    
  * 아니면 일정한게 맞을까?
    * **장점 : 레벨업이 매우 수월(쉬움). 이로인해 잦은 뽑기**
    * 단점 : 레벨업이 너무쉬워서 레벨의 의미가 약해지므로 동기부여가 제한
    
  * **결론1 : 두 장점을 가져가게끔 중간지점을 찾는다면?**
    
    * 레벨업을 쉽게하기 위해 - 경험치 수식을 수정해서(계수를 낮춘다던지) 레벨업을 쉽게끔 하자
    
      * 흠... 플래너 관련해서는 자료가 안보임 ㅠ
    
      * 임의로 계수 조절한 공식은 : INT((레벨-1)^1.2)+10
    
      * | 레벨 | 필요경험치 | 누적경험치 |
        | ---- | ---------- | ---------- |
        | 1    | 10         | 10         |
        | 2    | 11         | 11         |
        | 3    | 12         | 12         |
        | 4    | 13         | 13         |
        | 5    | 15         | 15         |
        | 6    | 16         | 16         |
        | 7    | 18         | 18         |
        | 8    | 20         | 20         |
        | 9    | 22         | 22         |
        | 10   | 23         | 23         |
    
    * 경험치 흭득유도를 위해 - 레벨업에 뽑기만 주는것이 아닌 레벨에 따른 경험치를 얻을때 "화폐"로도 챙겨주자
      * 추가로 특정레벨(5,10,15...)에 추가보상(방 넓히기, 선물지급 등등)을 주자
    
  * **결론2 : 중간지점이 별로라면 일정한것도 좋다고 생각**
    
    * 경험치 보상을 하루 제한을 걸어놨으므로 20정도로 일정하게 하면 되지않을까싶음
    * 대신 레벨의 의미가 약해지므로 이를 방지할 방안이 필요할듯
    
  * **결론3 : 한달마다 레벨을 초기화 하는건?**
  
    * 매달 초기화를 하기 때문에 기존 경험치 수식 or 계수를 좀 더 낮춘 수식 사용하면 될듯?
    * 계획 수행을 남들보다 늦게 시작해도 다음달에 레벨경쟁에 참여할 수 있다.
    * 매달 초기화 함으로써 매달 새롭게 플랜을 시작할 수 있다 -> 게임보단 좀 더 플랜에 비중
      * 계획이 1년 단위보다는 한달 단위로 수행하는게 더 플랜수행에 효과적이라 생각
    * 단, 레벨 초기화일 뿐 얻은 화페 및 보상아이템은 그대로 간직

<br>

**로우폴리 에셋찾아보기**

* 가구 위주로
  * [유료](https://assetstore.unity.com/packages/3d/props/furniture/low-poly-furniture-156774?locale=ko-KR)
  * [유료-예시로 쓰기 좋아보임](https://assetstore.unity.com/packages/3d/props/interior/low-poly-furniture-assets-221471)
  * [무료](https://assetstore.unity.com/packages/3d/props/furniture/low-poly-simple-furniture-free-240197?locale=ko-KR)
  * [무료](https://assetstore.unity.com/packages/3d/props/furniture/3d-dungeon-lowpoly-pack-231265)

<br>

**타이머 기능 및 컨트롤러**

* 타이머의 경험치 계산은 "집중, 허용" 상태를 제외하고는 구현된 상황
* 타이머 컨트롤러만 구현하면 되는데 구조가 Task에 꼭 묶여있는거 생각하고 구현
  * 생각해보니 이미 경험치 계산에 사용한 타이머인지 구분이 필요해서 필드 하나 추가해야할듯


<br>

**최적화 위주로 진행**

* 쿼리튜닝
  * 코드 계속 리팩토링을 거쳐서 쿼리수 줄여야 할듯
  * 다만 기능부터 다 개발이 완벽히 끝난게 확인되면 그때부터 진행해야할듯

* 캐시

  * https://hongong.hanbit.co.kr/%EC%99%84%EB%B2%BD-%EC%A0%95%EB%A6%AC-%EC%BF%A0%ED%82%A4-%EC%84%B8%EC%85%98-%ED%86%A0%ED%81%B0-%EC%BA%90%EC%8B%9C-%EA%B7%B8%EB%A6%AC%EA%B3%A0-cdn/  
    https://tbread-development.tistory.com/m/25  
    https://mygumi.tistory.com/275

  * https://rumor1993.tistory.com/86
    https://blog.lael.be/post/7605
    https://hudi.blog/spring-http-caching/
    https://wildeveloperetrain.tistory.com/119

    https://kim-gpt.tistory.com/entry/%ED%81%B4%EB%9D%BC%EC%9D%B4%EC%96%B8%ED%8A%B8-%EB%8B%A8-%EC%BA%90%EC%8B%9C-Client-side-Caching
    https://kim-gpt.tistory.com/entry/%EC%84%9C%EB%B2%84-%EB%8B%A8-%EC%BA%90%EC%8B%9C-Server-side-Caching

    (클ㄹ라!)브라우저 캐시 종류 - 디스크캐시, 메모리캐시
    (섯버!)서버 캐시 종류 - CDN, 등등...

    아마 아래는 전부 서버가 부담하는 서버단캐시 일거다.
    (1)정적이미지용 캐시 - .setCacheControl(cacheControl); 써서 메모리에 캐시해서 속도를 올리자(정적파일은 우리가 그냥 제공해주자URL)
    -> CDN-AWS S3? 로 구성해서 이미지 얻는게 속도가 더 빠르다고 하긴하는데 이건 고민,,
    -> 또한 Redis 같이 캐시서버 구축방법도 좋아보임(아마 위에서 설명한 캐시는 메모리에 바로 쓰는거? 잘 모르겠음 차이는.)
    
    ​	https://zangzangs.tistory.com/72
    
    (2)@Cachable - 나머지 캐시할것들 캐시ㄱㄱ
    
  * CDN을 사용하는게 굉장히 많은 속도 향상을 얻을듯 하다.(3d 이미지를 사용하다보니 이미지쪽 캐싱이 굉장히 중요하다고 생각)
  
* 모니터링

  * 이부분도 기능개발은 다 된것이 확인되면 진행해줘야 할듯하다.
  * 강의 본거 따라서 진행해보자.

* 로드밸런싱

  * [개념](https://velog.io/@alswn9938/%EB%A1%9C%EB%93%9C%EB%B0%B8%EB%9F%B0%EC%8B%B1), [개념](https://www.nowwatersblog.com/backend/serverLoad/serverDistribution)
  * [실습](https://velog.io/@msung99/Nginx-%EB%A1%9C%EB%93%9C%EB%B0%B8%EB%9F%B0%EC%8B%B1-%ED%99%98%EA%B2%BD%EC%9D%84-%EA%B5%AC%EC%B6%95%ED%95%B4-%ED%8A%B8%EB%9E%98%ED%94%BD-%EB%B6%84%EC%82%B0%EC%8B%9C%ED%82%A4%EA%B8%B0-feat.-%EB%AC%B4%EC%A4%91%EB%8B%A8%EB%B0%B0%ED%8F%AC_)
  * [로드밸런싱테스트](https://velog.io/@znftm97/Nginx-%EB%A1%9C%EB%93%9C%EB%B0%B8%EB%9F%B0%EC%8B%B1-%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98-%EC%84%B1%EB%8A%A5-%ED%85%8C%EC%8A%A4%ED%8A%B8-%EB%AC%B4%EC%A4%91%EB%8B%A8-%EB%B0%B0%ED%8F%AC)
    * [DevOps 강의](https://velog.io/@znftm97/series/Class101-foo-%EA%B0%95%EC%9D%98)

<br><br>

## 23-09-19~22

**캐릭터(친구기능) 목욜까지**

* 경험치량 수식 적용(임의로 아래 수식사용 - 확정은 아님)
  * 필요 경험치 수식 : (레벨-1)^2*1.5(계수)
  * 일정 경험치 보상량 : 1 or 1+T(Time)
  * 클라에서는 API요청 때 이전 레벨과 요청후 레벨이 다르면 "레벨업" 임펙트 발생시키면 될듯
  * **reqExp필드 추가 얘기하기!**
* **친구 테이블 -> 팔로우 테이블로 변경**
  * follow{follow_id, follower_id, following_id, 캐릭터id(fk)} - 팔로워들 id는 캐릭터id 사용
    * from - to 느낌
  * 알림은?? 알림 테이블을 따로 만들어두자
    * http://www.ciboard.co.kr/manual/tables/notification 참고 DB
    * **알림 테이블 물어보쟈!! -> OK OK**
* **"컨트롤러(API)" -> 할차례!!,,**
  * 캐릭터
    * 캐릭터 생성 API - 회원가입때...바로진행.. 따라서 "**회원가입 API**" 파트에서 해결?하자?
      * UUID와 닉넴 받을텐데 이때 "**경험치, 캐릭터 테이블**" 함께 생성
  * 경험치
    * 경험치량 조회 API - 누적, 현재, 레벨 전부 제공
    * 경험치 업데이트는 "**일정완료 API**" 추가해서 이곳에서 진행하자!
      * 경험치 제한까지 구현완료
      * 스케줄링으로 "일일경험치 제한" 매일 초기화 구현완료
  * 팔로우
    * 팔로우 생성 API
    * 팔로우 제거 API
    * 팔로잉 / 팔로워 조회 API - 팔로잉(해당캐릭터의 팔로잉), 팔로워(모든캐릭터의 팔로잉)
    * 팔로우시 상대방은 자신을 팔로우했는지 알려주는 API -> 이건그냥 PASS
      * 테이블 검색후 있으면 "맞팔로우 하기" 로 버튼명 변경하게끔
  * 알림 
    * 알림 생성 API - 팔로우 때 해야해서 **"팔로우 생성 API"**에 추가
    * 알림 조회 API
    * 알림제거는 따로 하지말고 읽음표시로 클라에서 해결하자
* **"화폐"는 상점만들때 추가 하겠음**
* **"일정완료" 종류**
  * 클라에서 일정들 체크 후 서버로 전송(List) -> OK
  * 클라에서 타이머 .... -> 타이머 구현방식 구글링 필요해보임.. -> 아직 X

<br>

주저리 주저리.. 회의내용들...

**경험치**

* 필요 경험치 수식 : (레벨-1)^2*1.5(계수)
* 일정소화 경험치 보상 : 1
* 타이머 경험치 보상 : 1+T(Time)
* 하루 최대 경험치 제한 : 24
  * 일정소화 최대 경험치 : 12
  * 타이머 최대 경험치 : 12
* 추후에 생각할 경험치
  * 타이머의 구체화 "집중, 허용시간"
  * 검증된 일정 소화의 경험치 - 예로 "러닝"

**기능개발 우선 - 캐릭터, 타이머, 상점**

**서버 성능 최적화**

* 모니터링
* 쿼리수 줄이기
* 캐시
* 로드밸런싱

## 23-09-17

아래 순서로 개발해나갈 예정,,, -> 먼저 **"캐릭터"**

개발
1. 캐릭터(친구,화폐,아이템, 경험치 등)
2. 타이머

리팩토링
1. 검증(Validation)
2. API 예외처리
3. AOP(공통 관심 해결사), 캐싱 등등
   * **애플리케이션의 성능을 개선**하기 위해 캐싱, 로드밸런싱 등을 적용할 예정

<br>

**[ERDCloud](https://www.erdcloud.com/d/qhJLFCiq5KpRSDN87) -> "화폐 제거"**

* 엔티티 -> "캐릭터" + 친구, 캐릭터아이템, 경험치
  * 친구 테이블명 friend로
    * id는 freind_id 로
  * 캐릭터의 레벨은 경험치 테이블로 옮기자 - 계산하기 더 쉽게
    * 임의로 경험치량 10으로 테스트.
  * **엔티티 - 테스트완료** -> 테스트코드 실행이 안되서 아래 두가지 수정으로 해결
    * 첫번째로 패키지명이 안바껴서 lepl로 전부 수정.
    * 다음으로 test패키지에 따로 application.yml 을 또 설정해놨었다. lepl로 수정.
* 레퍼지토리, 서비스 - 테스트 완료

<br>

**경험치량**

* 필요 경험치 = ((레벨 - 1) * 50 / 49) ^ 2.5 * 계수(=100만 테이블의 경우 10)
* 누적 경험치 = (기본 제공 수치 * 레벨^2) + 추가 제공 수치
* https://www.thisisgame.com/pad/tboard/?n=54281&board=22
* https://adelius.tistory.com/121
  * https://m.blog.naver.com/sirasaya/3032113

<br><br>

# 23-06-06

**리스트와 일정 "1:N" 관계로 전체적으로 수정**

**타이머를 제외하고 일정 관련한 조회, 수정, 삭제 등등 우선 개발**

* 조회 로직 쿼리 전송량 개선을 위해 **fetch join+distinct** 적절히 사용
* 조회 로직 null 문제 때문에 **lazy 강제 초기화** 적절히 사용

<br>

**Postman 의 기능을 좀 더 공부하여 API 명세서를 작성**

* 테스트 API 명세서 : https://documenter.getpostman.com/view/21970313/2s93mBwec5

<br>

**일정 완료의 경우 생각중인건??(지금은 안할생각)**

* 1분마다 @Scheduled 같이 스케줄링
  * 무엇을?? 전체 Task 조회로직을 실행해서 "종료시간"을 활용
  * `현재 서버시간 >= 종료시간` 이라면, 종료된(완료된) 일정이란것을 판단

<br><br>

# 23-05-31

**나머지 API들 CRUD 진행 및 엔티티에 편의 메서드들(비지니스, 생성 등등) 추가**

* 레퍼지토리, 서비스, 컨트롤러 작성
* TDD까지 함께 작성

<br>

**문제가 발생.. 리스트와 일정은 "다대다"관계가 아니였던것 같다.  
"다대다" 관계는 추후에 추가할 아이템 목록 테이블이 캐릭터와 "다대다" 관계로 해야한다.**

**따라서 리스트와 일정은 "1:N" 관계인 것 같고, 우선 이 관계를 DB에 추가로 그려놔야겠다...**

<br><br>

# 23-05-15

**추후에 리팩토링 과정**

* ExceptionHandlerExceptionResolver를 통해서 API 예외처리를 진행하겠다.

<br>

**"로그인" 관련해서 쿠키 세션 만료시간을 추가 및 ArgumentResolver 추가**

* AOP관련 해서는 웹의 경우 @Aspect 보다 URL을 활용하는 인터셉터가 더 좋으므로 이를 이용해서 "로그인 인증" 관련을 진행을 저번에 했고, 여기선 ArgumentResolover로 멤버 객체 바로 가져오게 추가한다.
* 세션 저장소에는 최소한의 데이터만 넣는게 중요하므로 Member객체가 아닌 Member id만을 담아두겠다.

<br>

**나머지 API들 CRUD 진행**

<br><br>

# 23-05-04

**로그인 처리 로직 - 세션 방식을 사용 (물론 전달을 해야해서 쿠키도 함께 사용)**

* 맨 처음에 로그인을 하면 서버에서 세션Id를 담은 쿠키를 클라에 응답으로 준다.
* 클라는 요청시 항상 쿠키에 세션Id가 포함되어 전달하게되고,  
  서버는 전달받은 쿠키 정보로 "세션 저장소"를 조회해서 회원임을 인증한다 => 메모리에 "세션 저장소(톰캣이 관리)"

<br>

**클라이언트**

* **클라 상에서 로그인 기록 있으면 "소셜 로그인" 화면 없이 그냥 바로 => 서버로 uid 전송**
  * API 주소는 "로그인" 주소를 준다.
* **클라 상에서 로그인 기록 없으면 "소셜 로그인" 화면 및 로그인 시도 => 이때, 서버로 uid 전송**
  * API 주소는 "회원가입" 주소를 준다.
* **클라 상에서 로그아웃을 요청하는 경우는 쿠키 정보가 있어서 바로 API 호출 및 "소셜 로그인" 화면으로 이동.**
  * 물론, 클라 상의 로그인 기록도 꼭 지워줘야 나중에 "회원가입"으로 잘 넘어감.
  * API 주소는 "로그아웃" 주소를 준다.
* **마지막으로 앱의 종료 이벤트때 "로그아웃 API"  호출 코드를 작성한다.**
  * onDestroy같이 앱 종료 이벤트때 웹뷰에서 얻은 쿠키정보를 request에 담아서 로그아웃 API 호출해주기

<br>

**서버**

* **로그인 API => 받은 uid로 회원판단 시도!! ("회원 저장소"에서 확인!!)**

  - **회원 일시**

    * UUID로 세션Id를 생성해서 "회원 저장소"에서 받은 회원정보(=memberA)와 함께 "세션 저장소"에 기록

    * 세션Id를 응답 쿠키로 전달

    - **회원 아닐시** 
      - 회원이 아니라고 클라에게 전송 (클라는 위 <클라>파트의 2번 카테고리를 행하면 됨)


* **회원가입 API => 받은 uid로 회원판단 시도!! ("회원 저장소"에서 확인!!)**

  - **첫 가입 회원**

    * uid, 기타정보 등등을 "회원 저장소"에 기록하고, UUID로 세션Id를 생성해서 회원정보(=memberA)와 함께 "세션 저장소"에 기록

    * 세션Id를 응답 쿠키로 전달

    - **이미 가입한 중복 회원**
      - 이미 회원이라고 클라에게 전송 (클라는 위 <클라>파트의 1번 카테고리를 행하면 됨)


* **로그아웃 API**
  - 쿠키 정보에 세션Id를 활용해서 해당 세션을 "세션 저장소"에서 제거

<br>

**기대 효과**

* **로그인 할때 이점 => "소셜 로그인"을 사용한 이점**
  * "소셜 로그인"을 통해서 회원 id,pw 등등 개인정보는 해당 "소셜 커뮤니티"와 주고 받기 때문에 개인정보 털릴 위험이 적어짐. 
  * "소셜 로그인"을 통해서 얻은 uid 값 또한 회원 id,pw 와는 관계없는 값을 주기 때문에 uid만을 우리 "서버"에 줘서 회원가입을 하면 개인정보 털릴 걱정이 없음.(즉, pw털릴 위험이 없음)
    * "uid가 털린것 vs id,pw 털린것" 을 비교해봐도 uid가 훨씬 안정적

* **로그인 이후의 이점 => "세션 방식"을 사용한 이점**
  * "회원 저장소" 와 "세션 저장소"를 함께 운영함으로써 회원 정보와는 전혀 관련없는 세션Id값(UUID)을 쿠키에 담아서 클라와 통신을 하기 때문에 개인정보 털릴 걱정이 없음.
  * 만료시간을 설정할 수 있기 때문에 쿠키가 탈취당해도 시간이 지나면 사용못하게 할 수 있다.
  * 세션Id를 서버에서 관리하므로 해킹이 의심된다면?? 서버에서 해당 세션을 강제로 제거할 수 있다.

<br>

**기타**

* **만료시간**
  * 보통은 그냥 만료시간=30분 정했으면 30분 뒤에 세션이 제거되지만,  
    스프링의 `HttpSession`은 클라->서버 요청의 제일 최신 시간을 이용해서 그시간 + 만료시간 을 계산해서 세션을 제거해준다.
  * 우리는 만료시간을 어떤 방식을 체택 해야할까??  
    웹의 경우 클라에서 웹을 종료했다고해서 알 수 있는 방법이 없다. 다른 방법이 있다고는 하는데, 잘 모르겠다.
  * 하지만 앱의 경우 안드로이드를 예로들자면 앱 종료때 onDestroy() 이벤트가 발생한다.  
    **따라서 앱의 종료 이벤트때 서버에 세션Id를 제거해주는 "로그아웃 API"  호출 코드를 작성한다.**
* **세션 체크하는 코드는 우리 앱에서는 모든 로직에서 다 필요하다.**
  * **따라서 "공통 관심사"로 두고 해결**해야하는데, 스프링의 AOP로도 해결이 가능하지만  
    "서블릿 필터 or 스프링 인터셉터"를 사용하는것을 추천한다.   
  * 왜냐하면 웹과 관련된 공통 관심사는 HTTP의 정보들도 필요한데, 이 정보도 "서블릿 필터 or 스프링 인터셉터"는 "HttpServletRequest"로 제공하기 때문이다.
  * 결론 : "스프링 인터셉터"가 더 편리,정교,다양한기능 을 제공해서 이 방식을 이용  
    * 사용법은 "HandlerInterceptor" 인터페이스를 구현하면 된다.
    * 동작 흐름 : WAS->필터->서블릿(Dispatcher Servlet)->스프링 인터셉터->컨트롤러
      * 따라서 컨트롤러 전에 로그인 인증해서 인증여부에따라 컨트롤러를 호출하거나 안하면 된다.
* **세션Id를 통해서 "세션 저장소"에 기록된 Member 정보를 가져와서 각종 DB들을 접근할 수 있다.**
  * **""세션Id를 통해서 "세션 저장소"에 기록된 Member 정보를 가져와""** 이부분이 코드가 많이 겹칠듯 한데, 이는 추후에 AOP로 해결을 하던지 하도록 하자.
  * 또는 인터셉터 반환때 Member까지 반환하게끔 해결하는건 보안에 취약할 수 있다고 하니까 Spring Security와 같은 보안 프레임워크를 사용하여, 사용자 인증과 권한 부여를 처리하고, 컨트롤러에서는 SecurityContextHolder를 통해 인증된 사용자 정보를 가져오는 방법도 존재한다는걸 인지.

<br>

**네이밍**

- **Database**
  - 테이블명 형식으로 `ORDER 또는 order` 사용 **=> 대문자 or 소문자**
  - 컬럼명 형식으로 `order_id` 사용 **=> 스네이크 케이스**
- **JPA -> ORM(객체 관계 매핑)**
  - 엔티티명 형식으로 `OrderItem` 사용 **=> 파스칼 케이스**
  - 필드명 형식으로 `orderId` 사용 **=> 카멜 케이스**  
    - **스프링 부트는 자동으로 필드명을 `orderId -> order_id` 로 컬럼명 찾아서 매핑**
      - 흠.. 이렇게 배웠었는데 정확히는 테이블 컬럼이 `ORDER_ID` 로 생성 되는 중이다.
      - 아마도 맨 마지막에 대문자로 바뀌는듯 하다?
    - **스프링 부트는 자동으로 엔티티명을 `OrderItem -> ORDERITEM` 로 테이블명 찾아서 매핑**
      - 이것도 `orderitem` 으로 매핑하고 맨 마지막에 대문자로 바뀌는건가 싶다.

```java
@Getter @Setter
@Entity
public class Member {
    @Id @GeneratedValue
    @Column(name = "member_id")
    private Long id; // DB PK
    @Column(nullable = false) // Not Null
    private String uid; // Entity ID => 대체키

    private String nickname;

    @OneToMany(mappedBy = "member") // 양방향
    private List<Lists> lists = new ArrayList<>(); // 컬렉션은 필드에서 바로 초기화
```

* Member엔티티명이지만 MEMBER로 테이블 매핑 
* id는 id와 매핑되기 때문에 직접 "member_id"와 매핑 => 결국 컬럼명은 MEMBER_ID로 생성

**엔티티구현 -> 레퍼지토리 -> 서비스 -> 컨트롤러 구현 순서로 진행.**

엔티티 구현에 많은 비중을 쌓기 위해 여러가지 메서드들도 추가할 예정.

* 연관관계 편의 메서드 등등 => 양방향때 활용하면 좋을 듯 하다.

또한 구현 때 TDD 작성이 매우 중요하므로 엔티티가 아니여도,

**레퍼지토리와 서비스 단계들은 되도록이면 TDD 작성을 하자.**

**개발과정 정리**

* 요구사항 분석(대략적 기능)
* 기능 목록(상세한 기능)
* 설계 시작
  * 도메인 모델 분석(간략히)
  * 테이블 설계(DB)
  * 엔티티 설계(JPA)
* 코드 구현 (각 파트별 TDD도 함께)
  * 도메인 구현 -> 엔티티를 의미하며, 모든 계층에서 사용
  * 레퍼지토리 구현 -> DB와 상호작용
  * 서비스 구현 -> 비지니스 로직 & 트랜잭션
    * `도메인 모델 패턴` : 서비스 계층은 단순히 엔티티에 필요한 요청을 위임하는 방식
    * `트랜잭션 스크립트 패턴` : 엔티티에는 비지니스 로직이 거의 없고 서비스 계층이 담당하는 방식
    * **참고로 `도메인 모델 패턴` 방식으로 진행 중**

  * 컨트롤러 구현 -> 웹 계층과 상호작용 (API 포함)

<br><br>

# 23-04-27

![image](https://user-images.githubusercontent.com/80165014/236442807-9c183cd9-424f-482e-b1c1-364f0e3825ab.png)

**엔티티 설계 과정**

•최대한 객체지향적으로 설계(테이즐 지향이 아닌)

•엔티티 설계대로 코드에 그대로 적용 됨

•따라서 member_id : Long 같은 필드명을 member : Member 형태로 객체 참조 형식으로 변경

•중요한 “연결 관계“

•기본적으로 “다대일”에서 “다“ 외래키를 가지며, 외래키를 가진 쪽이 주인, “일대일”의 경우 외래키를 아무나 가져도 되고 주인도 아무나 가능

•따라서 초기엔 주인을 중심으로 “단방향” 연결 관계 지향

•이후에 “양방향“ 설정에는 테이블 구조를 바꿀 필요없이 코드로 변경 가능하기 때문

•참고로 “일대일＂의 경우 “주 테이블 외래키 단방향“ 과 “대상 테이블 외래키 양방향“ 이 2가지의 연결관계가 존재하며 각각 장단점이 있어서 적절히 판단

<br><br>

# 23-04-14

**DB 구조 설계**

•사용자 ITEM에 “착용여부 상태” 컬럼 추가

•컬럼명 이름들 스프링 규칙에 맞게 수정

•일정 테이블 -> list_일정 테이블도 하나 추가

•“다대다“ 관계이므로 잘 풀어내야함.

•일정 테이블에 “타이머 상태정보” 를 위해 “상태” 테이블 추가

•그냥 일정인지 타이머 인지 구별 위해

•타이머 테이블 추가 및 “상태정보” 컬럼 추가(ENUM타입)

•**열품타** **처럼** : 허용앱 상태, 최대집중 상태 로 구별

•최대집중 상태 4시간? 이상시 보상X(제약조건 추가)

•허용앱 시간, 최대집중 시간, 총 누적시간 3개를 보여줌.

•시간 정보는 start, end 로 기록

•누적시간 계산은 전체 end – start => (허용, 최대집중 전부 포함)

**DB 구조 설계 (리스트_일정 테이블)**

•일정 테이블 -> list_일정 테이블도 하나 추가

•“다대다“ 관계

•하루 단위로 list_일정 테이블을 update할 것이기 때문

•“다대다” 관계는 중간에 테이블 하나 넣어서 잘 풀어내야 함.

•“다대다” 관계의 문제는 양방향으로 “무한 호출＂이 발생

•“ 하루_일정(=리스트) <-> 중간 연결(=리스트_일정) <-> 일정 “ 테이블 구조

•하루_일정 테이블과 중간연결 테이블에 양방향 관계 필요

•양방향 관계 없어도 구현가능하지만, 양방향 관계로 보기쉽게 구현하는것이 좋다

•중간 연결에서 일정 테이블은 단방향 관계

•“일정“ 에서 “하루_일정“ 으로 넘어갈 필요는 없기 때문

•참고 네이밍 규칙

•스프링 부트는 자동으로 ‘orderId -> order_id’ 로 컬럼명 찾아서 매핑

**DB 구조 설계 모습**

![image](https://user-images.githubusercontent.com/80165014/236442628-f00ad898-1bb2-427a-88b4-b4c0738f0b5b.png)

**보상관련**

•일정 완료에 따른 보상 관련해서는 재원이형 의견 추천

•타이머 사용시

•90% 미만?? 일반 보상

•90% 이상?? 큰 보상

•타이머 미사용시

•일반 보상

<br><br>

# 23-04-11

**DB 구조 설계**

•Erd cloud 사용(협업) 

•플래너 부분 DB 구조 자료조사후 개선할 예정

![image](https://user-images.githubusercontent.com/80165014/236442050-54f5a318-e92e-4051-a3c5-8ec846519330.png)

<br>

**DB 구조 설계**

•로그인 기능

•소셜 로그인 API 활용 + 한번 로그인하면 계속 자동 로그인

•uid 를 db에 기록해서 멤버 로그인!! (즉, 로그인을 복잡한 로직으로 할 필요가 없는 프로젝트이다.)

•기존 회원가입, 로그인 로직은 복잡하다. 참고 링크 참고

•https://rastalion.me/%ED%9A%8C%EC%9B%90-%EA%B0%80%EC%9E%85-%EB%B0%8F-%EB%A1%9C%EA%B7%B8%EC%9D%B8%EC%9D%84-%EC%9C%84%ED%95%9C-%ED%85%8C%EC%9D%B4%EB%B8%94-%EC%84%A4%EA%B3%84/
