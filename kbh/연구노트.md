# Intro

**개발 과정 기록**

참고) 인증체크 테스트할때 서버메모리에 쿠키를 저장하기 때문에 "로그아웃" 해줘야 함

참고) [h2 tutorialspoint](https://www.tutorialspoint.com/h2_database/h2_database_explain.htm), [h2 doc](https://www.h2database.com/html/features.html)

<br><br>

## 24-09-24~25 refactor(Valid, Excepction)

**이 부분은 util패키지에 전부 넣어놨음. 필요할때 여기서 코드 참고**

**valid, exception 하자 -> 바꿀 양이 많아서 좀 걸리네ㅠ**

- **“@Validated + {HTTP요청 + BindingResult} + 검증 애노테이션 + errors.properties”**

  - **{HTTP요청(@ModelAttribute or @RequestBody) + BindingResult}** 순서 지켜서 파라미터 작성  
    참고로 오류 메시지를 erros.propeties활용하면 이 파일 먼저 우선 체크 및 사용.

  - **bindingresult없이** @Valid랑 @NotNull 이런거 활용하면 검증 오류 발생 시 **"자동 처리"**

    - **DTO**에서 하는게 유용!! 안전하기도 하고!

  - **bindingresult 사용시** 오류가 이곳에 담기다보니 "컨트롤러 정상처리!!"  
    따라서 if문으로 `if(a.getId()!=null && b.getId()!=null) 이나 if(bindingResult.hasErros())` 이런걸로 검증오류 처리 **"직접 하는 방식"**

    - 보통 **API응답 양식**을 정해놓고 반환한다. 커스텀 가능하니까.  
      => `ApiResponse.java` 추가 + 제네릭까지 활용

      - **제네릭을 왜??** -> `ResponseEntity<ResDto>` 처럼 반환 타입이 bindingResult 와 달라서 타입 문제가 발생하기 때문
      - `ApiResponse` 에서 제네릭을 사용해서 해결. (**error함수 사용할 때 제네릭 필드부분에 null을 주기 때문에 타입에서 자유로워 질 수 있는게 POINT**)

    - FiledError -> erros.properties 활용 권장  
      ObjectError -> bindingResult.reject() 활용 권장

    - ```java
      //이런 느낌으로 사용 -> FiledError
      public ResponseEntity<ApiResponse<String>> login(@RequestBody @Validated LoginMemberRequestDto loginDto, BindingResult bindingResult, HttpServletRequest request) {
          log.info("bindingResult 때문에 검증에 걸려도 정상 동작");
          if (bindingResult.hasErrors()) {
              log.info("검증 오류 발생 errors={}", bindingResult);
              ApiResponse res = ApiResponse.error(HttpStatus.BAD_REQUEST.value(), bindingResult);
              return ResponseEntity.status(HttpStatus.BAD_REQUEST).body(res);
          }
          ApiResponse res = ApiResponse.success(HttpStatus.OK.value(), SUCCESS_LOGIN);
          return ResponseEntity.status(HttpStatus.OK)
      ```

    - ```java
      //ApiResponse.java
      public static <T> ApiResponse<T> success(int status, T data) {
          return new ApiResponse<>(status, "정상", data, null, null, null);
      }
      public static <T> ApiResponse<T> error(int status, BindingResult bindingResult) {
          return new ApiResponse<>(status, "검증 오류", null, bindingResult.getFieldError().getDefaultMessage(), bindingResult.getFieldError().getRejectedValue(), bindingResult.getObjectName());
      }
      public static <T> ApiResponse<T> errorObject(int status, BindingResult bindingResult) {
          return new ApiResponse<>(status, "검증 오류", null, bindingResult.getGlobalError().getDefaultMessage(), null, bindingResult.getGlobalError().getObjectName());
      }
      ```

    - <img src="https://github.com/user-attachments/assets/ac9185ae-2f1c-4062-9f0e-33bfff714186" alt="image" style="zoom: 80%;" /> 

    - <img src="https://github.com/user-attachments/assets/67877a2e-e0bc-4438-865c-41e0d6ac4c59" alt="image" style="zoom:80%;" /> 

    - ```java
      //이런 느낌으로 사용 -> ObjectError
      if (request.getPrice() != null && request.getPurchase_quantity() != null) {
          int resultPrice = request.getPrice() * request.getPurchase_quantity();
          if (resultPrice <= 0) {
              bindingResult.reject(null, null, "전체 가격은 0원 초과야 합니다. 현재 가격은 "+resultPrice); //errors.properties 안써서 그냥 null, null 한거임.
              log.info("검증 오류 발생 errors={}", bindingResult.getAllErrors());
              ApiResponse res = ApiResponse.errorObject(HttpStatus.BAD_REQUEST.value(), bindingResult);
              return ResponseEntity.status(HttpStatus.BAD_REQUEST).body(res);
          }
      }
      ```

    - <img src="https://github.com/user-attachments/assets/696e4ac4-afc9-49cd-bd57-b38cfcd09b71" alt="image" style="zoom:80%;" /> 

    - 해보니까 느낀게 **POST**에서만 거의 사용하게 되는 것 같다.? 즉 **외부 입력이 필요할때**

    - errors.properties는 굳이 안쓰겠다. 메시지 국제화에는 좋겠지만 뭐 기본제공 메시지도 넘 좋고, @NotNull("메시지내용") 처럼 직접 작성도 좋아서.

- Valid는 클라, 서버 둘다에서 하면 더 안전하고 좋다. 그리고 API의 경우 JSON으로 변경된걸 Valid로 검증하는거라서 **JSON으로 변경될 때 에러나 그전에 에러나 이런 경우는 Exception으로 해결**해야 하는것이다. 그럼 **Exception도 적용해보자.**

  - @ExceptionHandelr + @ControllerAdvice 조합 사용  
    참고: @RestControllerAdvice = @ControllerAdvice + @ResponseBody

    - ResponseBody 덕분에 에러 반환 형식도 JSON으로 처리하는것.

  - 참고로 컨트롤러에 예외가 그냥 @ExceptionHandler 덕분에 "정상처리" 되므로 상태코드 변환은 필수

  - **음.. 에러는 IllegalArgumentException(사용자가 값 잘못입력) JSON 변경전 잘못 입력된 값인 400에러(BAD REQUEST)랑  중복검증처럼 IllegalStateException(Conflict:409)이랑 그냥 서버자체에서 오류뜬 500에러(모든에러인 Exception으로 하겠음) 까지 총 3개를 기준으로 예외처리 컨트롤 해보겠음.**

    - (1)API 예외처리 응답 양식은 **ErrorResult** 객체로 code, message 필드 가지게 만들자.

    - (2)**ApiControllerAdvice** 를 추가 개발했다. 코드보면 이해 잘 될거다.

      - ```java
        @Slf4j
        @RestControllerAdvice(basePackages = "com.lepl.api") //컨트롤러 예외들 여기서 처리하게끔 역할
        public class ApiControllerAdvice {
        
          @ResponseStatus(HttpStatus.BAD_REQUEST) //이거 덕분에 ResponseEntity 없이 응답 코드 설정! (간단하게 하려고 추가함)
          @ExceptionHandler(IllegalArgumentException.class) //해당 예외가 잡히면 이 함수를 실행 역할!
          public ErrorResult illegalApiHandler(IllegalArgumentException e) {
            log.error("[exceptionHandler] ", e);
            return new ErrorResult("BAD REQUEST", e.getMessage());
          }
        
          @ResponseStatus(HttpStatus.CONFLICT) //중복 충돌이니까:409
          @ExceptionHandler(IllegalStateException.class)
          public ErrorResult illegalApiHandler(IllegalStateException e) {
            log.error("[exceptionHandler] ", e);
            return new ErrorResult("CONFLICT", e.getMessage());
          }
        
          @ResponseStatus(HttpStatus.INTERNAL_SERVER_ERROR)
          @ExceptionHandler
          public ErrorResult exceptionApiHandler(Exception e) {
            log.error("[exceptionHandler] ex", e);
            return new ErrorResult("SERVER ERROR", e.getMessage());
          }
        }
        ```

    - 아래는 결과 확인해보기 위한 테스트를 진행! -> register, login

      - register에 있는 중복검증 예외처리가 첫번째이다.(IllegalStateException)
      - 요청할 때 body에 아무것도 입력 안했을때 예외처리가 두번째이다.(Exception)
      - 요청할 때 body에 요청 json형식에 안맞게 입력했을 때가 세번째이다.(Exception)
      - 아쉽지만 IllegalArgumentException 에러는 확인 못했다. Json 입력 에러는 다른 예외처리 사용하더라구.

    - <img src="https://github.com/user-attachments/assets/8af54a7e-0ca5-4c7a-b256-ab872b9bed03" alt="image" style="zoom:80%;" /> 

    - ![image](https://github.com/user-attachments/assets/4fee6134-679c-45b0-a15c-229bf8109420) 

    - ![image](https://github.com/user-attachments/assets/d9f6d4af-0894-48e4-b309-83a77ecbafdf) 

**이후엔 DB만 그 README에 수정해두자. ㄱㄱㄱㄱ**

- **DB 구조가 좀 바뀜**(11개) Member, Profile, Lists, Task, TaskStatus, Character, CharacterItem, Exp, Follow, Notification, Item(상점대용.독립관계)  

  Timer 생략.. 시간상 클라한테 책임 넘김. 대신 클라에서 타임시간 받으면 경험치 업 했음.

<br>

## 24-09-22~23 refactor (구글컨밴션, 테스트 커버리지, 튜닝)

구글컨밴션은 적용했고 Ctrl+I, Ctrl+L 로 빠르게 정렬 적용했다.

**이전에 SQL 튜닝**한거부터 체크.

- 아 이게 그 서브쿼리에서 먼저 desc 인덱스 사용해서 속도 향상시킨 그 sql튜닝이구낭 (Member의 findAllWithPage 레포기능)
  - 음.. 이거 근데 기존 fetch join으로 하고 offset, limit 넣어도 전혀 페이징 문제 없었고, desc 인덱스도 잘 사용했겠는데? -> **JPA의 Fetch Join과 Pageable 사용해도 똑같이 잘 동작할 듯.1:1관계라 애초에 데이터 뻥튀기 걱정도 없었던거임.**

혹시나 **튜닝포인트** 보이면 기록해두자.

- `ListsRepository.java` 파일을 수정.   

  => **findByCurrent(), findByDateWithMemberTask(), findOneWithMemberTask() 함수**에 memberId, l.listsDate 인덱스 추가 + 날짜컬럼 함수 제거(컬럼가공 제거 `FORMATDATETIME` 제거) + member_id, lists_id 인덱스 추가

  - h2로 테스트해보공, 스샷찍공, 도메인에 인덱스 추가하겠음

  - ```h2
    explain analyze select * from lists
    where member_id = 1 and formatdatetime(lists_date, 'yyyy-MM-dd') = '2023-11-26';
    SET CACHE_SIZE 0;
    select * from lists
    where member_id = 1 and formatdatetime(lists_date, 'yyyy-MM-dd') = '2023-11-26';
    
    create index idx_member_lists_date on LISTS(LISTS_DATE);
    drop index 인덱스이름 on member;
    ```

    - 음.. h2가 인덱스 지정하는 힌트를 제공하질 않아서 테스트하기 불편.

    - 오라클에 잠시 연동시켜서 db에서 테스트 해봐야겠음 (F4로 인덱스쳌 간단)

    - ```sql
      <적용한거>
      create index idx_member_date on lists (member_id, lists_date);
      create index idx_member_lists on lists (member_id, lists_id);
      
      to_char() -> 컬럼 가공 제거 : 두 개 함수 둘다
      그리고 Lists는 애초에 시간단위는 필요없는 테이블이라 LocalDate로 타입변경 했다.
      그리고 도메인에 인덱스 추가코드도 작성했다. - db 필드명 보다 엔티티 필드명 우선 사용할 것.
      ```

    - 실행계획 (예상과 실제) 보는건 아래 참고

    - ```sql
      -- dba 권한 간접적 부여 후 dbms_xplan 으로 실행계획(예상+실제)
      GRANT SELECT_CATALOG_ROLE TO testuser; 
      -- gather_plan_statistics 힌트 자동 지정 방법 + 제거
      ALTER SESSION SET statistics_level = all;
      ALTER SESSION SET statistics_level = typical;
      -- 실행계획 보는법(예상+실제)
      SELECT /*+ gather_plan_statistics */ * FROM lists 
      WHERE member_id = 1 AND TO_CHAR(lists_date, 'YYYY-MM-DD') = '2023-11-26';
      SELECT * FROM TABLE(dbms_xplan.display_cursor(NULL,NULL,'ALLSTATS LAST +alias +outline +predicate'));
      
      SELECT /*+ gather_plan_statistics full(lists) */ * FROM lists 
      WHERE member_id = 1 AND TO_CHAR(lists_date, 'YYYY-MM-DD') = '2023-11-26';
      SELECT * FROM TABLE(dbms_xplan.display_cursor(NULL,NULL,'ALLSTATS LAST +alias +outline +predicate'));
      ```

- **더티체킹 대신 벌크연산**은 딱히 뭐 쓸만한 곳이 없어 보임. 패스해도 되겠노? 아니면 일정을 여러날짜 수정하는거 없으면 대충 만들어서 그걸 튜닝해두자. ㄲㄲ 굿굿 -> **TaskServicev2.java** 하면 된다이!~~

  - 레포에 updateAll함수 추가 - in 절로 task_id 값 비교하게 했고, start~end 날짜들 내용(content) 일괄 수정

  - ```java
    public void updateAll(List<Task> taskList, String content, LocalDateTime startTime, LocalDateTime endTime) {
        startTime = startTime.toLocalDate().atTime(0, 0, 0);
        endTime = endTime.toLocalDate().atTime(23, 59, 59);
        List<Long> idList = taskList.stream().map(o -> o.getId()).collect(Collectors.toList());
        int updatedCount = em.createQuery(
            "update Task t set t.content = :content" +
            " where t.startTime >= :startTime and t.endTime <= :endTime" +
            " and t.id in :idList")
            .setParameter("content", content)
            .setParameter("idList", idList)
            .setParameter("startTime", startTime)
            .setParameter("endTime", endTime)
            .executeUpdate();
    
        System.out.println("Updated count: " + updatedCount); // 업데이트된 개수 확인
    }
    ```

  - **formatdatetime 같이 컬럼가공을 하지 않기 위해서 localdatetime 타입으로 비교!**

  - **이를 위해 startTime, endTime을 time부분을 0으로 처리한 값을 사용하자.**

- **페이징 부분...** 페이징은 보통 부분범위 처리에서 좋은 효과를 얻을텐데, 일반 테이블이 아닌 조인문에서 페이징을 원할때는 어떻게 해야할까? -> 페이징은 이미 튜닝했었음!

  - Order, OrderItem의 경우 1:N의 관계이다. 근데 "관리자가 최신순 주문상품 내역" 보려고 한다. 이때는 주문상품 기준 최신순으로 나타내도 충분하다. **N:1로 페이징하면 될거니까 어려움이 없다.(데이터 뻥튀기 없으니까. ORM얘기도 아니라 1+N은 고려X)**
  - 근데, "관리자가 최신순 주문 내역"을 보려고 한다면? 주문이 중복없이 나열되고, 해당 주문에 해당되는 주문상품들이 함께 포함되어 나열되어야 한다. 이는 **1:N로 페이징해야 하니까 생각이 필요하다. 왜? 1:N 조인에 페이징하면 데이터 뻥튀기때문. Order,OrderItem일때 Order가 중복 생성되므로 순서가 애매해진다. OrderId가 동일하니까 순서를 정할 수가 없으니까!**
    - (1)orderId 그룹화는 성능이 아쉬워서 별로다. GPT가 아이디어를 줬다. 서브쿼리로 먼저 order 페이징 구한 이후에 또 order와 join하고 orderItem과 join하는 방안이다.  -> **미리 페이징 함으로써 데이터 중복으로 순서가 애매해졌던 문제가 해결 (정렬에 인덱스까지 사용할테니 충분히 성능 좋다고 판단)**
    - (2)ORM에서는 ToOne 관계는 fetch join으로 쿼리 수를 줄이고, 컬렉션(ToMany)는 default_batch_fetch_size로 최적화 한다. **JPA가 IN절로 size만큼 자동 처리!**

- **distinct를 꼭 사용해야만 하는 데이터 상황인가? 고민하다보니 fetch join vs 일반 join 의 늪에 지금 빠져있다.** -> 다 필요해서 사용했었다 distinct. 그러니 이해만하고 PASS

  - 일반 SQL에서 join시 중복데이터는 당연. 근데 사실 중복row들이 아니긴하다. 엄연히 다른 필드가 존재한다. 다만, Order{OrderItem2개}를 원하지 {Order OrderItem2개},{Order OrderItem2개} 를 원하진 않잖아?
  - <img src="https://github.com/user-attachments/assets/ac3f3548-797b-49f5-a644-90f491352ff3" alt="image" style="zoom: 50%;" /> 
  - ![image](https://github.com/user-attachments/assets/b11e7305-ee6a-44f4-b455-1805795adddd) 
  - ![image](https://github.com/user-attachments/assets/c5bd99ab-d8ce-41ea-b543-e413ab4c88fd) 
  - JPA의 distinct는 sql에도 붙이긴 하지만 **영속성 컨텍스트에서 중복객체를 확인해서 제거**한다는게 큰 특징이다.
    - 위 사례에선 RDB에선 distinct키워드 중복 처리 안한거임. 중복이 없으니까.
    - 물론 distinct도 컬럼 지정하면 해당 컬럼까지만 중복행 체크. 근데 그렇게하면 원하는 orderItem데이터도 삭제되버리니까 위 경우는.. order부분만 중복체크해서 제거했다해도 orderItem 하나 잃는거자냐.

**위 고민 내용 좀 더 알아보기..** [참고](https://devraphy.tistory.com/617)

- 애초에 jpql을 사용하지 않는 SQL의 경우 "영속성 컨텍스트" 자체에 해당되지 않는다.  
  애초에 일반 SQL에서 join은 row만 반환할 뿐이다.(객체로 보지않지)

  - **그럼 jpql에서 일반join과 fetch join은 뭐가 다른가?**  
    참고로 1:1, N:1은 중복생성 관련해서는 문제없다. 그리고 **중복문제는 distinct나 group by로 보통 해결한다.**

  - 일반 join에서도 N+1 문제는 방지 가능하다. 예로 `select o, oi from o랑 oi 조인;`  

    - 다만, order랑 orderItem을 각각을 반환해서 개별적으로 처리해야한다. 
    - 즉, order이 `List<OrderItem>` 로 가지고 있는데 이 관계로 주는게 아니다.

  - fetch join의 경우 지연로딩을 즉시로딩으로 N+1문제 방지 가능하고, 연관된 엔티티도 알아서 포함해준다(`List<OrderItem>` 으로 포함)

    - JPA자체가 객체지향적으로 작성하기위한 ORM 제공 요소인데, 당연히 JPA 사용한다면 fetch join사용이 낫다.

  - **만약 MyBatis의 1대다 일반 Join은?** ORM이아니라 SQL 매퍼다. 수동 처리해야한다.

    - ```xml
      <resultMap id="OrderResultMap" type="Order">
          <id property="id" column="order_id"/>
          <result property="orderDate" column="order_date"/>
          <collection property="orderItems" ofType="OrderItem">
              <id property="id" column="item_id"/>
              <result property="productName" column="product_name"/>
              <result property="quantity" column="quantity"/>
          </collection>
      </resultMap>
      
      <select id="getOrdersWithItems" resultMap="OrderResultMap">
          SELECT o.id AS order_id, o.order_date, 
                 i.id AS item_id, i.product_name, i.quantity
          FROM orders o
          LEFT JOIN order_items i ON o.id = i.order_id
      </select>
      ```

    - ResultMap을 사용해서 MyBatis가 수동 매핑해줘서 Order는 orderItems라는 컬렉션을 가질 수 있게 된다.

- **조회의 2가지 방법 -> 엔티티 조회, DTO 직접 조회**

- **엔티티 조회(1)** -> **JPA가 최적화를 많이 제공**해 줌

  - **엔티티 조회 후 DTO로 변환**해서 반환하는게 훨씬 안전. (엔티티 외부노출 방지는 필수) -> **DTO 변환 방식 (DTO 직접 조회랑 다른거임)**
  - **페치조인**으로 쿼리 수 최적화. -> 지연로딩을 즉시로딩으로 바꾸는 느낌 (N+1방지). 그리고 연관된 엔티티도 함께 조회
  - **컬렉션 페이징**(1:N같은)은 페치조인은 불가능. 따라서 **Batch활용** ㄱ
    - [Batch 방법 참고](https://velog.io/@guns95/%EC%BB%AC%EB%A0%89%EC%85%98-FetchJoin%EC%9D%98-%EB%AC%B8%EC%A0%9C%EC%A0%90%EA%B3%BC-%ED%95%9C%EA%B3%84-%EB%8F%8C%ED%8C%8CBetchSize)
      - 페이징은 ToOne에 페치조인한 쿼리에만 적용하는거임. 나머진 Batch를 통해 **JPA가 IN절에서 연관엔티티(지연로딩)들 Batch Size만큼 1번의 추가 쿼리에 가져와주는**거고!
    - 애초에 페이징이 전체 쿼리(FULL SCAN) 조회하려는 목적이 아니니까!
    - 물론 그룹핑이나 distinct을 하던지 하면 페이징 처리 자체는 가능하지만 목적에 부합하다. 
      - 일반SQL도 아니고 ORM인 JPA니까!
      - 중복제거는(그룹핑, distinct) 페치조인하면 1:N의 경우 데이터 뻥튀기 되니까 언급한 것!
    - **이것도 별로일때 DTO직접 조회로 해결도 해볼 수 있는것**

- **DTO직접 조회(2)** -> **SQL 직접 다루는것과 유사.** 직접 튜닝도 잘 해야겠죠?

  - **DTO 직접 조회**는 말그대로의 의미다. select절에 DTO로 원하는 형태로 조회!

  - **DTO 컬렉션 조회**는 **IN절을 활용**해서 메모리에 미리 조회해서 최적화 가능하다.

    - ```java
      // 아래 코드 확인.. 좀더 자세히.. 
      // orderId는 매개변수로 입력 받은 값이다. orderId가 N개이면 1+N이 발생할거다.
      private List<OrderItemDto> fun(Long orderId) {...}
      "select new com.example.dto.OrderItemDto(oi.order.id, i.name, oi.orderPrice, oi.count) " +
                      "from OrderItem oi " +
                      "join oi.item i " +
                      "where oi.order.id = :orderId"
      
      // 1+N 해결법은?? in활용 -> 쿼리 2개 발생 (findOrders랑 아래 jpql)
      // orderIds는 findOrders()로 구한 값
      private List<OrderItemDto> fun() {...}
      List<OrderItemDto> result = findOrders();
      List<Long> orderIds = result.stream().map...
      "select new com.example.dto.OrderItemDto(oi.order.id, i.name, oi.orderPrice, oi.count) " +
                          "from OrderItem oi " +
                          "join oi.item i " +
                          "where oi.order.id " +
                          "in :orderIds"
      result.forEach(o -> o.setOrderItems(...)); // orderItem 넣기
      return result;
      ```

    - IN 절인 `List<Long> postIds` 가 메모리에 있고, select절을 가져와서 한번에 비교할 수 있다. 그래서 쿼리도 1개로 줄어들 거고!

      - 1+N을 위 코드로 해결한 모습

    - **한방 쿼리는??** -> 위 쿼리는 N:1 로 접근한거라 "중복쿼리"생각 안한거

      - 근데 한방 쿼리문은 Order->OrderItem 접근 (=1:N) 이라 "중복쿼리 생김"
      - 이를 해결하면서 한방 쿼리 작성을 해야하는거임.(물론1+N해결하는 IN까지)
      - **이건 플랫 조회로 보면된다. 아래에서 확인하자.**

  - **플랫 조회**는 말 그대로 JOIN 결과 전부 조회후 앱단에서 모양을 커스텀한다.

    - 우리가 잘 아는 일반 SQL의 join 결과는 아래처럼 중복이 있다. (1:N 때)
    - ![image](https://github.com/user-attachments/assets/b11e7305-ee6a-44f4-b455-1805795adddd) 
    - 보통은 그룹핑해서 해결하면 된다. 여기서도 마찬가지로 **그룹핑**으로 해결
    - (1)OrderDTO의 컬렉션(OrderItem)을 컬렉션이아닌 컬렉션의 속성으로 구성
      - 즉, 위 그림의 원하는 필드들 가져다 사용하는것. fetch join이 아니니까.
    - (2)위 결과처럼 가져오게끔 일반적인 join문 쓰면 됨 ㅇㅇ. -> **"쿼리1개"**
    - (3)핵심은 여기서 그룹핑을(orderId 기준) 먹여서 **"중복해결"** 
    - 개인적으로 후처리가 넘 많고, **그룹핑 먹이는건 뭐.. distinct랑 다를게 없다**.
      - 물론, 엔티티가 아니라 DTO직접 조회 방식 사용할때의 최적화 방안이니까!!
      - 필요할때 쓰자.

  - **DTO직접조회 결론**

    - **마치 일반 SQL문 쓰는 느낌으로 사용한다고 생각하면 된다.**
    - 엔티티 조회 사용 불가시 사용!!, 컬렉션(1:N같이) 조회로 "중복데이터"나 지연로딩때문에 1+N 문제시 아래 방안으로 해결하자.
    - **컬렉션 조회는 "IN절"로 1+N을 해결하고, "N:1조회"로 중복데이터 해결하자.**
    - **또는 플랫 방식으로 해결. -> 당연히 쿼리1개고, 중복은 그룹핑으로 해결**

- **DTO변환 방식 vs DTO직접 조회**

  - 사실 요즘 스펙상 재사용성이 좋은 DTO변환이 낫다고 생각은해서 우선 적용하자.
  - 그래도 너무 쿼리 성능이 좋지 않다면 DTO직접 조회로 넘어가자. (확실히 select절의 필드 수가 줄어듦, **물론 일반 join문 사용해야하고**)
  - fetch join은 당연히 못 사용하는게 기존 엔티티 연관관계를 가지는게 아니라 DTO니까!!

- **권장순서**: 엔티티 조회 추천 -> 페치조인 쿼리 수 최적 -> 컬렉션의 경우 페이징 유무에 따라 Batch 활용 -> 엔티티 조회 방식 불가하면 DTO직접 조회로 ㄱㄱ -> 이거조차 안되면 Native나 JdbcTemplate이나 QueryDsl 등

<br>

**테스트를 위한 코드는 구현 코드에서 구현하지 말자 + @Setter 제거**

- 테스트를 위해 접근 제어자를 바꾸는 경우 (test 코드 api단에서 도메인의 setId 사용 발견)

- Member.java, 나머지 도메인들의 setId() 주석

  - 근데 테스트하기가 어려워짐. 그래서 아래 패턴으로 해결

  - ```java
    // Mocking Member 객체
    Member member = mock(Member.class);
    when(member.getId()).thenReturn(1L); // ID 반환 설정
    when(member.getUid()).thenReturn("12345");
    when(member.getNickname()).thenReturn("회원가입 테스트");
    ```

**커버리지는 테스트코드 전체 한번에 실행해서 체크하겠음.**

- ![image](https://github.com/user-attachments/assets/d7476323-da80-49f6-9666-73630a475d61) 
- 전체적으로 좋지만, service와 api는 Method 부분이 좀 낮다. 한번 체크해보자.
- 아이템이랑 구매하고 이런부분은 구현은 했지만 클라쪽에서 사용을 안해서 놔뒀었는데 그런 부분들이 대부분이였다. 적당히 문제 없는듯 하다. **커버리지 생각보다 괜찮다!?**

<br><br>

## 24-09-18~21 refactor를 위한 프로젝트 복습

**IDE를 인텔리J, 빌드 툴은 Gradle 사용**했었음. 근데 **실제 빌드와 실행은 인텔리J**로 설정함.  
=> 이게 실행 속도가 빨랐었음.

- Maven은 xml였나? 그런걸로 라이브러리 설정 했고,
- gradle 은 build.gradle에서 다 설정했었음.
- 이런거 사용안하고 이클립스에서 자바 플젝 했을때는 직접 jar파일 집어 넣었었음.

**build.gradle**

- **nGrinder가 17지원 안하니까** 초반엔 자바 11 썻네, 이후 `스프링 3.x` 사용위해 `자바 17` 쓰고.
  - 이때 jakatra 였나? 등등 마이그레이션때 오류때문에 한참 헤맸던 기억 난다.
- `lombok` 써서 @Getter 등 쓰겠네, `h2 db` 쓰고, `data-jpa` 니까 jpa나 spring data jap 쓰겠다.
- `starter-test` 관련해서도 사용중이고, `test lombok` 도 사용중이네
  - **JUnit(사용)**, Spring Test, Mockito, **AssertJ** 사용 가능하게되고, 롬복을 테스트에서 사용 허용! 
- `starter-validation` 으로 valid 사용 가능했네, `starter-cache, caffeine` 도 캐시!!
- `actuator, prometheus` 로 모니터링 했었고.

**application.yml**

- `spring: datasource: url, username, password...` 에서 h2 db 연결 세팅
  - **테스트에선 db연동 부분은 주석을 해야지 "메모리DB" 사용. db걱정 없음.**
- `spring: jpa: hibernate, properties` 에서 create, none으로 테이블 생성 또는 기존 테이블 사용 설정 + show_sql로 jpa가아닌 실제 sql문 체크(튜닝 하려면 필수로 체크)
  - show_sql은 근데 사용 안하고, 아래 logging.level의 SQL을 사용 하자.
- `server: servlet: session: timout: 30m` 으로 세션 타임아웃 설정
- `logging.level: org.hibernate.SQL: debug` 는 SQL쿼리를 디버그 레벨로 로깅
  - `com.level: debug`로 level설정도 debug로 하면 프로젝트 로그레벨은 debug 레벨 사용
  - **로그레벨 (왼쪽 가장 상세): trace > debug > info > warn > error > fatal 포함 관계**
- `management` 에서 endpoint 노출 설정했음. **(모니터링 때문에)**
  - shutdown 활성화해서 해당 앱을 외부에서 종료할 수 있게 엔드포인트 노출.
    - 기본적으로 비활성화지만 활성화하면 관리자가 **http 요청으로 앱 종료 가능**
  - exclude에는 env, beans 엔드포인트 노출을 제외했음. (환경정보, 빈 정보)

<br>

**"테스트 코드" 정상 동작과 흐름부터 체크하면 금방 이해 될 듯**  
[코드 커버리지 함께 참고하자](https://amaran-th.github.io/%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4%20%EC%84%A4%EA%B3%84/[IntelliJ]%20%EC%BD%94%EB%93%9C%20%EC%BB%A4%EB%B2%84%EB%A6%AC%EC%A7%80%20%ED%99%95%EC%9D%B8%ED%95%98%EA%B8%B0/)

- **인텔리J-edit configurations 세팅** 및 테스트 실행 때 **run test with 커버리지로 실행 ㄱ**

  - 참고로 여기서 **Run 멀티 설정이나 실행 프로필 설정**이나 여러가지 할 수 있던거 기억난다.

- **@Slf4j** -> `private static final Logger log = LoggerFactory.getLogger(YourClassName.class);`와 같은 로깅 필드가 자동 생성

  - `log.info("{}", member.getId());` 이런식 사용

- **given, when, then 패턴**인것도 기억난다.

  - **@BeforEach**는 각 @Test 수행 전 동작 -> @Test마다 **독립적** 상태라 필요
  - 다만, DB와 연동하는 **레포(DAO)단**에선 **@Transactional의 @Rollback(false)**를 통해 DB의 데이터 공유는 가능해서 테스트가 정상 동작 하는 것

- @SpringBootTest 의 경우 모든 빈을 로드..  
  **=> 컨트롤러만 테스트?? @WebMvcTest 사용 (서블릿 컨테이너 MOCK)**

  - @MockBean 으로 가짜 객체 등록. -> **중요: 실제 동작X**

    - 따라서 `when(member.getId()).thenReturn(1L);` 이런식으로 **임의로 리턴값 지정**
    - `mockMvc.perform()` 사용때 post, get 잘 구분해서 적용
    - 진짜 **컨트롤러만 테스트** 하는것. 

  - 로그인 세션 같이 **세션은??** 

    - `MockHttpSession()` 활용 -> 로그인 인증 "인터셉터" 통과
      - 실제로 세션이 필요한 컨트롤러 테스트 경우 이걸로 세션 넣어서 통과
    - 만약 세션을 흭득하는 "로그인" 컨트롤러 테스트 경우?
      - 로그인 로직은 로그인 성공시 세션을 생성!
      - @WebMvcTest 테스트 수행한 로그 request쪽에 session atr 보면 생성된 HttpServletRequest 정보 확인 가능
      - 다만, 응답 쿠키는 확인이 불가능했다. 쿠키는 웹에서는 자동 처리해주다보니 환경 차이인 것 같다.

  - **주의)** 컨트롤러에서 사용한 레포,서비스 등등 은 꼭 Mock해주자. memberService를 테스트코드에서 사용안하길래 지웠다가 에러 한참 떳다.. 컨트롤러에서 사용중이면 무조건 **@MockBean 등록은 일단 필수다!**

  - `mockMvc.perform` 함수에서 **json 내용**을 체크 하고 싶을때? -> `jsonPath()`

    - ```java
      .andExpect(jsonPath("$[0].content").value("알림테스트1")) // 응답 body 의 json 확인
          .andExpect(jsonPath("$[2].content").exists())
          .andExpect(jsonPath("$[3]").doesNotExist()) // 없어야 정상
      ```

- **@Order()+@Rollback(value=false) **활용  
  `@TestMethodOrder(MethodOrderer.OrderAnnotation.class)` 있어야 Order 가능

  - `@Order`은 테스트 순서 정하기 용이.
  - `@Rollback(value = false) //롤백 false 하면 커밋 시점의 flush 인 db 쿼리 다 보여줌 `  
    => 추가로 DB저장도 유지 되니까 유용함.

- **서비스 단에서 보통 트랜잭션을 사용**한다. **테스트 코드를 작성할때도 사용**하고있다.. 그럼 트랜잭션이 겹칠테고 전파로 인해 기존 사용중인 트랜잭션을 그대로 사용하는것도 안다. **그럼 독립적으로 트랜잭션을 사용하는 경우는 뭐가 있을까 궁금해졌다.**

  - 기본값: 트랜잭션 그대로 사용은 @Transactional의  `Propagation.REQUIRED` 속성  
    트랜잭션 독립 사용은 @Transactional의  `Propagation.REQUIRED_NEW` 속성

  - 사례1은 로그기록이다. 서비스단은 그대로 두고, 테스트코드에서 독립사용시 테스트코드에서 예외 터져도 service사용 부분은 롤백하지않고 커밋될 수 있다.

  - 사례2는 결제 처리와 알림이다. 결제가 성공하면 알림을 보낼건데, 알림 전송 실패하더라도 결제는 성공적으로 이루어져야 한다. 이것도 충분히 가능하다. -> 이게 실제 서비스에서 고려할 만한 부분인 것 같다.

  - 사례3은 배치 작업 및 상태 업데이트다. 대량 데이터를 처리하는 배치 로직에서 "상태 업데이트"를 독립 트랜잭션으로 실행해서 롤백을 당해도 상태는 업데이트 할 수 있는 방안이다.

    - ```java
      @Transactional
      public void processBatch(List<Data> dataList) {
          for (Data data : dataList) {
              try {
                  // 데이터 처리
                  processData(data);
                  statusUpdateService.updateStatus(data.getId(), "Processed");
              } catch (Exception e) {
                  // 처리 중 오류가 발생해도 상태 업데이트는 독립적으로 진행
                  statusUpdateService.updateStatus(data.getId(), "Failed");
              }
          }
      }
      
      -------------------------------
          
      @Transactional(propagation = Propagation.REQUIRES_NEW)
      public void updateStatus(Long dataId, String status) {
      // 상태 업데이트
      	statusRepository.updateStatus(dataId, status);
      }
      ```

**도메인**

- 도메인 속 **"생성\_편의 메서드", "연관관계\_편의메서드"** 등 편의메서드 테스트

  - **생성 편의 메서드** ex: static 선언인 createMember() 같은 것 - 생성자 대용

  - **연관관계 편의 메서드** ex: addLists(), sestCharacter() 같은 것 - 양방향에 주로

  - **비지니스 로직 편의 메서드**

  - ```java
    /**
     * 비지니스 로직 => 엔티티내에서 가능한 비지니스 로직은 작성 권장(객체지향적) 이건 작성할게 생기면 작성.
     */
    private static boolean compareDate(Task task, LocalDateTime listsDate) {
      // 년,월,일 만 비교하면 충분 하므로 Time 은 비교X
      LocalDate taskDay = task.getStartTime().toLocalDate();
      LocalDate listsDay = listsDate.toLocalDate();
      if (taskDay.compareTo(listsDay) == 0) { // 동일시 0
        return true;
      }
      return false;
    }
    
    public Lists updateTime(Long timerAllUseTime, Long curTime) {
      this.timerAllUseTime = timerAllUseTime;
      this.curTime = curTime;
      return this;
    }
    
    /**
     * 조회 편의메서드
     * 리스트(하루단위)내의 전체 일정 개수 조회 => 필요하면 작성
     */
    ```

- @Getter 필수, @Setter는 없애기 위해 **생성자 Protected**로 하는 패턴 (생성자 static으로 선언) -> **protected는 동일 패키지**까지만 허용

  - `@NoArgsConstructor(access = AccessLevel.PROTECTED)` 활용

  - 코드 의미대로 No Args(매개변수x) 생성자를 생성하는 코드!! (범위는 Protected)

- `@Table(name = "MEMBER", indexes = @Index(name = "IDX_MEMBER_ID", columnList = "member_id desc"))`

  - DB테이블명(MEMBER) 매핑, member_id desc 하는 인덱스 추가 코드 (튜닝)

- ```java
  @Id // pk
  @GeneratedValue
  @Column(name = "member_id") // db컬럼명 매핑, nullable = false 는 not null
  private Long id; // 엔티티에선 보통 "테이블명 생략"
  ```

  - @GeneratedValue는 사용 DB에 맞게 자동으로 identity or sequence 선택 해줌
  - 오라클12c 부턴 시퀀스말고 identity 문법 제공하므로 identity 가능

- ```java
  @OneToMany(mappedBy = "member") // 양방향 (member:lists = 1:N)
  private List<Lists> lists = new ArrayList<>(); // 컬렉션은 필드에서 바로 초기화
  
  @OneToOne(fetch = FetchType.LAZY) // 단방향(=원래방향), 지연로딩 설정
  @JoinColumn(name = "profile_id") // FK
  private Profile profile;
  
  // CascadeType.REMOVE 를 해줘야 고아객체가 안생기게 되며, Lists 삭제도 정상
  @OneToMany(mappedBy = "lists", cascade = CascadeType.REMOVE) // 양방향
  private List<Task> tasks = new ArrayList<>();
  ```

  - 내 기억엔 1:N에서 N이 fk 가지고, 1은 양방향 연결 해줬음. 안하면 걍 단방향이었고.
  - 1:1은 본인은 보통 주 키를 fk 가지는 단방향 연결만 했음. (null 허용 단점 기억난다.)

**레포지토리(DAO), 서비스** -> @SpringBootTest 는 빈 사용하려면 필수죠~!

- **persist는 영속성 등록, flush는 모아둔 쿼리 전부 쏴줌(영속성내용->DB반영)**

  - flush 자동발생의 경우 **트랜잭션 커밋**과 **em.createQuery문(jpql실행)** 때 발생  

    - 쌓여둔 영속성 내용을 DB에 먼저 반영해줘야 jpql로 조회할 때 데이터 불일치 방지
    - 단, 이건 내가 테스트해서 확인한거긴 한데 **jpql 에 member사용중이면 member가 영속성에 존재할 때 flush 자동발생. 그게 아니면 굳이 발생할 필요가 없다보니 자동 발생 안함.**

  - 번외) **em.find()** 도 즉시 쿼리 발생. **단, flush는 아님** - em.remove()는 즉시 쿼리도X (flush때 쿼리 쏨)

    - 당연하지만 영속성에 있는 엔티티를 find() 할 때는 **바로 해당 주소**를 가져와 줌.  
      => db에 쏘는 **쿼리 발생 안함.**

    - save()는? JPA는 당연히 직접 구현한다. 난 그냥 persist만 한다. Spring Data Jpa 에서는 persist+merge를 제공한다. 따라서 여기선 업데이트로 사용이 가능하다.

      - 근데, isNew() 함수를 써서 엔티티 이미 있는지 체크하는데 isNew는 엔티티의 Id가 null인지 체크하는 함수다. 따라서 @GeneratedValue를 사용하지 않은 id의 경우엔 임의로 id를 넣어 줄텐데 이러면 여기서 문제가 발생한다.
      - id가 null이 아니니까 persist가 아닌 merge 가 발생하는데 DB에 해당 엔티티를 찾아내려고 select쿼리가 나가는 문제이다.(없을텐데 불필요하게 나가는..)
      - 해결법은 [이 분꺼 참고](https://velog.io/@pjh612/JPA-Spring-Data-JPA%EC%9D%98-save%EC%9D%98-%EB%8F%99%EC%9E%91-%EA%B3%BC%EC%A0%95)
      - 참고로 merge동작은 이미 있는 엔티티(준영속상태)를 영속성으로 바꿔줘서 업뎃이 가능하단 말이다. 이 과정에서 DB 조회도 발생하는거고! (해당 엔티티 찾으려고 하는거임.)

    - 영속성 컨텍스트엔 4가지 상태가 있음(영속, 비영속, 준영속, 삭제)

      - **em.remove()를 하면 삭제 상태로 관리 되므로 find()를 해도 db까지 찾지 않는거임. 삭제인걸 아니까. (원래 find는 영속성 컨텍스트에서 못찾으면 db까지 찾아서 해당값 영속성에 등록하고(캐시) 조회 결과를 반환해주는 동작함.)**

      - ```java
        // given
        Task findTask = taskService.findOne(taskId); // 위에서 저장했던 Task 찾기. Task 만 조회함
        log.info("findTask : {}", findTask);
        
        // when
        //1. 영속성 컨텍스트에서 삭제 된걸 확인했기 때문에 find 에서 db 조회까지 안가고 종료
        taskService.remove(findTask); // 영속성 컨텍스트에서 상태4개 중 "제거 상태"로 운영 됨. (taskStatus 랑 cascade 이므로 지연로딩이였어서 여기서 taskStatus 조회가 발생)
        findTask = taskService.findOne(taskId); // 로그 없음. (삭제되어서) -> 영속성에서 이미 삭제된걸 확인해서 그럼. 이미 삭제한 걸 아는데 뭐하러 db 를 확인하겠음?
        
        //2. 원래 find 는 영속성 컨텍스트에 엔티티 없으면 db 조회까지 하기 때문에 그 부분을 로그로 보려고 함.
        em.flush();  // 삭제된 엔티티를 DB에 반영 (강제 플러시)
        em.clear();  // 영속성 컨텍스트 초기화
        
        // 이제 다시 조회를 시도하면 DB에서 조회
        findTask = taskService.findOne(taskId); // 삭제된 엔티티 조회 시도. 쿼리 발생! (null이어야 함)
        ```

      - em.find 하면 영속성일텐데 em.detach()로 영속성 컨텍스트에서 분리시켜서 **준영속으로** 만들어 버린다고 가정하자.  
        `em.merge()` 로 영속성 만들면, 데이터 수정시 **더티 체킹(Flush시점)** 잘 된다.  
        그냥 **merge사용보단** `find()`로 **영속성을 가져와서 내부 로직으로 수정**하자.

        - **더티 체킹은 주의하자**. 수정 될거면 최대한 수정 후 (persist)insert 해야 update 문이 덜 나갈거고, 변하는 엔티티가 많을경우 벌크연산이 더 낫다.
        - 벌크연산 간단함. 예로 여러날짜가 한번에 업데이트 될거 같으면 걍 우리가 잘 쓰는 쿼리문으로 조지면 됨. `UPDATE Task t SET t.status = :status WHERE t.dueDate < :currentDate`

      - **비영속 상태**는 그냥 말그대로 **persist하지 않은 상태**인거다.

  - persist때 generatedKey 등록한 엔티티는 자동 nextval **시퀀스** 쿼리 발생해 줌

    - 단, **identity** 방식 사용중이면 insert쿼리 시점에 DB에서 키를 생성
      - identity 전략은 기본 키 생성을 DB에 위임! 그래서 "JPA 쓰기 지연 방식 불가"
      - DB에 위임한다는건 반드시 엔티티가 DB에 저장되어야 키를 얻을 수 있음.
      - 근데, 쓰기지연을 위해 영속상태여야 하는데 있을수가 없는것
      - **즉, "쓰기지연" 사용하는 우리는 "시퀀스"전략 사용 중**
    - **H2, PostgreSQL, Oracle** 등에서는 기본적으로 **`GenerationType.SEQUENCE`**를 사용
    - **MySQL, SQL Server** 같은 DB에서는 기본적으로 **`GenerationType.IDENTITY`**가 사용

- **서비스 단에서 @Transactional(readOnly=true), @Cacheable(), @Scheduled()** -> 캐시랑 스케줄링 여기서 사용했다.  
  **쓰기모드 필요할때만 @Transactional 추가 선언**

  - ```java
    // value랑 cacheNames는 동일. 둘다 "캐시이름"의미. 하나 생략 가능.
    // key는 말 그대로 구분하는 키값
    // 만약 설정한 캐시매니저가 따로 있으면 cacheManager = "cacheManager2"
    @Cacheable(value = "members", key = "#pageId", cacheNames = "members") // [캐시 없으면 저장] 조회
    public List<FindMemberResponseDto> findAllWithPage(int pageId) {
        return memberRepository.findAllWithPage(pageId);
    }
    
    // 캐시에 저장된 값 제거 -> 30분 마다 실행하겠다.
    // 초(0-59) 분(0-59) 시간(0-23) 일(1-31) 월(1-12) 요일(0-6) (0: 일, 1: 월, 2:화, 3:수, 4:목, 5:금, 6:토)
    @Scheduled(cron = "00 30 * * * *") // 30분 00초 마다 수행
    @CacheEvict(value = "members", allEntries = true)
    public void initCacheMembers() {
    }
    ```

- **레포에서 em.createQuery()**할때 `.getResultList();` 로 반환받는게 꿀팁. null처리 용이함.
- jpql의 distinct는 sql에 distinct를 추가함과 동시에 영속성 컨텍스트의 중복엔티티도 제거

**컨트롤러**

- **json 형태 데이터로 바꿀때 에러 조심.** (jackson사용, writeValueAsString)

- ```java
  Map<String, LocalDateTime> map = new HashMap<>();
  map.put("startTime", st);
  map.put("endTime", en);
  ObjectMapper obj = new ObjectMapper();
  String content = obj.registerModule(new JavaTimeModule())
      .writeValueAsString(map); // Jackson 2.8.0 이전 버전에서는 JavaTimeModule 을 써야 에러 해결(직렬화 에러)
  ```

- 보통 @RestController + @RequestMapping + **@RequiredArgsConstructor** 조합 사용

  - @RequiredArgsConstructor 은 final 붙은 필드를 "인자로 받는 **생성자"를 자동 생성**  
    => **생성자 주입**이라고 함
  - 그래서 `private final ExpService expService` 만 선언해도 바로 사용 가능@

- **@RestController -> API, @RequestMapping("api/v1/members")** -> 전역 주소

  - @PostMapping, @GetMapping -> 주로 사용

  - **파라미터 요청이나 응답** 둘다 **DTO(+Valid)는 거의 필수** 사용하네

  - @RequestBody, @ResponseBody : HttpEntity 처럼 **HTTP 메시지 컨버터**가 **HTTP 메시지 바디**의 내용을 우리가 원하는 문자나 **객체(DTO) 등으로 자동 변환**!!

    - 요청(ex:json)엔 @RequestBody, 응답엔 @ResponseBody!! 없으면 @RestController에 이미 포함되어 있어서 생략한거임.
    - 응답엔 항상 `ResponseEntity.status(HttpStatus.NOT_FOUND).body(FAIL_LOGIN)` 이런 패턴 사용중임!

  - **세션 얻으려고 HttpServletRequest** 파라미터 받기도 함.

    ```java
    // 세션 있으면 세션 반환, 없으면 신규 세션 생성
    HttpSession session = request.getSession(); // UUID 형태로 알아서 생성 (기본값 : true)
    // 세션에 로그인 회원 정보 보관
    session.setAttribute(SESSION_NAME_LOGIN, findMember.getId());
    ```

- **DTO에서 lazy 강제 초기화 하고 있다.**

  - ```java
    List<Lists> listsList = listsService...
    List<ListsResDto> result = listsList.stream()
        .map(o -> new ListsResDto(o))
        .collect(Collectors.toList()); //반환 List타입 설정
    listsTasks = lists.getTasks().stream()
        .map(o -> new TaskDto(o))
        .collect(Collectors.toList());
    completedStatus = task.getTaskStatus().getCompletedStatus();
    timerOnOff = task.getTaskStatus().getTimerOnOff();
    ```

<br>

**언급안한 메인 코드는??**

- **interceptor 먼저 수행 후 -> argumentresolver 수행 순서**

  - 컨트롤러 쪽의 **argumentresolver패키지** -> 로그인 인증 담당**(세션 활용)**: memberId 반환
    - ArgumentResolver: HTTP 요청이 들어왔을 때, 요청의 데이터를 기반으로 컨트롤러 메서드의 매개변수에 적절한 값을 바인딩하는 과정을 담당
    - 애노테이션 생성 경험: @Login 생성. 정말 간단한 문법 제공
    - **즉, "컨트롤러 요청 전 파라미터에 중점"**
  - **interceptor 패키지는 컨트롤러 도달 전과 후**에 공통 수행 "좀 더 넓은 범위"
    - 인증 자주 사용 -> 회원 인증 사용했음. **(세션 활용)** -> preHandle() 오버라이딩
    - 컨트롤러 도달 후인 postHandle() 도 있다는거 기억만.

- **config 패키지는 기능확장!!** `@Configuration` 설정 -> 스프링은 WebMvcConfigurer 를 상속 받아서 스프링 빈에 등록 해서 기능을 확장 한다.

  - **인터셉터, ArgumentResolver 만든걸 다 여기서 add() 로** 기능 추가 하는것임!

    - 정적이미지 경로 핸들링 + **브라우저 캐시** 추가 -> `addResoucreHandler()`
      - 브라우저 캐시: 클라쪽 로컬 메모리 활용하는 것
    - CORS(Cross-Origin Resource Sharing) 해결 -> `addCorsMappings()`
      - 클라, 서버쪽 호스팅이 다르므로 CORS 설정은 필수!

  - **서버 메모리 캐시** 추가도 여러 방법이 있지만 여기선 CachingConfigurerSupport 를 상속 오버라이딩!! -> **CacheManager를 오버라이딩** 했음

    - ```java
      // 서비스단 메소드에 이런식으로 적용
      @Cacheable(value = "users", key = "#memberId", cacheNames = "users", cacheManager = "cacheManager2")
      
      // 스프링 빈 등록한 cacheManager2 로직에 Caffeine 사용
      cacheManager.setCaffeine(Caffeine.newBuilder()
                               .initialCapacity(1) // 내부 해시 테이블의 최소한의 크기 (캐릭터 어차피 1개만 기록)
                               .maximumSize(200) // 캐시에 포함할 수 있는 최대 엔트리 수 (멤버 200명 정도한테 적용하자)
                               //                .weakKeys() // 직접 키를 설정하므로 주석처리
                               .recordStats());
      ```

- **util 패키지의 Messages.java** -> 사실 messages.properties 설정을 다음에는 쓰려고 함.

  - WHY? 메시지 국제화 기능으로써 **여러 외국어도 지원**하게 만들기 수월하므로

- **aop 패키지의 TimeTraceAop.java** -> Aspect는 공통 기능 모듈화 (@Aspect)

  - @Around는 AOP의 어드바이스 타입 중 하나, 메서드 실행 전후 로직 실행 지원
  - proceed() 를 통해 원하는 시점 때 "실제 실행"을 지원 -> AOP 말고 실제 메서드

`HttpStatus` **클래스에서 제공하는 주요 상태 코드**

- **1xx: 정보 응답**

  - **100 Continue**: 클라이언트가 요청을 계속 진행해도 좋다는 의미입니다.

  - **101 Switching Protocols**: 서버가 클라이언트의 요청에 따라 프로토콜을 전환하고 있다는 의미입니다.

- **2xx: 성공**

  - **200 OK**: 요청이 성공적으로 처리되었습니다.

  - **201 Created**: 요청이 성공적으로 처리되어 새로운 자원이 생성되었습니다.

  - **202 Accepted**: 요청이 수락되었으나 아직 처리되지 않았음을 의미합니다.

  - **204 No Content**: 요청이 성공적으로 처리되었으나 반환할 내용이 없음을 의미합니다.

- **3xx: 리다이렉션**

  - **300 Multiple Choices**: 요청에 대해 여러 개의 선택지가 있음을 의미합니다.

  - **301 Moved Permanently**: 요청한 자원이 영구적으로 새로운 URI로 이동하였음을 나타냅니다.

  - **302 Found**: 요청한 자원이 다른 URI로 임시로 이동되었음을 의미합니다.

  - **304 Not Modified**: 클라이언트가 캐시한 자원이 수정되지 않았음을 나타냅니다.

- **4xx: 클라이언트 오류**

  - **400 Bad Request**: 요청이 잘못되어 서버가 이해할 수 없음을 의미합니다.

  - **401 Unauthorized**: 요청에 인증이 필요하며, 인증 정보가 없거나 유효하지 않음을 나타냅니다.

  - **403 Forbidden**: 서버가 요청을 이해했지만, 요청을 수행할 권한이 없음을 의미합니다.

  - **404 Not Found**: 요청한 자원을 찾을 수 없음을 나타냅니다.

  - **405 Method Not Allowed**: 요청한 HTTP 메서드가 해당 자원에서 지원되지 않음을 의미합니다.

- **5xx: 서버 오류**

  - **500 Internal Server Error**: 서버에서 요청을 처리하는 도중 오류가 발생했음을 나타냅니다.

  - **501 Not Implemented**: 요청한 메서드가 서버에서 구현되지 않았음을 의미합니다.

  - **503 Service Unavailable**: 서버가 현재 요청을 처리할 수 없음을 나타내며, 보통 서버가 과부하 상태이거나 유지보수 중일 때 발생합니다.

<br>

**API 명세서 + 포스트맨 다시 참고 및 테스트.** -> 명세서에 valid한 부분까지 추가는 안할래.

**nGrinder는 자바 버전때문에 동작 안할 것 같아서 했던거 복습만하자.(아래에 이미 예전에 정리했던게 있으니 그거 보자)**

**모니터링 체크와 CI했던 github action도 마찬가지로 아래에서 복습.**

- 모니터링, github action 둘다 검색하면 바로 아래에 있음.

<br><br>

## 23-12-01

**배운점, 느낀점, 보완할점?**

**배운점**

* 스프링MVC 패턴의 단위 테스트를 할 수 있게 되었습니다.
* DevOps를 다루는 경험을 할 수 있었습니다.
  * 사용 DevOps: 부하테스트(nGrinder), CI(Git Action), 모니터링(액츄어링, 프로메테우스, 그라파나)
* 최적화를 위해 SQL 쿼리튜닝을 경험할 수 있었습니다.
  - 사용 쿼리튜닝: 페이징, N+1해결(=JOIN), Index 사용

**느낀점**

* 서버 최적화를 하는 방법은 다양하단걸 느끼게 되었다.
* 특히 SQL 쿼리튜닝은 알면 알수록 내용이 방대했다.
* 또한, DevOps의 경우 굉장히 많았으며 개발에 많은 도움이 되는것을 체감하였다.

**보완할점**

* "배포"를 한다고 가정했을 때 보완할점들이 있다.

  - 현재 `단위테스트+CI` 까지 구축을 해서 테스트 속도를 향상시킨 상태이고, "배포"를 위한 CD(=Jenkins)까지 구축하여 테스트 속도를 향상시키겠다.

  - Docker로 이미지를 만들고 GCP의 Kubernetes로 배포 및 배포관리를 진행하겠다.

<br>

**마지막 연습할겸 진행할 할일**

* **리팩토링 - Valid, Exception => 여유있게 진행할 생각**

<br><br>

## 23-11-26 CI - Github Action

우선 본인 레포에서 해보고, 잘되면 실제 적용하던지 하겠음

배포는 따로 안하고 있으니까 CI 만 구축해보도록 하자.

* **CI 구축 이유**
  * 매번 main에 앱 업데이트 후 실행하여 정상 동작하는지 보는게 너무 귀찮
  * 제일 중요한 점은 열심히 작성한 단위테스트 코드들도 실행 가능
  * **따라서 테스트 시간을 대폭 단축**
    * **맨 처음 Unit Test Code** 작성으로 테스트시간 단축 후
    * **현재 CI** 까지 구축하여 테스트시간을 더욱 단축
* 참고 사이트 : [스프링&h2 - CI](https://jane514.tistory.com/4), [CI 속도향상](https://hellorennon.tistory.com/22)

<br>

**워크플로우 계획**

* main에 push 할 때 실행
* "정상 빌드" 확인
* "정상 테스트" 확인
  * test쪽 yml파일을 주석처리 함으로써 메모리DB 사용으로 h2 연결문제 해결

```yaml
name: CI Test

on:
  push:
#    branches: [ "main" ]
    branches: [ "kbh" ]
#  schedule:
  # - cron: '00 12 * * *' # UST 가 default. UST 10:00는 한국시간 21:00(9H 차이)
  # - cron: '00 19 * * *' # UST 가 default. UST 19:00는 한국시간 04:00(9H 차이)

jobs:
  build:
    runs-on: ubuntu-latest # 최신 우분투 사용

    # 루트 경로 지정(작업경로 지정) - 전역으로 지정한것
    defaults:
      run:
        working-directory: ./lepl

    steps:
      - uses: actions/checkout@v3

      - name: Set up JDK 17
        uses: actions/setup-java@v3
        with:
          java-version: '17'
          distribution: 'corretto' # JDK 17에 필수 temurin or adopt or corretto
      
      # 권한먼저!!
      - name: Grant execute permission for gradlew
        run: chmod +x ./gradlew

      - name: Setup Gradle
        uses: gradle/gradle-build-action@v2 # JDK 17지원
        with:
          arguments: build
          build-root-directory: ./lepl
          # cache-read-only: ${{ github.ref != 'refs/heads/main' && github.ref != 'refs/heads/develop' }}

      - name: New Gradle
        run: ./gradlew init

      # 빌드 -> 이때는 test 코드 실행 제외
      - name: Build with Gradle
        run: ./gradlew build -x test

      # 테스트 코드 (프로필로 실행)
      - name: Test with Gradle
        run: SPRING_PROFILES_ACTIVE=[test] ./gradlew test
```

<br>

**참고) 보통 gradle 빌드가 느리므로 캐싱으로 CI 속도를 향상 시킨다고도 한다.**

<br><br>

## 23-11-25 모니터링 알림

**모니터링 3단계** 

* 대시보드 
* 애플리케이션 추적 - 핀포인트(주로 HTTP 요청 추적)
* 로그

<br>

**3단계 중 대시보드를 구현하려고 함**

* 제품 : 마이크로미터, 프로메테우스, 그라파나 등등 
* 모니터링 대상
  * 시스템 메트릭(CPU, 메모리)
  * 애플리케이션 메트릭(톰캣 쓰레드 풀, DB 커넥션 풀, 애플리케이션 호출수) 
  * 비즈니스 메트릭(주문수, 취소수)

<br>

**액츄에이터, 프로메테우스, 그라파나 순으로 적용**

**액츄에이터**

* actuator 의존성 추가 + yml 설정
  * `implementation 'org.springframework.boot:spring-boot-starter-actuator' `
  * endpoints 기본 비활성화 되어있는것들을 전부 활성화로 세팅
* health, loggers, metric
  * health 에서 상태 OK이면 서버정상
  * 서버실행중에 loggers 레벨 변경가능
  * 자바 메모리 사용량 : `http://localhost:8080/actuator/metrics/jvm.memory.used`
  * HTTP 요청수 : `http://localhost:8080/actuator/metrics/http.server.requests`
* 보안을 위해서 내부망 포트로 수정하기도 한다는점 참고!
* **이러한 metric을 어딘가 지속 보관 및 대시보드로 확인을 위해 프로메테우스, 그라파나를 추가 적용**

<br>

**프로메테우스**

* 프로메테우스 설치 : `https://github.com/prometheus/prometheus/releases/download/v2.42.0/prometheus-2.42.0.windows-amd64.zip`
* 폴더에서 바로 실행 -> `http://localhost:9090`
* 각각의 metric들은 마이크로미터 표준 방식을 따르고 있기에 어떤 구현체인지만 지정해주면 되므로, 이를 위해 의존성으로 지정한다.
* 의존성 추가 : `implementation 'io.micrometer:micrometer-registry-prometheus`
  * 구현체 확인 : `http://localhost:8080/actuator/prometheus`
  * `http_server_requests_seconds_count` 의 숫자가 새로고침마다 변경됨을 확인할 수 있다.
* 수집 설정 - prometheus.yml(프로메테우스 폴더에 존재)
  * 타겟 주소, 프로메테우스 실행 주소 등등 설정
  * 특히, interval의 경우 임의로 1s로 하였고 실무에선 1m을 많이 한다고 함
* 대시보드는 그라파나로 보고싶기 때문에 그라파타 연동으로 넘어가자

<br>

**그라파나**

* 그라파나 설치 : `https://dl.grafana.com/enterprise/release/grafana-enterprise-9.3.6.windows-amd64.zip`
* bin폴더의 grafana-server 파일 실행해서 구동 -> `http://localhost:3000/login` 실행
* 프로메테우스와 연동
  * 설정에 Data sources 에 프로메테우스 `http://localhost:9090` 를 등록
* 다른 사람의 그라파나 사용
  * ID 11378 그라파나 사용
  * 추가설정 : Jetty 통계 -> Tomcat 통계
    * 이 대시보드는 톰캣이 아니라 Jetty라는 웹 서버를 기준으로 통계를 수집하기 때문
    * Jetty Statistics 부분 Title을 Tomcat Statistics로 변경
    * jetty_threads_config_max -> tomcat_threads_config_max_threads 로변경 
    * jetty_threads_current -> tomcat_threads_current_threads
    * jetty_threads_busy -> tomcat_threads_busy_threads
    * jetty_threads_idle 제거
    * jetty_threads_jobs 제거

<br>

**다음 3가지 반드시 구동 : 앱, 프로메테우스, 그라파나**

**주로 발생하는 4가지 예시**

* CPU 사용량 초과 
* JVM 메모리 사용량 초과 
* 커넥션 풀 고갈 
* 에러 로그 급증

<br>

**이런 공통적인 부분을 제외한 비지니스 부분 모니터링은?**

* 예로 주문수 같은 메트릭의 경우들은 직접 만들어서 등록해줘야 한다.
* **우리 프로젝트에서 넣을만한건?? -> 아래 2가지 정도만 추가해보겠음.**
  * 일정 등록수, 일정 완료수(경험치 보상) -> 이 2가지가 제일 사용 많을거라 생각하여..
  * **기존 Service는 남기기 위해 Task 부분만 인터페이스로 구현해서 테스트 해보겠음!!**
    * `http://localhost:8080/actuator/metrics/my.task` 에서 등록한 메트릭 확인
      * 등록한 name, method 등 참고하게 됨
    * `http://localhost:8080/actuator/prometheus` 에서 프로메테우스 포멧 메크릭 확인
      * 그라파나에 쿼리문 작성시 참고하게 됨
* **마이크로미터를 사용해 메트릭을 직접 등록**
  * 카운터와 게이지 중에 우리는 값이 증가만 하기때문에 **카운터를 사용**
  * **Timer도 사용**하여 실행시간 함께 보자
  * 이 모든걸 간단히 만들어주는것이 **`@Timed`**
    * Counter, Timer 둘다 간단히 제공
    * 원래는 Counter.builder... 또는 Timer.builder... 형태로 구현해줘야 함
* **모니터링 알림 참고 : [모니터링 Alert](https://cleaning-toolbox.tistory.com/94)**
  * 어떠한 값을 기준으로 Alert 발생시킬지 쿼리문 작성
  * 위험, 심각... 이런식으로 구별하여 알람을 받자.
    * **모니터링을 넣은 가장 큰 이유이다.**

![image](https://github.com/BH946/spring-second-roadmap/assets/80165014/1d7271c1-8daa-492c-a8c8-323406c6921e) 

![image](https://github.com/BH946/spring-second-roadmap/assets/80165014/94791ab9-4bab-43ff-b080-779f855f6907) 

<br><br>

## 23-11-23 (Pool 활용 부하테스트 개선) -> 개선은 이거까지만!

**+다중요청) DB Connection Pool, Thread Connection Pool**

* **Git merge 먼저 OK**
* **Thread는 일단 패스하겠고, DB Connection Pool은 당장 적용해보겠음**
  * pool size 도출 = ((core_count * 2) + effective_spindle_count) = 4*2+1=9
  * 음 근데 기본값이 10으로 잡혀있어서 그대로 사용하면 될듯!
  * 참고로 **스프링부트 yml 파일 HikariCP 설정** 로 간단히 바꿀수 있다.
* **[시리즈3 db 커넥션풀](https://hyuntaeknote.tistory.com/m/12)**
* **[Thread Pool 간단 적용법](https://velog.io/@rara_kim/Spring-Thread-Pool-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0feat.-Scheduler)**

<br>

**다음할거는??**

* **모니터링!!(=프로메테우스, 그라파나, 액츄에이터 사용) + CI/CD 중 CI만(=github action 사용) : 이번주말까지**
* **리팩토링 - Valid, Exception => 이건 여유있게 하면 될듯**

<br><br>

## 23-11-22 (본격 부하테스트 -> 성능개선) + Pool

**부하테스트로 성능비교 + 적절한 캐시 크기 함께 찾기**

* **nGrinder 테스트**
  
  * java11 버전 + cmd 사용
  * nGrinder 실행 : `java -jar ngrinder-controller-{version}.war --port=8300`
  * agent 실행시 `run_agent.bat`
  * 데이터 세팅 : 멤버1의 lists 데이터는 약 2만개, member 관련 데이터 약 4만개
  * db, 스프링, agent, ngrinder 재부팅 하면서 테스트 고고(혹시모르니)
* **참고) "조회 순서 때문에 Index 사용 안함 주의"**
  * 100% fetch join 부분들 때문이라 보면 됨
  * 예로 member desc 먼저 조회하고 character 외래키 하고 exp 외래키 순으로 index적용되어야 하는데,   
    캐릭터 풀스캔, exp 풀스캔, member 풀스캔.... 엉망이다.
    * 따라서 member -> character -> exp 순으로 조회되게끔 최대한 sql 수정해보자.
    * 생각한 아이디어는 서브쿼리를 활용하는것!
    * **참고 : [페이지네이션 최적화](https://taegyunwoo.github.io/tech/Tech_DBPagination#limit-offset-%EB%B0%A9%EC%8B%9D%EC%9D%98-%EB%AC%B8%EC%A0%9C%EC%A0%90)**
    * **JPQL로 서브쿼리는 from절에 사용불가하므로 이땐 "네이티브 쿼리활용!!"**

* **수정전 부하테스트 진행 -> 결과 꼭 기록(+사진)**

  * **시나리오1 -> 나중에 예외처리할 때 수정할 예정**
  * **시나리오3-2**
    * full scan 시? 약 2만개 : 5천개 17일자, 1만5천개 20일자
    * 스크립트 - scenario3-2.groovy 사용 / 에이전트1 / vuser500 / 2분 / Ramp-up (쓰레드, 단위10, 주기1000)
    * 컬렉션 페치조인이다 보니 h2 db에서 쿼리를 어떻게 작성해야할지 모르겠음.
    * 페치조인 제외하고 테스트를 해보면 "외래키Index" 사용중이라 그렇게 느리진 않음
  * **시나리오4**
    * full scan 시? 약 4만개
    * 스크립트 - scenario4.groovy 사용 / 에이전트1 / vuser500 / 2분 / Ramp-up (쓰레드, 단위10, 주기1000)
    * 캐시를 제거하고 테스트해서 성능개선 하겠음 (물론, 마지막에 캐시도 추가할거임)
    * **order by 때문에 매번 full scan을 하므로 TPS : 25, MTT : 12초 라는 최악의 성능을 보여준다.**

* **수정후 부하테스트 진행 -> 결과 꼭 기록(+사진)**

  * **시나리오3-2**

    * **`create index idx_member_id_lists_date on LISTS(MEMBER_ID, LISTS_DATE);` 인덱스 생성**

    * 아무리 서브쿼리를 사용하려고 한다고 해도 "컬렉션 페치조인" 이다보니 적용을 못하겠음

    * ```
      // h2 db
      set cache_size 0;
      explain analyze select * from (select l.* from lists l where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-16' and MEMBER_ID = 1) l;
      select * from (select l.* from lists l where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-16' and MEMBER_ID = 1) l;
      ```

  * **시나리오4**

    * **`create index idx_member_id on member(member_id desc);` 로 인덱스 생성할 것!**

      * 해당 Index를 사용하기 위해서는 JPQL을 수정해야 한다!! - 서브쿼리 사용

      * JPQL로 서브쿼리는 from절에 사용불가하므로 이땐 네이티브쿼리 쓸수밖에

      * **핵심은 Index 사용하는 부분을 "서브쿼리"로 가져와 나머지 JOIN**

      * **이때, JOIN들도 외래키로 등록된 Index 를 통해 빠르게 조회**

      * ```java
        return em.createNativeQuery("select m.member_id, m.nickname, e.level " +
                                    "from (select * from member order by member_id desc limit "+offset+","+limit+") m " +
                                    "inner join character c on m.character_id=c.character_id " +
                                    "inner join exp e on c.exp_id=e.exp_id;")
            .getResultList();
        ```

        ```
        // h2 db
        select m.member_id, m.nickname, e.level from (select * from member order by member_id desc limit 0,10) m inner join character c on m.character_id=c.character_id inner join exp e on c.exp_id=e.exp_id;
        ```

    * **일정 주기마다 데이터 캐싱초기화 - 스케줄링 사용(30분 주기로 설정) + "회원가입 로직 수정"**

      * 회원가입 로직에서 캐싱 초기화 함수 제거
      * **30분마다 실행하는 스케줄링 추가**

* **적절한 캐시 크기 결과 - 시나리오4**

  * 캐시 100 ? 캐시 1000 ? 막 극적으로 변하진 않고,
  * 또한 테스트하면서 느꼈는데 중복사용해야 캐시가 효과적이다.
  * 그렇다면,, 제일 많이사용하는곳은?? 당연히 앞쪽 페이지이다!
  * **결론 : 캐시 10~50정도로 적게 사용하자.**

* **성능비교 결과**

  * **h2 db**
    * 시나리오3 : 10ms -> 6ms
    * 시나리오4 : 80ms -> 3ms
  * **부하테스트 API**
    * 시나리오3 : XXXX 여긴 안하겠다. -> 손을못대겠음 ㅜ
    * 시나리오4 : 100배정도 개선

<br><br>

## 23-11-21 (sql 쿼리튜닝)

**시나리오3, 4 관련 성능개선을 먼저 해보겠다.**

* 시나리오3, 4 : 쿼리튜닝
* 이후 부하테스트를 통해 **성능개선 확인 및 시나리오4 의 적절한 캐시크기 찾기**

<br>

**시나리오3 : 쿼리튜닝**

* **적용해볼 쿼리튜닝은?? (앞서 정리한 내용들만 체크해보겠다.)**
  
  * 페이징 - 사용하지 않는다. 전체 데이터가 필요하기 때문
  * N+1문제 - join fetch로 해결된 상태
  * **Index 사용 - 적용해보겠다.**
    * 가급적 where 조건에는 Index 컬럼 모두 사용 -> 가급적 "=" 연산 사용(LIKE 같은것은 효율X)
  * UPDATE 대신 CASE 문 사용, 배치 모드로 Delete, Update 작업 - 조회라서 PASS
  * OR 보다는 AND 사용 - AND 사용중
  * 전체범위 처리, 부분범위 처리 - Index로 열심히 처리해보겠음
  * **distinct 는 가급적 사용X (내부적으로 정렬연산 발생하기 때문) - 가능한지 적용해보겠다.**
  
* **(1) index를 적용할만 한가?**

  * lists 테이블 특성상 lists_date 컬럼은 수정, 삭제가 거의 없다. 
  * 또한, lists_date를 where 절에서 항상 사용중이다.
  * 따라서 충분히 적용할만 하다.

* **테스트할 내용**

  * where문에 lists_date 와 memberId 를 index로 사용중이고,  
    memberId의 경우 외래키이기 때문에 외래키index가 존재해서 자동으로 사용중이다.  
    다만, lists_date + memberId 인 복합 index를 사용중인건 아니기 때문에 속도비교를 해보자
  * **3가지 테스트 : 외래키index / {lists_date, memberId} index / {lists_date, memberId} index**
  * **테스트 쿼리 : `select * from LISTS where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-18' and MEMBER_ID = 1;`**
    * 참고로 **6000개의 데이터** 존재
      * **11-17일자 1000개, 11-20일자 1000개, 11-21일자 1000개, 11-22일자 1000개, 11-23일자 1000개, 11-24일자 1000개 -> memberId = 1** 해당
      * 또한 총 member는 5만, lists도 5만6천개 정도 데이터가 존재중

* **(1-1) 외래키index**

  * 6ms / scanCount: 6002

  * scanCount가 6000개인건 memberId=1의 lists데이터가 6000개이기 때문

  * 따라서 member외래키 index로 바로 찾아가서 lists데이터 6000개를 전체 스캔

    ```
    explain analyze select * from "PUBLIC"."LISTS" use index (FKMRA2MVJOG7I44UKBKTJY3JIDL_INDEX_4) where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-18' and MEMBER_ID = 1;
    SET CACHE_SIZE 0;
    select * from "PUBLIC"."LISTS" use index (FKMRA2MVJOG7I44UKBKTJY3JIDL_INDEX_4) where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-18' and MEMBER_ID = 1;
    explain analyze select * from lists where member_id = 2;
    explain analyze select * from lists where member_id = 1;
    ```

    * 아래 explain 2줄은 확인용일 뿐

* **(1-2) {lists_date, memberId} index**

  * 17ms / scanCount: 50074 / reads: 2176

  * scanCount가 약 50000개인건 lists_date의 17일자 까지 데이터수는 약 50000개 이기 때문

  * member보다 lists가 보통 충분히 많으며, 여기서는 lists를 먼저 scan했기 때문에 이렇게 성능이 안좋게 나오는 것이다.

    ```
    explain analyze select * from "PUBLIC"."LISTS" use index (idx_lists_date_member_id) where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-18' and MEMBER_ID = 1;
    SET CACHE_SIZE 0;
    select * from "PUBLIC"."LISTS" use index (idx_lists_date_member_id) where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-18' and MEMBER_ID = 1;
    ```

* **(1-3) {memberId, lists_date} index**

  * 3ms / scanCount: 1002/ reads: 46

  * scanCount가 약 1000개 인건 index 덕분에 11-18일자 1000개 데이터를 바로 가져왔기 때문

    ```
    explain analyze select * from "PUBLIC"."LISTS" use index (idx_member_id_lists_date) where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-18' and MEMBER_ID = 1;
    SET CACHE_SIZE 0;
    select * from "PUBLIC"."LISTS" use index (idx_idx_member_id_lists_date) where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-18' and MEMBER_ID = 1;
    ```

* **(2) distinct 제거가능한가?**

  * lists와 tasks 는 1:N의 관계를 가지므로 fetch join시 "중복"존재
    * 데이터 뻥튀기 때문에 페이징도 불가 -> batch size로 해결해야함.
  * **1:1, N:1의** 관계의 경우 fetch join해도 데이터 뻥튀기 안되므로 "중복"없다고 볼 수 있음
    * 데이터 뻥튀기 없으니 페이징도 가능
    * **이 경우엔 전부 distinct 제거해도 될 듯?!**
  * 다만, 현재 시나리오3의 쿼리는 **1:N인** 컬렉션을 fetch join한 상태므로 "중복"존재
    * 일반 sql에 distinct는 db단에서 완전 동일한 중복을 제거하지만, jpql의 distinct는 일반 sql처럼 동작 + 앱에서도 중복 제거를 시도
    * **jpql의 특징때문에 오히려 쓰는게 좋다고 생각한다.**

* **정리**

  * **복합 index의 경우 컬럼의 순서가 매우 중요**함을 알 수 있다.
    * 실제로, lists_date컬럼이 먼저온 index의 경우 자동 생성되는 외래키 index가 훨씬 성능이 좋았다.
  * **제일 좋은것은 (3) {memberId, lists_date} index** 였으며 기존보다 **2배 성능**이 좋아졌다.
    * 외래키의 Index를 사용하고 있었기에 드라마틱하게 변할 쿼리문은 아니였다.
    * 다만, Index가 필요한데 사용안하고 있는 쿼리문이 있다면 성능을 6~10배는 올릴수 있겠다고 예상된다.
  * **1:N인 컬렉션 join fetch 이므로 distinct는 그대로 사용하겠다.**
    * 물론, distinct 자체를 사용하게 db설계를 했다는것은 db설계를 효율적이지 않게 설계했다고도 하는데 그렇게 딥하게 생각하지는 않겠다.

* **결론**

  * **`create index idx_member_id_lists_date on LISTS(MEMBER_ID, LISTS_DATE);` 로 인덱스 생성할것!**

<br>

**시나리오4 : 쿼리튜닝 + 캐시에 스케줄링!**

* **적용해볼 쿼리튜닝은?? (앞서 정리한 내용들만 체크해보겠다.)**

  * 페이징 - 사용중이다!! 여기선 필수로 사용할 것이다.
  * N+1문제 - join fetch로 해결된 상태
  * **Index 사용 - 외래키만 쓰면될듯해서 딱히.. 사용안할듯 하다.?**
    * 가급적 where 조건에는 Index 컬럼 모두 사용 -> 가급적 "=" 연산 사용(LIKE 같은것은 효율X)
  * UPDATE 대신 CASE 문 사용, 배치 모드로 Delete, Update 작업 - 조회라서 PASS
  * OR 보다는 AND 사용 - 아예 사용X
  * 전체범위 처리, 부분범위 처리 - 딱히 할게 없을듯?
  * distinct 는 가급적 사용X (내부적으로 정렬연산 발생하기 때문) - 사용안함

* **(1) Index..? 사용할만한가?? 페이징?? 고민**

  * 처음에는 OFFSET을 아예안쓰는 NO OFFSET 방식을 진행하려 했으나,
  * id를 기준 "최신순"으로 보여주고 있어서 해당방식은 id하나 삭제시 "순번이 망가진다."
  * 따라서 "커버링 인덱스" 라고 하여 Index 사용한 채 OFFSET 을 진행하려 했는데,
  * 레벨은 자주 변하는 컬럼이다보니 별루인듯 하다고 생각한다.
  * **제일 좋은건 멤버id기준 desc 정렬인 index를 사용하는게 좋아보인다.**
    * 실제로, 기존 쿼리의 문제는 매순간 order by 정렬의 문제... 즉, full scan의 문제..라 생각

* **테스트할 내용**

  * 새로 생성한 index 와 현재 상태 비교
  * **테스트 쿼리 : `select * from member m inner join character c on m.character_id=c.character_id order by m.member_id desc limit 10000,5;`**
  * 멤버 데이터 참고로 **5만개**정도 있음

* **(1-1) 기존 실행?**

  * 50ms / scanCount: 98146

  * scanCount가 약 10만개인건 join 때문인지 member 5만개, character 5만개 데이터 읽은거라 예상

  * order by 때문에 "전체범위 처리"이므로 기존 offset 1만을 읽는것도 문제지만 전체 5만을 다 읽는 더 큰 문제가 발생..

    ```
    explain analyze select * from member m inner join character c on m.character_id=c.character_id order by m.member_id desc limit 10000,5;
    SET CACHE_SIZE 0;
    select * from member m inner join character c on m.character_id=c.character_id order by m.member_id desc limit 10000,5;
    ```

* **(1-2) 새로운 Index?**

  * 12ms / scanCount: 20009 / index sorted

    * 신기하게 index sorted 라고 정렬된 index 사용한것을 알려준다.

  * scanCount가 약 2만개 인건 order by가 이미 적용된 index를 사용하게 되기 때문!

  * 따라서 기존 OFFSET의 문제인 해당 자리까지 데이터 읽는것 때문에 2만개일 뿐!

    * sql문에 offset 1만개로 설정되어 있기에 member 1만개, character 1만개 읽은 걸로 예상

  * `create index idx_member_id on member(member_id desc);`

  * `drop index idx_member_id on member;` 는 삭제

    ```
    explain analyze select * from member m inner join character c on m.character_id=c.character_id order by m.member_id desc limit 10000,5;
    SET CACHE_SIZE 0;
    select * from member m inner join character c on m.character_id=c.character_id order by m.member_id desc limit 10000,5;
    ```

    * **`order by member_id desc` 가 있으니 자동으로 index 사용**

* **(2) 캐시에 스케줄링은??**

  * **[랭킹시스템 DB](https://www.inven.co.kr/webzine/news/?news=265156)**
    * 시나리오4 가 사용자들을 조회하다보니 캐싱방식이 궁금했는데 해당사이트가 잘 정리되어있다.
    * **일정 주기마다 데이터 캐싱초기화! - 스케줄링 사용하자**
      * 대충 30분 주기로 설정하면 충분할듯
    * **따라서 현재 "회원가입" 때 캐시 제거를 했기때문에 이거 주석처리 해야한다.**

* **정리**

  * order by 한 index를 사용한 경우 거의 5배 가까이 성능이 개선되었다.
    * 물론 OFFSET의 문제는 가져가긴 하지만,
    * 제일 큰 문제인 매번 조회마다 "order by desc" 실행을 해결한것이 큰 이득이다.
  * 실제로 캐시를 사용하기에 좋은 API이기 때문에 반드시 적용할 생각이고, 데이터의 변경을 위한 캐시 갱신을 "스케줄링" 을 통해서 하자.

* **결론**

  * **`create index idx_member_id on member(member_id desc);` 로 인덱스 생성할 것!**
  * **일정 주기마다 데이터 캐싱초기화 - 스케줄링 사용(30분 주기로 설정) + "회원가입 로직 수정"** 

<br>

```
// h2에 사용.. 명령어들..

explain analyze select * from member m inner join character c on m.character_id=c.character_id limit 10000,5;
SET CACHE_SIZE 0;
select * from member m inner join character c on m.character_id=c.character_id limit 10000,5;

explain analyze select * from member limit 1000,5;
SET CACHE_SIZE 0;
select * from member limit 1000,5;


explain analyze select * from "PUBLIC"."LISTS" use index (FKMRA2MVJOG7I44UKBKTJY3JIDL_INDEX_4) where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-18' and MEMBER_ID = 1;
SET CACHE_SIZE 0;
select * from "PUBLIC"."LISTS" use index (FKMRA2MVJOG7I44UKBKTJY3JIDL_INDEX_4) where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-18' and MEMBER_ID = 1;
explain analyze select * from lists where member_id = 2;
explain analyze select * from lists where member_id = 1;

explain analyze select * from "PUBLIC"."LISTS" use index (lists_date_member_id) where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-18' and MEMBER_ID = 1;
SET CACHE_SIZE 0;
select * from "PUBLIC"."LISTS" use index (lists_date_member_id) where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-18' and MEMBER_ID = 1;

explain analyze select * from "PUBLIC"."LISTS" use index (idx_idx_member_id_lists_date) where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-18' and MEMBER_ID = 1;
SET CACHE_SIZE 0;
select * from "PUBLIC"."LISTS" use index (idx_member_id_lists_date) where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-18' and MEMBER_ID = 1;
```

<br><br>

## 23-11-20 (부하테스트, 쿼리튜닝 정리) + 할일

**어떻게 프로젝트에 적용할지 개념과 방법을 정리해보겠다.**

**1. 부하테스트??**

* `성능 테스트, 스트레스 테스트, 부하 테스트` 를 먼저 알아야 한다.
  * 성능 테스트가 제일 큰 개념 - 하위에 스트레스, 부하 테스트가 존재
    * 성능 테스트는 "임계치 이전, 초과" 모두 테스트
      * 앱 성능의 벤치마크(=성능 측정과 비교)와 표준을 설정하는 목적
    * **부하 테스트는 "임계치 이전" 까지 테스트**  
      * **과부하 데이터를 처리하는 방법을 확인 목적**
    * 스트레스 테스트는 "임계치 초과" 하며 테스트   
      * 임계치 초과니까 시스템 과부하에서의 작동방식, 장애복구 방식 등을 알아내는 목적
  * **[주요 차이점 - 성능, 스트레스, 부하 테스트](https://seongwon.dev/ETC/20220919-%EC%84%B1%EB%8A%A5%ED%85%8C%EC%8A%A4%ED%8A%B8-%EB%B6%80%ED%95%98%ED%85%8C%EC%8A%A4%ED%8A%B8-%EC%8A%A4%ED%8A%B8%EB%A0%88%EC%8A%A4%ED%85%8C%EC%8A%A4%ED%8A%B8%EB%9E%80/)**
* **"부하테스트 목적" : 시스템의 상한선을 식별하려면 앱의 SLA를 설정하고 시스템이 과부하 볼륨을 처리하는 방법을 확인한다.**
  * 즉, `volume test` 라고도 하며, `volume` 은 대량의 데이터를 의미
  * `SLA` 란 Service Level Agreement(서비스 수준 협약)
    * 자세히 알아보면 훨씬 방대한 내용을 가진다.
    * 지금 알아둘 수준은 **"제공할 서비스 수준"**이라고 볼 수 있다.
* **"부하테스트 도구" -> nGrinder 사용**
* 자세한 테스트 과정들은 `23-11-13 ~` 에 내용 참고

<br>

**1. 쿼리튜닝??**

* 쿼리튜닝은 서버 최적화처럼 **DB 성능개선을 위해 SQL 최적화**를 하는것이라 볼 수 있다.

* **`페이징, N+1 해결(=쿼리수 줄이기=적절한 JOIN사용=ORM의 문제 해결), Index 사용(단일 or 복합), db캐시(물론 db캐시는 안쓰고 서버,웹 캐시만 사용할 예정)` 전부 해당**한다고 생각한다.
  
  * 특히, 방법들이 다양하게 많다. - 자료첨부
    * **[더 빠른 SQL 쿼리를 위한 21가지 데이터베이스 튜닝 규칙](https://www.itworld.co.kr/tags/2665/SQL/105792?page=0,0)**
    * **[추가적인 튜닝 규칙](https://velog.io/@gillog/SQL-%ED%8A%9C%EB%8B%9D#%EC%B6%94%EA%B0%80%EC%A0%81%EC%9D%B8-%ED%8A%9C%EB%8B%9D-%EA%B7%9C%EC%B9%99)**
    * **[DB전문가의 TIP - Youtube](https://youtu.be/qY-nOOX_Smc?si=28sjP31btwGLlcDM)**
  
* **그렇다면, 적용해볼 쿼리튜닝 방식들은??**
  
  * **"전체범위 처리", "부분범위 처리"**
  
    * **좀 포괄적인 개념이다. Index도 포함 할 수 있고,, 기본적으로 인지해야할 부분이다.**
  
    * 전체범위 처리 예시 : `select * from 테이블 order by asc`
  
      * order by, count함수 등
  
      - Full Range Scan과 다를바 없다.
  
    * 부분범위 처리 예시 : `select * from 테이블`
  
      - Index를 타서 그부분만 읽던지, order by가 없던지 등
      - `select * from 테이블`은 데이터 처리하는 입장에서보면 테이블을 한바퀴 스캔할 필요없이 그냥 바로 테이블에 있는 데이터를 보여주면 되기 때문에 "부분범위 처리"
  
    * 참고 : **[전체vs부분범위 처리](https://kjw1313.tistory.com/m/96)**
  
  * Not 조건의 중요성 - “아니다”란 조건이 있으면 맞다는 조건을 찾을것
  
  * 페이징, N+1 해결(ORM의 문제로 발생)
  
  * UPDATE 대신 CASE 문 사용, 배치 모드로 Delete, Update 작업
  
  * OR 보다는 AND 사용, distinct 는 가급적 사용X (내부적으로 정렬연산 발생하기 때문)
  
  * 가급적 where 조건에는 Index 컬럼 모두 사용 -> 가급적 "=" 연산 사용(LIKE 같은것은 효율X)
    * `CHECKPOINT;` : db 버퍼 캐시 비우기 -> 테스트시 반드시 필수로 사용
    * `SET CACHE_SIZE 0;` : checkpoint 보다 이게 확실한 방법 (캐시 지우기)
      * 공식문서 한참 뒤지니까 나옴
    * `explain` : 반드시 사용해서 index 적용여부 확인
    * `use index` : index가 원하는대로 적용되지 않으면 직접 설정하라(방법은 다양함)
    * 참고로 예상이 안가면 할 수 있는 Index 를 다 적용해서 성능비교를 해보자
      * **필수 세팅 : "데이터 세팅(실제처럼)" + "SET CACHE_SIZE 0;(캐시비우기)"**
      * **예시로 `단일index, 복합index(컬럼순서중요), index사용X` 를 성능비교 해볼 수 있겠다.**
  
  * 다양한 예시들
    * [**DB의 페이지네이션을 어떻게 최적화-이해하기 좋음**](https://taegyunwoo.github.io/tech/Tech_DBPagination#limit-offset-%EB%B0%A9%EC%8B%9D%EC%9D%98-%EB%AC%B8%EC%A0%9C%EC%A0%90) : Index의 개념도 포함되어 있다.
    * **[SQL 튜닝 여러가지 방식](https://chung-develop.tistory.com/145)**
  
* **추가정보1) 발견한 특징??**

  * h2는 `explain analyze` 를 사용해야 rows 까지 확인 가능
  * Index에 사용한 컬럼 정보는 h2웹에서 직접 확인 가능
  * mysql의 `show index` 대신할 명령어 -> index 정보확인
    * `SELECT * FROM INFORMATION_SCHEMA.INDEXES WHERE TABLE_NAME = 'LISTS';`
  * 그냥 컬럼 정보는?
    * `SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = 'LISTS';`
  * 특히 "외래키 매핑" 하면 "**자동**으로 해당 외래키와 현재키 매핑한 Index 생성"
  * h2 db테스트 할때 처음 db connection 에 제일 많은 시간이 소요
    * 이는 db connection pool 기법을 활용해서 개선가능 (나중에 다룰 문제)
  * db connection 이후엔 캐시를 고려해야 함
    * 캐시를 제거안해주면, 정확한 속도 측정이 어려우므로 꼭 캐시 제거하면서 테스트하자
  * h2에 "최대 행 수" 부분을 전체로 해줘야 limit 설정을 적용하기 쉬우니 이부분도 체크

* **추가정보2) Index 사용 주의점**
  1. 인덱스는 **열 단위에 생성**
  2. 인덱스는 **WHERE 절에서 사용되는 열에 생성**
  3. WHERE 절에 사용되는 열이라도 자주 사용해야 가치가 있음
  4. 데이터 중복도가 높은 열에는 인덱스를 만들어도 효과가 없음 (선택도가 높은 경우는 효과 없음)
  5. **외래키를 설정한 열**에는 **자동으로 외래키 인덱스가 생성**됨
  6. **조인에 자주 사용되는 열**에는 인덱스를 생성하는 것이 좋음
  7. **데이터 변경(삽입, 수정, 삭제) 작업이 얼마나 자주 일어나는지 고려**해야 함
  8. 단일 테이블에 인덱스가 많으면 속도가 느려질 수있다. (**테이블당 4~5개 권장**)
  9. **클러스터형 인덱스는 테이블당 하나만** 생성할 수 있음
  10. 테이블에 클러스터형 인덱스가 아예 없는 것이 좋은 경우도 있음
  11. 사용하지 않는 인덱스는 제거
  12. 복합 인덱스는 **WHERE절에서 OR조건이 아니라 AND 조건일 때** 사용하는 것이 좋음
  13. [복합 인덱스의 컬럼 순서 결정법](https://khdscor.tistory.com/51)

* 자세한 테스트 과정들은 `23-11-17 or 23-11-21` 에 내용 참고

<br>

**그래서 뭐를 진행할까?**

* 앞서 진행한 부하테스트 **시나리오1,3,4**의 **부족한 부분 개선** -> 시나리오5는 나중에 생각
  * 시나리오1 : 예외처리 -> 마지막에 리팩토링할때 ㄱㄱ(검증, API예외처리 할 생각)
  * 시나리오3 : 쿼리튜닝
  * 시나리오4 : 적절한 캐시크기 찾기 & 쿼리튜닝
  * 여기서 언급한 **쿼리튜닝** 은?
    * 페이징, N+1 해결(=쿼리수 줄이기=적절한 JOIN사용=ORM의 문제 해결), Index 사용(단일 or 복합), db캐시(물론 db캐시는 안쓰고 서버,웹 캐시만 사용할 예정) 등등 전부 해당
* 모니터링
  * 모니터링 : 프로메테우스, 그라파나, 액츄에이터 사용
  * 인프런 강의에서 본 내용 그대로 따라할 예정 -> 그래서 금방 할 수 있을듯
* 배포자동화 - CI/CD (지속적 통합과 배포) -> 필수는 아닌데 하고싶음
  * 깃헙액션 쉬움, 젠킨스 복잡 -> 따라서 깃헙 액션으로 구성
* 마지막 refactor -> 검증 + 예외처리는 꼭 경험해야한다고 생각
  * valid, exception : 검증 과 API예외처리
* 솔직히 시간만 있으면 "도커"로 서버 구성하여 "배포"까지 할 생각

<br><br>

## 23-11-17 (쿼리튜닝 맛보기)

**시나리오 1~4 의 결론 -> 처리할차례(튜닝먼저도전!!)**

* 시나리오 1에서는 **예외처리**! -> 나중에 리팩토링할떄 ㄱ

* 시나리오 2에서는 **페이징** & 캐시(X 이건 프론트에서!) -> 일단 pass

  * 금일, 이번달, 이번년도, 전체년도... 생각해보면 그냥 시나리오3 밖에 안쓸듯?
  * 시나리오2는 일단 놔두자.

* 시나리오 3에서는 **(1)쿼리튜닝 & 페이징** & 캐시(X 이건 프론트에서!) -> 쿼리튜닝만 ㄱㄱ
  * 인덱스 쿼리튜닝 https://jie0025.tistory.com/509, https://leezzangmin.tistory.com/42, https://taegyunwoo.github.io/tech/Tech_DBPagination#limit-offset-%EB%B0%A9%EC%8B%9D%EC%9D%98-%EB%AC%B8%EC%A0%9C%EC%A0%90
  
  * 날짜를 매번 전체 비교하기 때문에 쿼리수정이 필요함을 느낌 -> "전체범위처리"
  
  * 솔직히 날짜로 분류했다 생각해서 일정 다가져와야하니 페이징은 필요없을듯?
  
  * =>> 인덱스 그래도 적용해보자.
  
  * **기존 속도 확인! -> offset 문제는 없다는점 참고**
    
    * **h2db :** `select * from LISTS where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-14' limit 10;`  
      => 테스트하기 쉽게 limit 10으로 (데이터10개) 비교하겠음  
      => 또한, 다른날짜 데이터가 많아야 속도 비교가 됨
      * 76ms -> explain 찍어보면 전체 테이블 스캔도 하고있음
      * id컬럼은 index존재한다지만 lists_date를 확인해보면 없음
    
  * **인덱스 테이블 추가 꼬꼬**
    
    * NO OFFSET으로 계속하고 인덱스를 추가하면 좋을듯! -> 쿼리튜닝!
    
    * `create index lists_date_index on LISTS(LISTS_DATE);`
      
      * `explain select lists_date from lists;` 입력시 index 사용을 확인가능
      
    * `select * from LISTS where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-14' limit 10;`
      
      * 4ms -> explain 찍어보면 index 사용중!
      
    * memberId 조건문 추가해보자 (이게 원래 사용중인 조건)
      * `select * from LISTS where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-14' and MEMBER_ID = 1 limit 10;`
      
      * 이 또한 4ms로 인덱스 바로 적용됨을 확인(아마 member외래키때매 자동으로 인덱스 추가되는게 있는듯?)
      
      * 단, 이렇게되면 lists_date 인덱스가 필요하긴 한건지 모르겠음..
      
      * memberId =1 로하고 lists가 진짜 수천개 가진 데이터에 테스트해봐야할듯  
        -> 1000개 데이터 생성해봤음
        
        * `select * from LISTS where LISTS_DATE >= '2023-11-10' and LISTS_DATE <= '2023-11-16' and MEMBER_ID = 1 limit 100;`
          
          * 13ms index추가전후 그냥 비슷..
          
          * 이미 외래키등록하면서 자동으로 뭔가 인덱스가 다 되어있나보다
          
            * 진짜 그런것같음 -> gpt는 맞다고 함 ㅇㅇ. 자동으로 인덱스 생성한다함.
          
            * h2 디비에선 show index... 명령어 못쓰니까 아래명령어 사용
          
            * ```
              1. explain 함수 사용 -> 외래키 index 사용 뜸
              explain select * from lists where lists_date = '2021-02-01' and member_id = 1;
              
              2. show index 대신할 명령어임 - index 정보 볼 수 있다.
              => 단, h2의 경우 무슨열의 index 인지 자세한건 직접 웹으로 확인!!
              SELECT * FROM INFORMATION_SCHEMA.INDEXES WHERE TABLE_NAME = 'LISTS';
              SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = 'LISTS';
              
              3. 무슨 index 사용할지 hint를 주는방법으로 사용하게 가능!!! 찾았네
              explain SELECT * FROM "PUBLIC"."LISTS" USE INDEX (idx_lists_date_member_id) WHERE "LISTS_DATE" = TIMESTAMP '2021-02-01 00:00:00' AND "MEMBER_ID" = CAST(1 AS BIGINT);
              ```
          
          * 흠.. 근데 아무리생각해도 여긴 패스하긴 해야할듯 -> 일단 다시 도전
          
            * 추측이지만 memberId 관련 외래키 index쪽에서 한번에 해당 member주소 찾아서! lists와 memberId 로 뭔가 있을듯?? 그래서 바로 lists 정보 들어가서
            * lists_date index가 있는거마냥 빠르게 동작될듯한데? ㄹㅇ
            * 다만 lists가 굉장히많다면?? memberId와 연관된 lists는 바로 찾았다고 해도
            * 해당 lists의 lists_date를 찾는과정에선 여전히 index 없는거나 마찬가지라 생각
            * 따라서 굳이 수정하고 싶다면 외래키 등록때 자동으로 index 만들어지는 부분에 lists_date를 추가로 넣어야 할듯?
          
          * **그래서 lists_date, member_id 두개 열로 구성한 복합 index를 만들어 사용해서**
          
          * **기존과 속도비교 해보겠다!**
          
            * 23ms vs 2ms => 충분히 더 빠른듯! => 근데 캐시되어서 이럴수도 있으니 다시확인해보자.
            
            * ```
              SELECT * FROM "PUBLIC"."LISTS" USE INDEX (idx_lists_date_member_id) WHERE "LISTS_DATE" = TIMESTAMP '2021-02-01 00:00:00' AND "MEMBER_ID" = CAST(1 AS BIGINT);
              SELECT * FROM "PUBLIC"."LISTS" USE INDEX (idx_lists_date_member_id2) WHERE "LISTS_DATE" = TIMESTAMP '2021-02-01 00:00:00' AND "MEMBER_ID" = CAST(1 AS BIGINT);
              select * from lists where lists_date = '2021-02-01' and member_id = 1;
              ```
            
            * 음? 캐시때문이었던거같음.. 속도 차이없는디
            
            * 아니 대체 왜없음? 속도차이 나야 정상아닌가? 
            
            * **현재 3개 index 비교중인데 데이터 좀 많이 넣고 테스트해보겠음..**
  
* 시나리오 4에서는 **수정... (1)캐시크기제한? & (2)쿼리튜닝**

  * 쿼리튜닝으로써 페이징으로 인한 limit offset의 의미없는 I/O는 없는지?? -> 존재

  * 잠시 캐시 제거후 **데이터... 3만개로... 확인.**..  
    **참고) 조회하면 버퍼캐시에 기록하므로 h2 db도 재접속하면서 테스트 할것**

    * **h2db : `select * from MEMBER limit 1, 10;` -> 4ms**
      * `select * from MEMBER limit 30000, 10;` -> 54ms
      * 속도차이는 limit offset 의 특징 때문! -> 30000까지 **데이터 스캔**

    * **스프링(처음 "db커넥트시간 제외") : pageId가 1일때 -> 21, 6ms**  
      (참고) 스프링과 db사이의 db커넥트시간도 따로 존재함을 인지! -> 그래서 db커넥션풀 존재
      * pageId가 3000일때 -> 129, 119ms
      * "실행계획"을 보면 스캔볼 수 있음 -> EXPLAIN 을 sql문 앞에 작성하면 볼 수 있음

  * **참고 : "실행계획" 예시들 -> 데이터 스캔과 인덱스 유무 체크 간단!**

    * `explain select uid from MEMBER;`

      ```sql
      PLAN  
      SELECT
          "UID"
      FROM "PUBLIC"."MEMBER"
          /* PUBLIC.MEMBER.tableScan */
      ```

    * `explain select member_id from MEMBER;`

      ```sql
      PLAN  
      SELECT
          "MEMBER_ID"
      FROM "PUBLIC"."MEMBER"
          /* PUBLIC.CONSTRAINT_INDEX_8 */
      ```

  * 생각해볼만한건 **NO OFFSET(인덱스사용) or 커버링 인덱스**

    * 물론, 잘 생각해보면 NO OFFSET 방식이든뭐든... 값 삭제되면.... 풀스캔 필요할듯

    * **잦은 인덱스 수정은 오히려 성능 다운 -> 이부분 조심!**
    * **이 또한 전부 인덱스 쿼리튜닝의 일종이라 생각**

  * **NO OFFSET(=커서 기반 페이징 방식)** 

    * 페이징 대신 where , id 조합 ㄲ -> id는 기본적으로 인덱스 컬럼 있을 
    * **`select * from MEMBER where member_id > 30000 limit 10;` -> 4ms !!**
      * **성능개선 : 기존 54ms에서 4ms로 성공**

  * **커버링 인덱스 : 쿼리에 사용되는 모든 칼럼을 가지고 있는 인덱스를 의미**  
    => 이는 인덱스에서 조회가 끝나는것이 가능하기에 성능개선이 가능하다는 것  
    => OFFSET을 계속 사용해야할 경우? n번째의 데이터를 얻고싶을때라 볼 수 있음

    * [**제일 이해하기 좋은듯 - DB의 페이지네이션을 어떻게 최적화**](https://taegyunwoo.github.io/tech/Tech_DBPagination#limit-offset-%EB%B0%A9%EC%8B%9D%EC%9D%98-%EB%AC%B8%EC%A0%9C%EC%A0%90)
    * 성능은 NO OFFSET이 훨씬 좋고, 커버링 인덱스는 굳이 `OFFSET` 을 사용할거라면! 사용!

  * **쿼리튜닝 결론 : NO OFFSET 이 유력**

    * Member 의 id 인덱스만 있으면 충분! id 컬럼은 특히 수정 안함!
    * 단, id 삭제의 경우는 ????? 문제인데????????
      * id가 중간에빠지면 기존엔 전부 스캔하기에 offset, limit가 정상인데
      * NO OFFSET은 where id > 30000 limit 10 이런식인데.. 30000이 문제.....
      * 1 2 3 4 5 6 7 8 10 11 12 13 14 15 16 17 18 19 20
      * 1 2 3 4 5 6 7 8 10 11 : pageId=0*10
      * 11 12 13 14 15 16 17 18 19 20 : pageId=1*10
      * 11이 또 나온 문제..

    * id 삭제의 경우가 해결이 안된다면 포기하고 캐시만 해야할듯 -> 포기
    * 커버링 인덱스를 적용해봤자 level같은 정보들이 자주 변경되므로 좋지가 않다고 생각

  * **찐 결론 : 커버링 인덱스나 NO OFFSET 사용하지말자, 캐시만 사용!**

    * **아니다 "커버링 인덱스"는 그래도 한번 해보자. 좋을수도??**

  * **캐시 사이즈 설정**
  
    * 캐시매니저 생성 후 "cacheNames = ..." 로 추가하겠음 (그래야 연동되는듯)
    * 캐시매니저에서 캐시크기 설정 : 100으로 일단 설정하고 몇개 페이지기록이 나을지는 부하테스트를 진행한 후 결정하겠음
    * `implementation 'com.github.ben-manes.caffeine:caffeine:3.1.1'`


<br>

**할일**

* 캐시매니저에서 캐시크기 설정 : 100으로 일단 설정하고 몇개 페이지기록이 나을지는 부하테스트를 진행한 후 결정하겠음
* 쿼리튜닝 할게없는것같음. 공부한것에 만족하겠음. -> 다시 찾아보겠음.
* mysql 쓸지도 고민. -> explain 에 rows 가져온 숫자까지 보여줫. h2는 안보여주는듯. 안보임
  * 방법을 찾았따. 역시 공식문서를 직접 찾아봐야겠네

* 이후에 모니터링 추가 및 시나리오5 도 해결

<br><br>

## 23-11-13 ~ 23-11-16 (부하테스트 첫시도)

* 테스트를 위한 코드는 구현 코드에서 분리되어야 한다.   
  =>"테스트를 위해 접근 제어자를 바꾸는 경우, 테스트 코드에서만 사용되는 메서드"
* **테스트 툴(부하테스트공부) -> 할차례**
  * **nGrinder(네이버 오픈소스) - 부하테스트**
    * 작성한 API 에 **병목 현상**과 얼마 만큼의 **트래픽을 수용**할 수 있는지에 대한 여부를 확인하고자 스트레스 테스트를 작성한다.
    * 아마 이 부하테스트를 통해서 api 장애 개선을 진행할 것이고,
    * 쿼리튜닝도 여기서 시도해보지 않을까 예상됨
  * **nGrinder 설치**
    * download nGrinder + agent 
    * nGrinder 실행 : `java -jar ngrinder-controller-{version}.war --port=8300`
    * agent 실행시 `run_agent.bat` 으로 실행성공..
    * Groovy(언어)는 JUnit 기반 동작. 자바처럼 JVM에서 동작
    * **Java 1.8과 11버전을 지원하므로 nGrinder+agent 실행할 때 꼭 유의!**
      * 이거때문에 **cmd**로 실행했음 (예전에 자바버전 쉽게변경하게 세팅해뒀어서)
      * **반드시 nGrinder와 agent 둘다 Java 1.8 or 11 로 해야함**
      * 포트 확인법(예:16001) : `telnet 127.0.0.1 16001`
    * **스크립트 생성 후 검증 테스트! -> 정상 동작**
    * **특히, 스크립트 오류찾을때 ngrinder 에서 제공하는 로그파일 확인**
    * **실제 시나리오(스크립트) 작성하여 "성능 테스트" 시작**
      * **실제 예상 시나리오 작성**해보겠음
  * **nGrinder 예상 시나리오 작성 -> 하는중!! (시나리오1 하는중)**
    * 예 : [회원가입]로그인 -> 장바구니에 상품 담기 -> 주문 순 등등
      * [참고](https://kirinman.tistory.com/m/102)
      * **한글!! 주의!! 인코딩 에러!! -> 그냥 영어로!! 하자!**
    * 보통 시나리오 단위테스트(+성능개선) -> 통합테스트(+성능개선) 순서대로 진행한다고함.
    * **시나리오1 : [회원가입] -> [로그인]**
      * @Test 로 전부 진행 -> **임의로 실행횟수 지정**해서 1000명 정도 테스트
      * 회원가입, 로그인을 각각 @Test 로 나눠서 스크립트 작성
    * **시나리오2-1 : [로그인] -> [일정 추가] -> [본인의 일정 전체조회]**
      * 임의로 실행횟수가 아닌 **"시간"** 을 설정
      * 이곳에 페이징이나 캐시 없어서 **일정 추가될수록** 아마 성능 안좋게 나올거로 예상
      * [로그인] : @BeforeProcess (uid:123 으로 로그인하겠음)
      * [일정 추가] -> [본인의 일정 전체조회] : @Test (나눠서 스크립트 작성)
    * **시나리오2-2 : [로그인] -> [본인의 일정 전체조회]**
      * 임의로 실행횟수가 아닌 **"시간"** 을 설정
      * 시나리오2-1 방식에서 "일정추가" 만 제외하고 vuser 대폭 키워서 테스트할 목적
      * 데이터 5천개 이상을 조회 가정 (시나리오2-1 실행시 이정도 추가됨!)
    * **시나리오3-1 : [로그인] -> [일정 추가] -> [본인의 해당 날짜 일정조회]**
      * 임의로 실행횟수가 아닌 **"시간"** 을 설정
      * [로그인] : @BeforeProcess (uid:1234 으로 로그인하겠음)
      * [일정 추가] -> [본인의 해당 날짜 일정조회] : @Test (나눠서 스크립트 작성)
    * **시나리오3-2 : [로그인] -> [본인의 해당 날짜 일정조회]**
      * 임의로 실행횟수가 아닌 **"시간"** 을 설정
      * 시나리오3-1 방식에서 "일정추가" 만 제외하고 vuser 대폭 키워서 테스트할 목적
      * 데이터 5천개 이상을 조회 가정 (시나리오3-1 실행시 이정도 추가됨!)
    * **시나리오4 : [전체 멤버 조회(팔로우에 보여줄)]**
      * 임의로 실행횟수가 아닌 **"시간"** 을 설정
      * 로그인 인증 필요없음 + 페이징 + 캐시 적용상태 -> 캐시때매 성능 좋게나올듯
      * pageId 25 제한으로 Member 250개 데이터 확인하게끔
      * [전체 멤버 조회] : @Test
    * **시나리오5~** : **캐릭터부분**... -> 모니터링 추가하고 이부분 추가 테스트 하겠음ㅇㅇ
  * **nGrinder 동작순서**
    * [참고](https://jerry92k.tistory.com/48)
    * @BeforeProcess -> @BeforeThread -> HTTP 요청 순서
    * @Before 의 경우 각각 @Test 실행전에 반복 실행
    * **개인적인 생각**
      * **(1)여러 사용자의 로그인이 필요없다면 로그인 로직을 @BeforeProcess**
        * EX) [회원가입] -> [로그인] -> [로그인필요한 페이지] 테스트의 경우?
        * **로그인필요한 페이지만을 테스트하려는 목적만 강하다면,**
        * [회원가입] -> [로그인] : @BeforeProcess
        * [로그인 필요한 페이지] : @Test
      * **(2)여러 사용자의 로그인이 필요하다면 @BeforeThread**
        * EX) [회원가입] -> [로그인] -> [로그인필요한 페이지] 테스트의 경우?
        * **여러 사용자의 회원가입이 중요하다면,**
        * [회원가입] -> [로그인] : @BeforeThread
          * 설정한 스레드수 만큼 회원가임+로그인 동작
        * [로그인 필요한 페이지] : @Test
          * 설정한 실행횟수 만큼 @Test 동작
      * **(3)로그인+로그인필요 사이트 테스트는 @Before**
        * EX) [회원가입] -> [로그인] -> [로그인필요한 페이지] 테스트의 경우?
        * **회원가입 + 로그인필요 사이트 둘다 중요하다면,**
        * [회원가입] -> [로그인] : @Before
          * "쿠키"를 static 으로 관리하다보니 @BeforeThread 에선 
          * Thread 시작전에 @BeforeThread 있는거 전부 실행해버려서 쿠키가 겹침
          * 단, @Test 쪽이기 때문에 "시간"으로 설정시 굉장히 많은 회원가입 발생
        * [로그인 필요한 페이지] : @Test
      * **(4)else의 경우 ? -> 로그인 인증 필요없는걸 의미**
        * 그냥 @Test 에 다 하면 될듯
  * **nGrinder 부하테스트 결과 분석**
    * 결과 분석할줄도 알아야함 -> 공부필요..
      * 테스트 용어 참고 https://gogoonbuntu.tistory.com/m/83#77
      * 시리즈1 Throughput, Latency : https://hyuntaeknote.tistory.com/m/10
      * 시리즈2 Throughput, Latency 테스트적용 분석 + 동시사용자 일반사용자 https://hyuntaeknote.tistory.com/m/11
      * 시리즈3 db 커넥션풀 https://hyuntaeknote.tistory.com/m/12
      * 프로세스 스레드 차이 http://ngrinder.373.s1.nabble.com/process-thread-td2636.html
      * 페이징 유무에따른 차이 테스트 https://kth990303.tistory.com/446
      * 쿼리튜닝 여러방법 https://kth990303.tistory.com/446
      * 인덱스 쿼리튜닝 https://jie0025.tistory.com/509
    * 시나리오1의 경우?
      * 첫번째 시나리오1 테스트는?
        * 프로세스2, 쓰레드500, 실행횟수1, Ramp-Up 주기 500에 증가단위1 -> vuser:1000
        * 테스트 횟수는 1000이 될때까지 돌아감
        * 실행횟수와 Ramp-up 으로 인해 TPS는 적당히 잘 나오는듯 하다?
        * 에러의 원인은 대부분 중복uid 로써 서버에서 **500 이미등록회원 에러**가 터진다.
          * 나중에 예외처리할때 이부분 꼭 예외처리!
      * 두번째 시나리오1 테스트는?
        * 프로세스1, 쓰레드500, 실행횟수1, Ramp-Up 주기 1000에 증가단위1 -> vuser:500
        * 테스트 횟수는 500이 될때까지 돌아감
          * 참고로 회원가입, 로그인을 각각 @Test 로 나눠서 스크립트 작성해서
          * 총 테스트 횟수가 500인데 실제 db에 250개가 등록되는 것 (실제로 에러0에 db250개)  
            -> 매우 안전하게 돌렸기에 에러도 거의 없는것
          * 즉, @Test 2개라서 통틀어서 1회로 보는게 아니라 각각을 1회, 2회로 보는듯 함
    * 시나리오2-1의 경우? 
      * vuser:100 에 시간 1분설정 및 Ramp-Up 주기 1000에 증가단위 10  
        -> **10초뒤면 vuser 100**(=스레드100) 이 됩니다
      * TPS 그래프를 보면, 10초까지는 "일정추가+스레드증가" 때문에 **제일 가파르게** TPS가 낮아짐 
        * 10초 이후는 "일정추가" 만 있으니 초반 보다는 **가파르진 않음**
      * 다행이 **에러는 전혀 없는**걸 보니 사용자 100명은 충분히 감당 되는듯 하다.
      * **TPS도 200**대는 넘어서 괸찮은듯 하다. (단, 데이터가 커질수록 100아래로도 줄어듬 ㅜ)
      * **단, vuser를 대폭 키워서 "일정조회" 만 한번 테스트 해보겠음 -> 시나리오2-2**
    * 시나리오2-2 의 경우? -> 에이전트 CPU100%, MEM85%(근데 로컬이라... 서버쪽이랑 비교를 못할듯. 서버도 로컬에서 구동중이라..)
      * vuser:500 에 시간 2분설정 및 Ramp-Up 주기 1000에 증가단위 10  
        -> **50초뒤면 vuser 500**
      * 결과보면 **에러**가 많진않지만 생겼음
      * 평균 테스트시간(MTT)이 굉장이 높아짐 **약5초..**
      * **TPS가 73** -> 사용자가 500명 잡았는데 73이면 매우 성능이 안좋은것
    * 시나리오3-1 의 경우?
      * vuser:100 에 시간 1분설정 및 Ramp-Up 주기 1000에 증가단위 10  
        -> **10초뒤면 vuser 100**(=스레드100) 이 됩니다
      * TPS 그래프를 보면, 10초까지는 "일정추가+스레드증가" 때문에 **제일 가파르게** TPS가 낮아짐 
        * 10초 이후는 "일정추가" 만 있으니 초반 보다는 **가파르진 않음**
      * 다행이 **에러는 전혀 없는**걸 보니 사용자 100명은 충분히 감당 되는듯 하다.
      * **TPS도 200**대는 넘어서 괸찮은듯 하다. (단, 데이터가 커질수록 100아래로도 줄어듬 ㅜ)
      * **단, vuser를 대폭 키워서 "일정조회" 만 한번 테스트 해보겠음 -> 시나리오3-2**
    * 시나리오3-2 의 경우?
      * vuser:500 에 시간 2분설정 및 Ramp-Up 주기 1000에 증가단위 10  
        -> **50초뒤면 vuser 500**
      * 결과보면 **에러**가 많진않지만 생겼음
      * 평균 테스트시간(MTT)이 굉장이 높아짐 **약5초..**
      * **TPS가 79** -> 사용자가 500명 잡았는데 79이면 매우 성능이 안좋은것
    * 시나리오4 의 경우? CPU-99% MEM-85% RX-66.0B TX-0.0B
      * vuser:500 으로 2분간.. 테스트했는데 너무 TPS가 좋게나옴
      * 캐시와 페이징 덕분일거임.
    * **시나리오 1~4 의 결론**
      * 시나리오 1에서는 **예외처리**!
      * 시나리오 2에서는 **페이징** & 캐시(X 이건 프론트에서!)
      * 시나리오 3에서는 **쿼리튜닝 & 페이징** & 캐시(X 이건 프론트에서!)
        * 인덱스 쿼리튜닝 https://jie0025.tistory.com/509, https://leezzangmin.tistory.com/42
        * 날짜를 매번 전체 비교하기 때문에 쿼리수정이 필요함을 느낌
      * 시나리오 4에서는 **수정할게 없을듯. 굳이할거면.. 캐시?크기?제한?**
  * **용어**
    * TPS(=Test Per Seconds) : 초당 테스트 개수
    * MTT: 평균 테스트 타임(vuser와 비례관계)
    * MTFB: 평균 첫 번째 바이트 도달 시간(=Response Time으로 볼 수도 있다.)
    * 테스트 기간 : 요청후 응답받으면 바로 다시 요청보내고, 설정한 시간만큼 진행한다.
      * @Test(+@Before) 이부분을 의미!
      * 따라서 설정한 시간만큼 엄청많이 테스트 함
    * 실행 횟수 : 스레드당 몇번 테스트할지 직접 설정할 수 있다.
      * @Test(+@Before) 이부분을 의미!
      * 따라서 설정한 횟수 만큼 테스트 함
    * GTest 객체 : 각각 테스트 시나리오 (@Test에 작성하는것)
* 모니터링
  * 모니터링 : 프로메테우스, 그라파나, 액츄에이터 사용

<br><br>

## 23-11-09 (리팩토링... + DevOps 계획)

* **임시 refactor:** 
  * **전체적으로... 특히 Setter는 다 지우자.(양방향 매핑빼고 별루라는듯?)**
    * 이를 정적 팩토리 메서드로 많이 하는듯.
    * 생각해보니 private 필드는 외부에서 객체.필드 로 접근 안됨
    * Setter 지우면될듯
  * +**@NoArgsConstructor(access = AccessLevel.PROTECTED)** 
* **모니터링 + 테스트 툴(부하테스트공부) -> 할차례**
  * 모니터링 : 프로메테우스, 그라파나, 액츄에이터 사용
  * 테스트툴 ?? : ...앵그라인더(부하테스트)
    * https://leezzangmin.tistory.com/42
    * 아마 이 부하테스트를 통해서 api 장애 개선을 진행할 것이고,
    * 쿼리튜닝도 여기서 시도해보지 않을까 예상됨
* 배포자동화 - CI/CD (지속적 통합과 배포) -> 필수는 아닌데 하고싶음
  * 깃헙액션 쉬움, 젠킨스 복잡 -> 따라서 깃헙 액션으로 구성

* 쿼리튜닝이 정확히 뭐지?? -> 쿼리튜닝 공부해서 적용해야겠음.
  * **fetch join은 1+N 문제 해결방안** 인듯 하다. 쿼리튜닝이라고 칭하긴 좀 그런거같다.
  * 그럼 쿼리튜닝은?? 뭐지? 대표적인게 인덱스 조회?? 가 있는듯 하다.
* ++++refactor -> 필수는 아니고,, 하거나 말거나
  * 스프링데이터JPA혹시 사용할수 있게끔 레포지토리를 인터페이스....추가..
  * valid, exception...??

<br><br>

## 23-10-31 ~ 11-08 (리팩토링:MockMvc 첫시도)

**할일**

* 기능추가 - 상점,아이템 ( +캐시 ) -> DB설계까지.. 완.

  * 캐릭터에 화폐필드 추가

  * 캐릭터아이템에 아이템ID를 외래키로

  * 아이템 테이블 추가!
  * **나머지 API 구현은 유진님이 하고 계시는듯!**
* 경험치 리팩토링 -> **굿(유진님 개발!)**
* ++++test: 테스트코드 컨트롤러(MOCK)

  * 기존 테스트코드부터!! 새로!! 다시! 최대한 Assert로!
    * DOMAIN 먼저
      * character 완료(아이템구현후 캐릭터는 추가로!).
      * member 완료
      * task 완료
    * REPOSITORY
      * character 완료
      * member 완료
      * task 완료
    * SERVICE
    
      * character 완료
      * member 완료
      * task 완료
    * CONTROLLER -> **MockMvc 먼저 공부**
    
      * member 완료
      * character 완료
      * task 완료


<br><br>

## 23-10-17~24

**최적화**

* 브라우저 캐시 : 3d에셋 서버에 저장 후 스프링에 캐시 사용 -> 이 url을 threejs에 넘겨줘서 사용
  * 정적파일 캐싱 한줄로 끝내기.
* 서버 캐시(ex:@Cacheable, @Cacheput)
  * 팔로우(공통), 일정(앱단에서 기록), 캐릭터(상점,??)
* 쿼리튜닝(+코드 리팩토링)
  * **읽기전용쿼리힌트(레퍼지토리), 읽기전용트랜잭션사용(서비스)**
* 상점 테이블이나 아이템 테이블...!! 추가
  * !!@!@!@!@!@!@!@!@!@!@!@!!!
  * **테스트코드 컨트롤러도 나중에 작성 ㄱㄱ**
* 모니터링(인프런), 로드밸런싱([참고1](https://velog.io/@korea3611/Spring-Boot-Spring-Cloud-Gateway-Load-Balancer-MSA5), [참고2](https://kimyhcj.tistory.com/entry/Spring-Cloud-%EC%8B%9C%EB%A6%AC%EC%A6%88-5-Loadbalancer-feat-Ribbon)) 등등
  * 로드밸런싱은 방법이 다양함. 그냥 쿠버네티스로 배포 다 관리하고 싶긴함. 아니면 nginx 설치해서 로드밸런싱 한다던지.
    * 쿠버네티스?? 클라우드환경이라 비용생각해야함.
    * nginx?? 로컬에 설치해야하는데 그렇게 하기는 싫음.

  * 다만, 그건 최종 배포할때 결정하면 되는 문제라고 생각해서 그냥 본인 로컬에서 테스트 해볼수 있는 방안으로 생각을 돌림.
    * Eureka 란것을 사용하면 되는듯 하다. 위에 로드밸런싱 참고1,2 사이트함께 참고할것
    * https://cjw-awdsd.tistory.com/52

<br>

**할일**

0. AOP로 시간측정 코드 추가(최종 때 모니터링으로!!)  
   +쿼리 join조차 안쓴 코드로 바꾸기(Lists레포만 해당->findAllWithMemberTask,findByDateWithMemberTask !!)  
   +꼭 따로 복제하든 커밋으로 남겨두든하자  
   +추후에 모니터링때 비교위해서!
   * **OK**
1. 각 기능별 쿼리수, 시간 정리(적당히 캡쳐도)
   * 일정 조회(all, date) 부분
     * all(해당멤버의 모든 일정)
       * 일정 3개 조회 시간(all) : 46ms
       * 일정 3개 조회 쿼리(all) : 5개
     * date(해당멤버의 지정한 날짜범위 일정)
       * 하루 일정 2개 조회 시간(date) : 27ms
       * 하루 일정 2개 조회 쿼리(date) : 4개
   * 경험치 부분(리팩토링 필수)
     * expTask(일정 완료시 경험치)
       * Task(여러개가능) 1개 완료 시간 : 45ms
       * Task(여러개가능) 1개 완료 쿼리 : 14개..
     * expTimer(타이머 완료시 경험치)
       * Timer(1개만) 1개 완료 시간 : 48ms
       * Timer(1개만) 1개 완료 쿼리 : 8개..
   * 팔로우 부분(조회)
     * 시간 - 14ms
     * 쿼리 - 2개
   * 멤버 조회
     * pass
   * **OK(쿼리많은이유는 LAZY라서 어쩔수없음)**
2. 쿼리튜닝,코드리팩토링작성 한후의 쿼리수 정리    
   +인터셉터 추가수정 - 로그인때 멤버 조회하는겸 캐릭터ID도 같이 조회해두는게 좋을듯  
   +서버캐시도 바로 진행후 테스트 -> "팔로우"만
   * 캐릭터ID, 팔로우 서버캐시
     * 캐릭터 조회를 서버캐시로 기록해두는걸로 하겠음 - resolveArgument에서 따로 DB조회 하는건 굉장히 쿼리 낭비인것 같고, 캐릭터는 회원ID 만큼이나 많이 쓰이게 되기 때문
       * 참고로 멤버ID 는 이미 세션 메모리 사용중
       * **알림, 팔로우 부분에 findCharacterWithMember(캐시) 로 적용!**
     * 팔로우 캐시?
       * 팔로우 추가에 회원가입처럼 **"중복검증 로직 추가"**
       * **전체 멤버 조회 로직 작성후(페이징필수) 캐시 적용**
         * 팔로워순, 랜덤순 이런건 일단 프론트에서 할수도있으니 디테일한건 패스
   * 일정 조회(all, date) 부분
     * all(해당멤버의 모든 일정)
       * 일정 3개 조회 시간(all) : 30ms
       * 일정 3개 조회 쿼리(all) : 1개
     * date(해당멤버의 지정한 날짜범위 일정)
       * 하루 일정 2개 조회 시간(date) : 9ms
       * 하루 일정 2개 조회 쿼리(date) : 1개
   * 경험치 부분(리팩토링 필수) -> 나중에.... 수정..
     * expTask(일정 완료시 경험치)
       * Task(여러개가능) 1개 완료 시간 : 
       * Task(여러개가능) 1개 완료 쿼리 : 
     * expTimer(타이머 완료시 경험치)
       * Timer(1개만) 1개 완료 시간 : 
       * Timer(1개만) 1개 완료 쿼리 : 
   * 팔로우 부분(조회)
     * 시간 - 3ms
     * 쿼리 - 1개(캐시 캐릭)
   * 멤버 조회
     * 시간 - 44ms => 캐시? => 1ms (쿼리0개)
     * 쿼리 - 1개(join fetch)
3. 브라우저 캐시 - 일단 img!!  
   => 이건 three js 돌려서 브라우저에 저장잘되는지 테스트필수  
   => 꼭 캐시전 img로딩 시간과 캐시후 img로딩 시간기록  
   => 이때 3d에셋 예전꺼 받아서 그 이미지와 새로 경랑화된거 구매한 이미지 둘다 테스트 기록!!  
   * 웹 브라우저에서 같은 탭에서 새로고침이나 url요청시 캐시 무시되기도 한다고해서
   * **새로운 탭으로 계속 테스트**하자
   * 되는것같으면 **반드시 three js 로 확인!!**
     * **CORS 해결**
     * **OK**
4. 서버 캐시 - 팔로우(공통), 상점(이건 말만하자. 최종때개밝.)  
   => 이것도 꼭 적용전과 후 속도차이 !!!!! 기록!!  
   => 쿼리가 안날라가서 굉장히 빠를거임.
   * 위에서 이미 적용했음!. **OK**

<br>

**경험치부분 꼭 리팩토링 해야함.**

<br><br>

## 23-10-13

**타이머 구현완료**

* 클라한테는 밀리세컨 단위로 "사용시간" 보내달라 하기
* 서버 DB는 Long 타입으로 "현재시간, 타이머총사용시간, 잔여시간" 구성
  * 단, 일정조회 관련 컨트롤러로 클라한테 반환할때는 "시:분:초" 형태로 바꿔서 반환
  * 구현쉽게 String으로 반환

<br>

**최적화 적용연습**

<br><br>

## 23-10-12

**경험치 체계 확립**

* `=INT((A2-1)^1.2)+10` 이걸로 일단 진행 및 상한선 레벨 100 지정
  * 1년간 시즌제를 통해서 만렙이 100정도까지 경험치 얻을수 있음.
* 물론 추후 테스트를 진행하면서 바뀔가능성도 높음

**타이머 구조 정리 -> "사용시간" 밀리세컨 단위로 달라할것**

* 타이머 테이블 삭제해야 할 듯
  * 여기있던 "집중,허용"상태는 따로 앱사용시 타이머 일시정지로 만들어버리는걸로 **질문방지**
* 클라이언트에서 "사용시간"을 전송
  * 일정추가{시작, 끝, 내용}
    * 일반 일정 -> 체크표시로 완료 전송(클라에서)
      * expUpdate 사용!
    * 타이머 일정 -> 체크표시 사용X. 무조건 종료때!
      * if 타이머상태OFF : 일정상태{타이머상태ON}, 일정{잔여시간}, 리스트{총사용시간}, 리스트{현재시간} 기록
      * else : 일정{잔여시간}, 리스트{총사용시간}, 리스트{현재시간} -> **시간계산**
        * if,else 타이밍은 타이머 종료때로 볼 수 있다.
        * 단, if면 초기 타이머 생성단계. 즉 초기화 단계
    * 시간계산과정
      * if -> 초기화 과정으로 보면 됨
        * 타이머상태 = ON
        * (TASK)잔여시간 = (끝시간 - 시작시간) - "사용시간"
        * (LISTS)타이머총사용시간 += "사용시간"
        * (LISTS)현재시간 += "사용시간"
          * **시간계산**
      * else
        * 잔여시간 -= "사용시간"
        * 타이머총사용시간 += "사용시간"
        * 현재시간 += "사용시간"
          * **시간계산**
      * **시간계산 -> 시간만 경험치 업데이트에 사용**
        * if 현재시간/시간 == 0 : pass
        * else
          * 경험치시간=현재시간/시간
          * 현재시간=현재시간%시간
          * **expUpdate(경험치시간)**
* **일정완료 컨트롤러에서** 타이머상태 조건문에 따라
  * 일반일정완료, 타이머일정완료 구현
  * **사용시간(클라) : 밀리세컨단위로 클라에게서 받기!**
  * **현재시간(계산용), 잔여시간, 타이머총사용시간 : 밀리세컨단위로 기록하기! -> 즉.. 전부다 밀리세컨!**
    * 왜냐하면 날짜로는 기록할수가 없음. 시간타입으로도 24시간을 넘어가서 기록이안됨
    * **애초에 Long으로 DB에 기록하고, 클라에 줄때 String으로 {시:분:초}로 보내**줘야할듯 ㅇㅇ

<br><br>

## 23-09-27 ~

**경험치 수식 재정립**

* 기존공식에 레벨당 필요경험치를 더욱 낮추자.
  * 초반, 중반, 후반에 레벨난이도는 갈수록 어려워지는게 맞을까?
    * **장점 : 레벨이 높을수록 확실히 강해지는 효과**
    * 단점 : 경험치 보상은 일정해서 레벨업이 힘듦. 뽑기도 자주 못하게됨.
    
  * 아니면 일정한게 맞을까?
    * **장점 : 레벨업이 매우 수월(쉬움). 이로인해 잦은 뽑기**
    * 단점 : 레벨업이 너무쉬워서 레벨의 의미가 약해지므로 동기부여가 제한
    
  * **결론1 : 두 장점을 가져가게끔 중간지점을 찾는다면?**
    
    * 레벨업을 쉽게하기 위해 - 경험치 수식을 수정해서(계수를 낮춘다던지) 레벨업을 쉽게끔 하자
    
      * 흠... 플래너 관련해서는 자료가 안보임 ㅠ
    
      * 임의로 계수 조절한 공식은 : INT((레벨-1)^1.2)+10
    
      * | 레벨 | 필요경험치 | 누적경험치 |
        | ---- | ---------- | ---------- |
        | 1    | 10         | 10         |
        | 2    | 11         | 11         |
        | 3    | 12         | 12         |
        | 4    | 13         | 13         |
        | 5    | 15         | 15         |
        | 6    | 16         | 16         |
        | 7    | 18         | 18         |
        | 8    | 20         | 20         |
        | 9    | 22         | 22         |
        | 10   | 23         | 23         |
    
    * 경험치 흭득유도를 위해 - 레벨업에 뽑기만 주는것이 아닌 레벨에 따른 경험치를 얻을때 "화폐"로도 챙겨주자
      * 추가로 특정레벨(5,10,15...)에 추가보상(방 넓히기, 선물지급 등등)을 주자
    
  * **결론2 : 중간지점이 별로라면 일정한것도 좋다고 생각**
    
    * 경험치 보상을 하루 제한을 걸어놨으므로 20정도로 일정하게 하면 되지않을까싶음
    * 대신 레벨의 의미가 약해지므로 이를 방지할 방안이 필요할듯
    
  * **결론3 : 한달마다 레벨을 초기화 하는건?**
  
    * 매달 초기화를 하기 때문에 기존 경험치 수식 or 계수를 좀 더 낮춘 수식 사용하면 될듯?
    * 계획 수행을 남들보다 늦게 시작해도 다음달에 레벨경쟁에 참여할 수 있다.
    * 매달 초기화 함으로써 매달 새롭게 플랜을 시작할 수 있다 -> 게임보단 좀 더 플랜에 비중
      * 계획이 1년 단위보다는 한달 단위로 수행하는게 더 플랜수행에 효과적이라 생각
    * 단, 레벨 초기화일 뿐 얻은 화페 및 보상아이템은 그대로 간직

<br>

**로우폴리 에셋찾아보기**

* 가구 위주로
  * [유료](https://assetstore.unity.com/packages/3d/props/furniture/low-poly-furniture-156774?locale=ko-KR)
  * [유료-예시로 쓰기 좋아보임](https://assetstore.unity.com/packages/3d/props/interior/low-poly-furniture-assets-221471)
  * [무료](https://assetstore.unity.com/packages/3d/props/furniture/low-poly-simple-furniture-free-240197?locale=ko-KR)
  * [무료](https://assetstore.unity.com/packages/3d/props/furniture/3d-dungeon-lowpoly-pack-231265)

<br>

**타이머 기능 및 컨트롤러**

* 타이머의 경험치 계산은 "집중, 허용" 상태를 제외하고는 구현된 상황
* 타이머 컨트롤러만 구현하면 되는데 구조가 Task에 꼭 묶여있는거 생각하고 구현
  * 생각해보니 이미 경험치 계산에 사용한 타이머인지 구분이 필요해서 필드 하나 추가해야할듯


<br>

**최적화 위주로 진행**

* 쿼리튜닝
  * 코드 계속 리팩토링을 거쳐서 쿼리수 줄여야 할듯
  * 다만 기능부터 다 개발이 완벽히 끝난게 확인되면 그때부터 진행해야할듯

* 캐시

  * https://hongong.hanbit.co.kr/%EC%99%84%EB%B2%BD-%EC%A0%95%EB%A6%AC-%EC%BF%A0%ED%82%A4-%EC%84%B8%EC%85%98-%ED%86%A0%ED%81%B0-%EC%BA%90%EC%8B%9C-%EA%B7%B8%EB%A6%AC%EA%B3%A0-cdn/  
    https://tbread-development.tistory.com/m/25  
    https://mygumi.tistory.com/275

  * https://rumor1993.tistory.com/86
    https://blog.lael.be/post/7605
    https://hudi.blog/spring-http-caching/
    https://wildeveloperetrain.tistory.com/119

    https://kim-gpt.tistory.com/entry/%ED%81%B4%EB%9D%BC%EC%9D%B4%EC%96%B8%ED%8A%B8-%EB%8B%A8-%EC%BA%90%EC%8B%9C-Client-side-Caching
    https://kim-gpt.tistory.com/entry/%EC%84%9C%EB%B2%84-%EB%8B%A8-%EC%BA%90%EC%8B%9C-Server-side-Caching

    (클ㄹ라!)브라우저 캐시 종류 - 디스크캐시, 메모리캐시
    (섯버!)서버 캐시 종류 - CDN, 등등...

    아마 아래는 전부 서버가 부담하는 서버단캐시 일거다.
    (1)정적이미지용 캐시 - .setCacheControl(cacheControl); 써서 메모리에 캐시해서 속도를 올리자(정적파일은 우리가 그냥 제공해주자URL)
    -> CDN-AWS S3? 로 구성해서 이미지 얻는게 속도가 더 빠르다고 하긴하는데 이건 고민,,
    -> 또한 Redis 같이 캐시서버 구축방법도 좋아보임(아마 위에서 설명한 캐시는 메모리에 바로 쓰는거? 잘 모르겠음 차이는.)
    
    ​	https://zangzangs.tistory.com/72
    
    (2)@Cachable - 나머지 캐시할것들 캐시ㄱㄱ
    
  * CDN을 사용하는게 굉장히 많은 속도 향상을 얻을듯 하다.(3d 이미지를 사용하다보니 이미지쪽 캐싱이 굉장히 중요하다고 생각)
  
* 모니터링

  * 이부분도 기능개발은 다 된것이 확인되면 진행해줘야 할듯하다.
  * 강의 본거 따라서 진행해보자.

* 로드밸런싱

  * [개념](https://velog.io/@alswn9938/%EB%A1%9C%EB%93%9C%EB%B0%B8%EB%9F%B0%EC%8B%B1), [개념](https://www.nowwatersblog.com/backend/serverLoad/serverDistribution)
  * [실습](https://velog.io/@msung99/Nginx-%EB%A1%9C%EB%93%9C%EB%B0%B8%EB%9F%B0%EC%8B%B1-%ED%99%98%EA%B2%BD%EC%9D%84-%EA%B5%AC%EC%B6%95%ED%95%B4-%ED%8A%B8%EB%9E%98%ED%94%BD-%EB%B6%84%EC%82%B0%EC%8B%9C%ED%82%A4%EA%B8%B0-feat.-%EB%AC%B4%EC%A4%91%EB%8B%A8%EB%B0%B0%ED%8F%AC_)
  * [로드밸런싱테스트](https://velog.io/@znftm97/Nginx-%EB%A1%9C%EB%93%9C%EB%B0%B8%EB%9F%B0%EC%8B%B1-%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98-%EC%84%B1%EB%8A%A5-%ED%85%8C%EC%8A%A4%ED%8A%B8-%EB%AC%B4%EC%A4%91%EB%8B%A8-%EB%B0%B0%ED%8F%AC)
    * [DevOps 강의](https://velog.io/@znftm97/series/Class101-foo-%EA%B0%95%EC%9D%98)

<br><br>

## 23-09-19~22

**캐릭터(친구기능) 목욜까지**

* 경험치량 수식 적용(임의로 아래 수식사용 - 확정은 아님)
  * 필요 경험치 수식 : (레벨-1)^2*1.5(계수)
  * 일정 경험치 보상량 : 1 or 1+T(Time)
  * 클라에서는 API요청 때 이전 레벨과 요청후 레벨이 다르면 "레벨업" 임펙트 발생시키면 될듯
  * **reqExp필드 추가 얘기하기!**
* **친구 테이블 -> 팔로우 테이블로 변경**
  * follow{follow_id, follower_id, following_id, 캐릭터id(fk)} - 팔로워들 id는 캐릭터id 사용
    * from - to 느낌
  * 알림은?? 알림 테이블을 따로 만들어두자
    * http://www.ciboard.co.kr/manual/tables/notification 참고 DB
    * **알림 테이블 물어보쟈!! -> OK OK**
* **"컨트롤러(API)" -> 할차례!!,,**
  * 캐릭터
    * 캐릭터 생성 API - 회원가입때...바로진행.. 따라서 "**회원가입 API**" 파트에서 해결?하자?
      * UUID와 닉넴 받을텐데 이때 "**경험치, 캐릭터 테이블**" 함께 생성
  * 경험치
    * 경험치량 조회 API - 누적, 현재, 레벨 전부 제공
    * 경험치 업데이트는 "**일정완료 API**" 추가해서 이곳에서 진행하자!
      * 경험치 제한까지 구현완료
      * 스케줄링으로 "일일경험치 제한" 매일 초기화 구현완료
  * 팔로우
    * 팔로우 생성 API
    * 팔로우 제거 API
    * 팔로잉 / 팔로워 조회 API - 팔로잉(해당캐릭터의 팔로잉), 팔로워(모든캐릭터의 팔로잉)
    * 팔로우시 상대방은 자신을 팔로우했는지 알려주는 API -> 이건그냥 PASS
      * 테이블 검색후 있으면 "맞팔로우 하기" 로 버튼명 변경하게끔
  * 알림 
    * 알림 생성 API - 팔로우 때 해야해서 **"팔로우 생성 API"**에 추가
    * 알림 조회 API
    * 알림제거는 따로 하지말고 읽음표시로 클라에서 해결하자
* **"화폐"는 상점만들때 추가 하겠음**
* **"일정완료" 종류**
  * 클라에서 일정들 체크 후 서버로 전송(List) -> OK
  * 클라에서 타이머 .... -> 타이머 구현방식 구글링 필요해보임.. -> 아직 X

<br>

주저리 주저리.. 회의내용들...

**경험치**

* 필요 경험치 수식 : (레벨-1)^2*1.5(계수)
* 일정소화 경험치 보상 : 1
* 타이머 경험치 보상 : 1+T(Time)
* 하루 최대 경험치 제한 : 24
  * 일정소화 최대 경험치 : 12
  * 타이머 최대 경험치 : 12
* 추후에 생각할 경험치
  * 타이머의 구체화 "집중, 허용시간"
  * 검증된 일정 소화의 경험치 - 예로 "러닝"

**기능개발 우선 - 캐릭터, 타이머, 상점**

**서버 성능 최적화**

* 모니터링
* 쿼리수 줄이기
* 캐시
* 로드밸런싱

## 23-09-17

아래 순서로 개발해나갈 예정,,, -> 먼저 **"캐릭터"**

개발
1. 캐릭터(친구,화폐,아이템, 경험치 등)
2. 타이머

리팩토링
1. 검증(Validation)
2. API 예외처리
3. AOP(공통 관심 해결사), 캐싱 등등
   * **애플리케이션의 성능을 개선**하기 위해 캐싱, 로드밸런싱 등을 적용할 예정

<br>

**[ERDCloud](https://www.erdcloud.com/d/qhJLFCiq5KpRSDN87) -> "화폐 제거"**

* 엔티티 -> "캐릭터" + 친구, 캐릭터아이템, 경험치
  * 친구 테이블명 friend로
    * id는 freind_id 로
  * 캐릭터의 레벨은 경험치 테이블로 옮기자 - 계산하기 더 쉽게
    * 임의로 경험치량 10으로 테스트.
  * **엔티티 - 테스트완료** -> 테스트코드 실행이 안되서 아래 두가지 수정으로 해결
    * 첫번째로 패키지명이 안바껴서 lepl로 전부 수정.
    * 다음으로 test패키지에 따로 application.yml 을 또 설정해놨었다. lepl로 수정.
* 레퍼지토리, 서비스 - 테스트 완료

<br>

**경험치량**

* 필요 경험치 = ((레벨 - 1) * 50 / 49) ^ 2.5 * 계수(=100만 테이블의 경우 10)
* 누적 경험치 = (기본 제공 수치 * 레벨^2) + 추가 제공 수치
* https://www.thisisgame.com/pad/tboard/?n=54281&board=22
* https://adelius.tistory.com/121
  * https://m.blog.naver.com/sirasaya/3032113

<br><br>

# 23-06-06

**리스트와 일정 "1:N" 관계로 전체적으로 수정**

**타이머를 제외하고 일정 관련한 조회, 수정, 삭제 등등 우선 개발**

* 조회 로직 쿼리 전송량 개선을 위해 **fetch join+distinct** 적절히 사용
* 조회 로직 null 문제 때문에 **lazy 강제 초기화** 적절히 사용

<br>

**Postman 의 기능을 좀 더 공부하여 API 명세서를 작성**

* 테스트 API 명세서 : https://documenter.getpostman.com/view/21970313/2s93mBwec5

<br>

**일정 완료의 경우 생각중인건??(지금은 안할생각)**

* 1분마다 @Scheduled 같이 스케줄링
  * 무엇을?? 전체 Task 조회로직을 실행해서 "종료시간"을 활용
  * `현재 서버시간 >= 종료시간` 이라면, 종료된(완료된) 일정이란것을 판단

<br><br>

# 23-05-31

**나머지 API들 CRUD 진행 및 엔티티에 편의 메서드들(비지니스, 생성 등등) 추가**

* 레퍼지토리, 서비스, 컨트롤러 작성
* TDD까지 함께 작성

<br>

**문제가 발생.. 리스트와 일정은 "다대다"관계가 아니였던것 같다.  
"다대다" 관계는 추후에 추가할 아이템 목록 테이블이 캐릭터와 "다대다" 관계로 해야한다.**

**따라서 리스트와 일정은 "1:N" 관계인 것 같고, 우선 이 관계를 DB에 추가로 그려놔야겠다...**

<br><br>

# 23-05-15

**추후에 리팩토링 과정**

* ExceptionHandlerExceptionResolver를 통해서 API 예외처리를 진행하겠다.

<br>

**"로그인" 관련해서 쿠키 세션 만료시간을 추가 및 ArgumentResolver 추가**

* AOP관련 해서는 웹의 경우 @Aspect 보다 URL을 활용하는 인터셉터가 더 좋으므로 이를 이용해서 "로그인 인증" 관련을 진행을 저번에 했고, 여기선 ArgumentResolover로 멤버 객체 바로 가져오게 추가한다.
* 세션 저장소에는 최소한의 데이터만 넣는게 중요하므로 Member객체가 아닌 Member id만을 담아두겠다.

<br>

**나머지 API들 CRUD 진행**

<br><br>

# 23-05-04

**로그인 처리 로직 - 세션 방식을 사용 (물론 전달을 해야해서 쿠키도 함께 사용)**

* 맨 처음에 로그인을 하면 서버에서 세션Id를 담은 쿠키를 클라에 응답으로 준다.
* 클라는 요청시 항상 쿠키에 세션Id가 포함되어 전달하게되고,  
  서버는 전달받은 쿠키 정보로 "세션 저장소"를 조회해서 회원임을 인증한다 => 메모리에 "세션 저장소(톰캣이 관리)"

<br>

**클라이언트**

* **클라 상에서 로그인 기록 있으면 "소셜 로그인" 화면 없이 그냥 바로 => 서버로 uid 전송**
  * API 주소는 "로그인" 주소를 준다.
* **클라 상에서 로그인 기록 없으면 "소셜 로그인" 화면 및 로그인 시도 => 이때, 서버로 uid 전송**
  * API 주소는 "회원가입" 주소를 준다.
* **클라 상에서 로그아웃을 요청하는 경우는 쿠키 정보가 있어서 바로 API 호출 및 "소셜 로그인" 화면으로 이동.**
  * 물론, 클라 상의 로그인 기록도 꼭 지워줘야 나중에 "회원가입"으로 잘 넘어감.
  * API 주소는 "로그아웃" 주소를 준다.
* **마지막으로 앱의 종료 이벤트때 "로그아웃 API"  호출 코드를 작성한다.**
  * onDestroy같이 앱 종료 이벤트때 웹뷰에서 얻은 쿠키정보를 request에 담아서 로그아웃 API 호출해주기

<br>

**서버**

* **로그인 API => 받은 uid로 회원판단 시도!! ("회원 저장소"에서 확인!!)**

  - **회원 일시**

    * UUID로 세션Id를 생성해서 "회원 저장소"에서 받은 회원정보(=memberA)와 함께 "세션 저장소"에 기록

    * 세션Id를 응답 쿠키로 전달

    - **회원 아닐시** 
      - 회원이 아니라고 클라에게 전송 (클라는 위 <클라>파트의 2번 카테고리를 행하면 됨)


* **회원가입 API => 받은 uid로 회원판단 시도!! ("회원 저장소"에서 확인!!)**

  - **첫 가입 회원**

    * uid, 기타정보 등등을 "회원 저장소"에 기록하고, UUID로 세션Id를 생성해서 회원정보(=memberA)와 함께 "세션 저장소"에 기록

    * 세션Id를 응답 쿠키로 전달

    - **이미 가입한 중복 회원**
      - 이미 회원이라고 클라에게 전송 (클라는 위 <클라>파트의 1번 카테고리를 행하면 됨)


* **로그아웃 API**
  - 쿠키 정보에 세션Id를 활용해서 해당 세션을 "세션 저장소"에서 제거

<br>

**기대 효과**

* **로그인 할때 이점 => "소셜 로그인"을 사용한 이점**
  * "소셜 로그인"을 통해서 회원 id,pw 등등 개인정보는 해당 "소셜 커뮤니티"와 주고 받기 때문에 개인정보 털릴 위험이 적어짐. 
  * "소셜 로그인"을 통해서 얻은 uid 값 또한 회원 id,pw 와는 관계없는 값을 주기 때문에 uid만을 우리 "서버"에 줘서 회원가입을 하면 개인정보 털릴 걱정이 없음.(즉, pw털릴 위험이 없음)
    * "uid가 털린것 vs id,pw 털린것" 을 비교해봐도 uid가 훨씬 안정적

* **로그인 이후의 이점 => "세션 방식"을 사용한 이점**
  * "회원 저장소" 와 "세션 저장소"를 함께 운영함으로써 회원 정보와는 전혀 관련없는 세션Id값(UUID)을 쿠키에 담아서 클라와 통신을 하기 때문에 개인정보 털릴 걱정이 없음.
  * 만료시간을 설정할 수 있기 때문에 쿠키가 탈취당해도 시간이 지나면 사용못하게 할 수 있다.
  * 세션Id를 서버에서 관리하므로 해킹이 의심된다면?? 서버에서 해당 세션을 강제로 제거할 수 있다.

<br>

**기타**

* **만료시간**
  * 보통은 그냥 만료시간=30분 정했으면 30분 뒤에 세션이 제거되지만,  
    스프링의 `HttpSession`은 클라->서버 요청의 제일 최신 시간을 이용해서 그시간 + 만료시간 을 계산해서 세션을 제거해준다.
  * 우리는 만료시간을 어떤 방식을 체택 해야할까??  
    웹의 경우 클라에서 웹을 종료했다고해서 알 수 있는 방법이 없다. 다른 방법이 있다고는 하는데, 잘 모르겠다.
  * 하지만 앱의 경우 안드로이드를 예로들자면 앱 종료때 onDestroy() 이벤트가 발생한다.  
    **따라서 앱의 종료 이벤트때 서버에 세션Id를 제거해주는 "로그아웃 API"  호출 코드를 작성한다.**
* **세션 체크하는 코드는 우리 앱에서는 모든 로직에서 다 필요하다.**
  * **따라서 "공통 관심사"로 두고 해결**해야하는데, 스프링의 AOP로도 해결이 가능하지만  
    "서블릿 필터 or 스프링 인터셉터"를 사용하는것을 추천한다.   
  * 왜냐하면 웹과 관련된 공통 관심사는 HTTP의 정보들도 필요한데, 이 정보도 "서블릿 필터 or 스프링 인터셉터"는 "HttpServletRequest"로 제공하기 때문이다.
  * 결론 : "스프링 인터셉터"가 더 편리,정교,다양한기능 을 제공해서 이 방식을 이용  
    * 사용법은 "HandlerInterceptor" 인터페이스를 구현하면 된다.
    * 동작 흐름 : WAS->필터->서블릿(Dispatcher Servlet)->스프링 인터셉터->컨트롤러
      * 따라서 컨트롤러 전에 로그인 인증해서 인증여부에따라 컨트롤러를 호출하거나 안하면 된다.
* **세션Id를 통해서 "세션 저장소"에 기록된 Member 정보를 가져와서 각종 DB들을 접근할 수 있다.**
  * **""세션Id를 통해서 "세션 저장소"에 기록된 Member 정보를 가져와""** 이부분이 코드가 많이 겹칠듯 한데, 이는 추후에 AOP로 해결을 하던지 하도록 하자.
  * 또는 인터셉터 반환때 Member까지 반환하게끔 해결하는건 보안에 취약할 수 있다고 하니까 Spring Security와 같은 보안 프레임워크를 사용하여, 사용자 인증과 권한 부여를 처리하고, 컨트롤러에서는 SecurityContextHolder를 통해 인증된 사용자 정보를 가져오는 방법도 존재한다는걸 인지.

<br>

**네이밍**

- **Database**
  - 테이블명 형식으로 `ORDER 또는 order` 사용 **=> 대문자 or 소문자**
  - 컬럼명 형식으로 `order_id` 사용 **=> 스네이크 케이스**
- **JPA -> ORM(객체 관계 매핑)**
  - 엔티티명 형식으로 `OrderItem` 사용 **=> 파스칼 케이스**
  - 필드명 형식으로 `orderId` 사용 **=> 카멜 케이스**  
    - **스프링 부트는 자동으로 필드명을 `orderId -> order_id` 로 컬럼명 찾아서 매핑**
      - 흠.. 이렇게 배웠었는데 정확히는 테이블 컬럼이 `ORDER_ID` 로 생성 되는 중이다.
      - 아마도 맨 마지막에 대문자로 바뀌는듯 하다?
    - **스프링 부트는 자동으로 엔티티명을 `OrderItem -> ORDERITEM` 로 테이블명 찾아서 매핑**
      - 이것도 `orderitem` 으로 매핑하고 맨 마지막에 대문자로 바뀌는건가 싶다.

```java
@Getter @Setter
@Entity
public class Member {
    @Id @GeneratedValue
    @Column(name = "member_id")
    private Long id; // DB PK
    @Column(nullable = false) // Not Null
    private String uid; // Entity ID => 대체키

    private String nickname;

    @OneToMany(mappedBy = "member") // 양방향
    private List<Lists> lists = new ArrayList<>(); // 컬렉션은 필드에서 바로 초기화
```

* Member엔티티명이지만 MEMBER로 테이블 매핑 
* id는 id와 매핑되기 때문에 직접 "member_id"와 매핑 => 결국 컬럼명은 MEMBER_ID로 생성

**엔티티구현 -> 레퍼지토리 -> 서비스 -> 컨트롤러 구현 순서로 진행.**

엔티티 구현에 많은 비중을 쌓기 위해 여러가지 메서드들도 추가할 예정.

* 연관관계 편의 메서드 등등 => 양방향때 활용하면 좋을 듯 하다.

또한 구현 때 TDD 작성이 매우 중요하므로 엔티티가 아니여도,

**레퍼지토리와 서비스 단계들은 되도록이면 TDD 작성을 하자.**

**개발과정 정리**

* 요구사항 분석(대략적 기능)
* 기능 목록(상세한 기능)
* 설계 시작
  * 도메인 모델 분석(간략히)
  * 테이블 설계(DB)
  * 엔티티 설계(JPA)
* 코드 구현 (각 파트별 TDD도 함께)
  * 도메인 구현 -> 엔티티를 의미하며, 모든 계층에서 사용
  * 레퍼지토리 구현 -> DB와 상호작용
  * 서비스 구현 -> 비지니스 로직 & 트랜잭션
    * `도메인 모델 패턴` : 서비스 계층은 단순히 엔티티에 필요한 요청을 위임하는 방식
    * `트랜잭션 스크립트 패턴` : 엔티티에는 비지니스 로직이 거의 없고 서비스 계층이 담당하는 방식
    * **참고로 `도메인 모델 패턴` 방식으로 진행 중**

  * 컨트롤러 구현 -> 웹 계층과 상호작용 (API 포함)

<br><br>

# 23-04-27

![image](https://user-images.githubusercontent.com/80165014/236442807-9c183cd9-424f-482e-b1c1-364f0e3825ab.png)

**엔티티 설계 과정**

•최대한 객체지향적으로 설계(테이즐 지향이 아닌)

•엔티티 설계대로 코드에 그대로 적용 됨

•따라서 member_id : Long 같은 필드명을 member : Member 형태로 객체 참조 형식으로 변경

•중요한 “연결 관계“

•기본적으로 “다대일”에서 “다“ 외래키를 가지며, 외래키를 가진 쪽이 주인, “일대일”의 경우 외래키를 아무나 가져도 되고 주인도 아무나 가능

•따라서 초기엔 주인을 중심으로 “단방향” 연결 관계 지향

•이후에 “양방향“ 설정에는 테이블 구조를 바꿀 필요없이 코드로 변경 가능하기 때문

•참고로 “일대일＂의 경우 “주 테이블 외래키 단방향“ 과 “대상 테이블 외래키 양방향“ 이 2가지의 연결관계가 존재하며 각각 장단점이 있어서 적절히 판단

<br><br>

# 23-04-14

**DB 구조 설계**

•사용자 ITEM에 “착용여부 상태” 컬럼 추가

•컬럼명 이름들 스프링 규칙에 맞게 수정

•일정 테이블 -> list_일정 테이블도 하나 추가

•“다대다“ 관계이므로 잘 풀어내야함.

•일정 테이블에 “타이머 상태정보” 를 위해 “상태” 테이블 추가

•그냥 일정인지 타이머 인지 구별 위해

•타이머 테이블 추가 및 “상태정보” 컬럼 추가(ENUM타입)

•**열품타** **처럼** : 허용앱 상태, 최대집중 상태 로 구별

•최대집중 상태 4시간? 이상시 보상X(제약조건 추가)

•허용앱 시간, 최대집중 시간, 총 누적시간 3개를 보여줌.

•시간 정보는 start, end 로 기록

•누적시간 계산은 전체 end – start => (허용, 최대집중 전부 포함)

**DB 구조 설계 (리스트_일정 테이블)**

•일정 테이블 -> list_일정 테이블도 하나 추가

•“다대다“ 관계

•하루 단위로 list_일정 테이블을 update할 것이기 때문

•“다대다” 관계는 중간에 테이블 하나 넣어서 잘 풀어내야 함.

•“다대다” 관계의 문제는 양방향으로 “무한 호출＂이 발생

•“ 하루_일정(=리스트) <-> 중간 연결(=리스트_일정) <-> 일정 “ 테이블 구조

•하루_일정 테이블과 중간연결 테이블에 양방향 관계 필요

•양방향 관계 없어도 구현가능하지만, 양방향 관계로 보기쉽게 구현하는것이 좋다

•중간 연결에서 일정 테이블은 단방향 관계

•“일정“ 에서 “하루_일정“ 으로 넘어갈 필요는 없기 때문

•참고 네이밍 규칙

•스프링 부트는 자동으로 ‘orderId -> order_id’ 로 컬럼명 찾아서 매핑

**DB 구조 설계 모습**

![image](https://user-images.githubusercontent.com/80165014/236442628-f00ad898-1bb2-427a-88b4-b4c0738f0b5b.png)

**보상관련**

•일정 완료에 따른 보상 관련해서는 재원이형 의견 추천

•타이머 사용시

•90% 미만?? 일반 보상

•90% 이상?? 큰 보상

•타이머 미사용시

•일반 보상

<br><br>

# 23-04-11

**DB 구조 설계**

•Erd cloud 사용(협업) 

•플래너 부분 DB 구조 자료조사후 개선할 예정

![image](https://user-images.githubusercontent.com/80165014/236442050-54f5a318-e92e-4051-a3c5-8ec846519330.png)

<br>

**DB 구조 설계**

•로그인 기능

•소셜 로그인 API 활용 + 한번 로그인하면 계속 자동 로그인

•uid 를 db에 기록해서 멤버 로그인!! (즉, 로그인을 복잡한 로직으로 할 필요가 없는 프로젝트이다.)

•기존 회원가입, 로그인 로직은 복잡하다. 참고 링크 참고

•https://rastalion.me/%ED%9A%8C%EC%9B%90-%EA%B0%80%EC%9E%85-%EB%B0%8F-%EB%A1%9C%EA%B7%B8%EC%9D%B8%EC%9D%84-%EC%9C%84%ED%95%9C-%ED%85%8C%EC%9D%B4%EB%B8%94-%EC%84%A4%EA%B3%84/
